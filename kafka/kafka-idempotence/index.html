<!DOCTYPE html>
<html lang='en'>

<head>
  <meta name="generator" content="Hexo 5.4.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.17.2">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://fastly.jsdelivr.net'>
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>kafka</title>

  
    <meta name="description" content="什么是幂等幂等 这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。 下面通过几个简单的例子说明一下。 比如在乘法运算中，让数字乘以 1 就是一个幂等操作，因为不管你执行多少次这样的运算，结果都是相同的。再比如，取整函数（floor 和 ceiling）是幂等函数，那么运行 1 次 floor(3.4) 和 100 次 floor(3.4)，结果是一样的，都">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka 系列(六)：幂等实现剖析">
<meta property="og:url" content="https://yanliang.cool/kafka/kafka-idempotence/">
<meta property="og:site_name" content="yanliang">
<meta property="og:description" content="什么是幂等幂等 这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。 下面通过几个简单的例子说明一下。 比如在乘法运算中，让数字乘以 1 就是一个幂等操作，因为不管你执行多少次这样的运算，结果都是相同的。再比如，取整函数（floor 和 ceiling）是幂等函数，那么运行 1 次 floor(3.4) 和 100 次 floor(3.4)，结果是一样的，都">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-08-17T00:00:00.000Z">
<meta property="article:modified_time" content="2021-08-17T00:00:00.000Z">
<meta property="article:author" content="yanliang">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="幂等">
<meta name="twitter:card" content="summary_large_image">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/icon.svg">
  

  

  


  
</head>

<body>
  


  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/index-head.png" onerror="javascript:this.classList.add('error');this.src='https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title"><div style="line-height: 1.5; letter-spacing: 3px; position: relative;">Yanliang</div> <div style="font-size: .85rem; letter-spacing: 1px; font-weight: 500;">Believe in yourself.</div></div></a></div>

<nav class="menu dis-select"><a class="nav-item active" href="/">Blog</a><a class="nav-item" href="/wiki/">Wiki</a><a class="nav-item" href="/friends/">Friends</a><a class="nav-item" href="/about/">More</a></nav></header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" placeholder="Search"></form><div id="search-result"></div><div class="search-no-result">No Results!</div></div></div></widget>

<widget class="widget-wrapper toc single" id="toc"><div class="widget-header cap dis-select"><span class="name">Kafka 系列(六)：幂等实现剖析</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%82%E7%AD%89"><span class="toc-text">什么是幂等</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer-%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-text">Producer 幂等性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer-%E5%B9%82%E7%AD%89%E6%80%A7%E4%BD%BF%E7%94%A8"><span class="toc-text">Producer 幂等性使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">幂等性要解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer-%E5%B9%82%E7%AD%89%E6%80%A7%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-text">Producer 幂等性实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PID"><span class="toc-text">PID</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PID-%E7%94%B3%E8%AF%B7"><span class="toc-text">PID 申请</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sequence-Numbers"><span class="toc-text">Sequence Numbers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B"><span class="toc-text">发送流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E9%80%81%E9%80%BB%E8%BE%91"><span class="toc-text">客户端发送逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91"><span class="toc-text">服务端处理逻辑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-text">思考题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B1%82-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-%E5%B0%8F%E4%BA%8E%E7%AD%89%E4%BA%8E5"><span class="toc-text">为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-%E9%85%8D%E7%BD%AE%E5%A4%A7%E4%BA%8E1%E6%97%B6%EF%BC%8C%E6%98%AF%E5%90%A6%E4%BF%9D%E8%AF%81%E6%9C%89%E5%BA%8F"><span class="toc-text">当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序</span></a></li></ol></li></ol></div></div></widget>


</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" title="Back to Top" href="#start" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/social/top.svg"/></a><a class="social" title="GitHub" href="https://github.com/gyl-coder/" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/social/github.svg"/></a><a class="social" title="Spotify" href="https://open.spotify.com/" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/social/music.svg"/></a><a class="social" title="Unsplash" href="https://unsplash.com/" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/social/music.svg"/></a><a class="social" title="Comments" href="/about/#comments" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/social/message.svg"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">Home</a><span class="sep"></span><a class="cap breadcrumb" href="/">Blog</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/kafka/">kafka</a></div><div id="post-meta">💧 Posted on&nbsp;<time datetime="2021-08-17T00:00:00.000Z">Aug 17, 2021</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>Kafka 系列(六)：幂等实现剖析</span></h1>
<h2 id="什么是幂等"><a href="#什么是幂等" class="headerlink" title="什么是幂等"></a>什么是幂等</h2><p><strong>幂等</strong> 这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。</p>
<p>下面通过几个简单的例子说明一下。</p>
<p>比如在乘法运算中，让数字乘以 1 就是一个幂等操作，因为不管你执行多少次这样的运算，结果都是相同的。再比如，取整函数（floor 和 ceiling）是幂等函数，那么运行 1 次 floor(3.4) 和 100 次 floor(3.4)，结果是一样的，都是 3。相反地，让一个数加 1 这个操作就不是幂等的，因为执行一次和执行多次的结果必然不同。</p>
<p>在计算机领域中，幂等性的含义稍微有一些不同：</p>
<ul>
<li>在命令式编程语言（比如 C）中，若一个子程序是幂等的，那它必然不能修改系统状态。这样不管运行这个子程序多少次，与该子程序关联的那部分系统状态保持不变。</li>
<li>在函数式编程语言（比如 Scala 或 Haskell）中，很多纯函数（pure function）天然就是幂等的，它们不执行任何的 side effect。</li>
</ul>
<p>幂等性有很多好处，<strong>其最大的优势在于我们可以安全地重试任何幂等性操作</strong>，反正它们也不会破坏我们的系统状态。如果是非幂等性操作，我们还需要担心某些操作执行多次对状态的影响，但对于幂等性操作而言，我们根本无需担心此事。</p>
<h2 id="Producer-幂等性"><a href="#Producer-幂等性" class="headerlink" title="Producer 幂等性"></a>Producer 幂等性</h2><p>Producer 的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是 Kafka 所提供的幂等性是有条件的：</p>
<ol>
<li>kafka 中的幂等性只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）;</li>
<li>kafka 中的幂等性不能跨多个 TopicPartition，只能保证单个 partition 内的幂等性，当涉及多个 Topic-Partition 时，这中间的状态并没有同步。</li>
</ol>
<p>如果需要跨会话、跨多个 topic-partition 的情况，需要使用 Kafka 的事务性来实现。</p>
<h2 id="Producer-幂等性使用"><a href="#Producer-幂等性使用" class="headerlink" title="Producer 幂等性使用"></a>Producer 幂等性使用</h2><p>在 Kafka 中，Producer 默认不是幂等性的，但我们可以创建幂等性 Producer。</p>
<p>指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即 <code>props.put(&quot;enable.idempotence&quot;, ture)</code>，或 <code>props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>); <span class="comment">// 当 enable.idempotence 为 true，这里默认为 all</span></span><br><span class="line">props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">KafkaProducer producer = <span class="keyword">new</span> KafkaProducer(props);</span><br><span class="line"></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord(topic, <span class="string">&quot;test&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>Prodcuer 幂等性对外保留的接口非常简单，其底层的实现对上层应用做了很好的封装，应用层并不需要去关心具体的实现细节，对用户非常友好。</p>
<h2 id="幂等性要解决的问题"><a href="#幂等性要解决的问题" class="headerlink" title="幂等性要解决的问题"></a>幂等性要解决的问题</h2><p>一般来说，消息可靠性交付保障，提供三种级别：</p>
<ul>
<li>最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。</li>
<li>至少一次（at least once）：消息不会丢失，但有可能被重复发送。</li>
<li>精确一次（exactly once）：消息不会丢失，也不会被重复发送。</li>
</ul>
<p>kafka 默认提供的就是第二种，即至少一次。</p>
<p>在 kafka 中，消息已提交的含义，通常是Broker 成功接收到消息，并且 Producer 接到 Broker 的应答才会认为该消息成功发送。不过倘若消息成功“提交”，但 Broker 的应答没有成功发送回 Producer 端（比如网络出现瞬时抖动），那么 Producer 就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是 Kafka 默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送。</p>
<p>Kafka 也可以提供最多一次交付保障，只需要让 Producer 禁止重试即可。这样一来，消息要么写入成功，要么写入失败，但绝不会重复发送。我们通常不会希望出现消息丢失的情况，但一些场景里偶发的消息丢失其实是被允许的，相反，消息重复是绝对要避免的。此时，使用最多一次交付保障就是最恰当的。</p>
<p>对于大多数应用而言，数据保证不丢是可以满足其需求的，但是对于一些其他的应用场景（比如支付数据等），它们是要求精确计数的，这时候如果上游数据有重复，下游应用只能在消费数据时进行相应的去重操作，应用在去重时，最常用的手段就是根据唯一 id 键做 check 去重。</p>
<p>在这种场景下，因为上游生产导致的数据重复问题，会导致所有有精确计数需求的下游应用都需要做这种复杂的、重复的去重处理。试想一下：如果在发送时，系统就能保证 exactly once，这对下游将是多么大的解脱。这就是幂等性要解决的问题，主要是解决数据重复的问题，正如前面所述，数据重复问题，通用的解决方案就是加唯一 id，然后根据 id 判断数据是否重复，Producer 的幂等性也是这样实现的，这一小节就让我们看下 Kafka 的 Producer 如何保证数据的 exactly once 的。</p>
<h2 id="Producer-幂等性实现原理"><a href="#Producer-幂等性实现原理" class="headerlink" title="Producer 幂等性实现原理"></a>Producer 幂等性实现原理</h2><p>正如前面所述，幂等性要解决的问题是：Producer 设置 at least once 时，由于异常触发重试机制导致数据重复，幂等性的目的就是为了解决这个数据重复的问题，简单来说就是：</p>
<p><code>at least once + 幂等 = exactly once</code></p>
<p>kafka Producer 在实现时有两个重要机制：</p>
<ul>
<li>PID（Producer ID），用来标识每个 producer client；</li>
<li>sequence numbers，client 发送的每条消息都会带相应的 sequence number，Server 端就是根据这个值来判断数据是否重复。</li>
</ul>
<h3 id="PID"><a href="#PID" class="headerlink" title="PID"></a>PID</h3><p>每个 Producer 在初始化时都会被分配一个唯一的 PID，这个 PID 对应用是透明的，完全没有暴露给用户。对于一个给定的 PID，sequence number 将会从0开始自增，每个 Topic-Partition 都会有一个独立的 sequence number。Producer 在发送数据时，将会给每条 msg 标识一个 sequence number，Server 也就是通过这个来验证数据是否重复。</p>
<p>这里的 PID 是全局唯一的，Producer 故障后重新启动后会被分配一个新的 PID，这也是幂等性无法做到跨会话的一个原因。</p>
<h4 id="PID-申请"><a href="#PID-申请" class="headerlink" title="PID 申请"></a>PID 申请</h4><p>下面我们看下 ProducerId 是如何获取的。</p>
<p>KafkaProducer 中的 Sender 线程在执行发送逻辑之前，会先判断判断是否需要一个新的 ProducerID</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOnce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果开启了幂等或事务，需要多一些检查</span></span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            transactionManager.maybeResolveSequences();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// do not continue sending if the transaction manager is in a failed state</span></span><br><span class="line">            <span class="keyword">if</span> (transactionManager.hasFatalError()) &#123;</span><br><span class="line">                RuntimeException lastError = transactionManager.lastError();</span><br><span class="line">                <span class="keyword">if</span> (lastError != <span class="keyword">null</span>)</span><br><span class="line">                    maybeAbortBatches(lastError);</span><br><span class="line">                client.poll(retryBackoffMs, time.milliseconds());</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 判断是否需要一个新的 ProducerId</span></span><br><span class="line">            transactionManager.bumpIdempotentEpochAndResetIdIfNeeded();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (maybeSendAndPollTransactionalRequest()) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AuthenticationException e) &#123;</span><br><span class="line">            <span class="comment">// This is already logged as error, but propagated here to perform any clean ups.</span></span><br><span class="line">            log.trace(<span class="string">&quot;Authentication exception while processing transactional request&quot;</span>, e);</span><br><span class="line">            transactionManager.authenticationFailed(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> currentTimeMs = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> pollTimeout = sendProducerData(currentTimeMs);</span><br><span class="line">    client.poll(pollTimeout, currentTimeMs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">bumpIdempotentEpochAndResetIdIfNeeded</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!isTransactional()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (epochBumpRequired) &#123;</span><br><span class="line">            bumpIdempotentProducerEpoch();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 当前不处于初始化状态，并且没有 ProducerId</span></span><br><span class="line">        <span class="keyword">if</span> (currentState != State.INITIALIZING &amp;&amp; !hasProducerId()) &#123;</span><br><span class="line">            transitionTo(State.INITIALIZING);</span><br><span class="line">            InitProducerIdRequestData requestData = <span class="keyword">new</span> InitProducerIdRequestData()</span><br><span class="line">                    .setTransactionalId(<span class="keyword">null</span>)</span><br><span class="line">                    .setTransactionTimeoutMs(Integer.MAX_VALUE);</span><br><span class="line">            <span class="comment">// 构建初始化ProducerId请求，放入请求队列中</span></span><br><span class="line">            InitProducerIdHandler handler = <span class="keyword">new</span> InitProducerIdHandler(<span class="keyword">new</span> InitProducerIdRequest.Builder(requestData), <span class="keyword">false</span>);</span><br><span class="line">            enqueueRequest(handler);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>之后请求会被发送到服务端（Broker）, 服务端处理该请求的入口是 KafkaApis 中的 handleInitProducerIdRequest()</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">handleInitProducerIdRequest</span><span class="params">(request: RequestChannel.Request, requestLocal: RequestLocal)</span>: Unit </span>= &#123;</span><br><span class="line">  val initProducerIdRequest = request.body[InitProducerIdRequest]</span><br><span class="line">  val transactionalId = initProducerIdRequest.data.transactionalId</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 权限校验</span></span><br><span class="line">  <span class="keyword">if</span> (transactionalId != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!authHelper.authorize(request.context, WRITE, TRANSACTIONAL_ID, transactionalId)) &#123;</span><br><span class="line">      requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!authHelper.authorize(request.context, IDEMPOTENT_WRITE, CLUSTER, CLUSTER_NAME, <span class="keyword">true</span>, <span class="keyword">false</span>)</span><br><span class="line">      &amp;&amp; !authHelper.authorizeByResourceType(request.context, AclOperation.WRITE, ResourceType.TOPIC)) &#123;</span><br><span class="line">    requestHelper.sendErrorResponseMaybeThrottle(request, Errors.CLUSTER_AUTHORIZATION_FAILED.exception)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 此处省略部分代码</span></span><br><span class="line">  <span class="function">def <span class="title">sendResponseCallback</span><span class="params">(result: InitProducerIdResult)</span>: Unit </span>= &#123;...&#125; </span><br><span class="line"></span><br><span class="line">  val producerIdAndEpoch = (initProducerIdRequest.data.producerId, initProducerIdRequest.data.producerEpoch) match &#123;  <span class="comment">// 初始化的是否都是 -1（具体可以看 InitProducerIdRequest 的构造方法），所以进入第一个 case</span></span><br><span class="line">    <span class="keyword">case</span> (RecordBatch.NO_PRODUCER_ID, RecordBatch.NO_PRODUCER_EPOCH) =&gt; Right(None)</span><br><span class="line">    <span class="keyword">case</span> (RecordBatch.NO_PRODUCER_ID, _) | (_, RecordBatch.NO_PRODUCER_EPOCH) =&gt; Left(Errors.INVALID_REQUEST)</span><br><span class="line">    <span class="keyword">case</span> (_, _) =&gt; Right(Some(<span class="keyword">new</span> ProducerIdAndEpoch(initProducerIdRequest.data.producerId, initProducerIdRequest.data.producerEpoch)))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  producerIdAndEpoch match &#123;</span><br><span class="line">      <span class="comment">// 初始化 ProducerId</span></span><br><span class="line">    <span class="function"><span class="keyword">case</span> <span class="title">Right</span><span class="params">(producerIdAndEpoch)</span> </span>=&gt; txnCoordinator.handleInitProducerId(transactionalId, initProducerIdRequest.data.transactionTimeoutMs,</span><br><span class="line">      producerIdAndEpoch, sendResponseCallback, requestLocal)</span><br><span class="line">    <span class="function"><span class="keyword">case</span> <span class="title">Left</span><span class="params">(error)</span> </span>=&gt; requestHelper.sendErrorResponseMaybeThrottle(request, error.exception)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">handleInitProducerId</span><span class="params">(transactionalId: String,</span></span></span><br><span class="line"><span class="params"><span class="function">                         transactionTimeoutMs: Int,</span></span></span><br><span class="line"><span class="params"><span class="function">                         expectedProducerIdAndEpoch: Option[ProducerIdAndEpoch],</span></span></span><br><span class="line"><span class="params"><span class="function">                         responseCallback: InitProducerIdCallback,</span></span></span><br><span class="line"><span class="params"><span class="function">                         requestLocal: RequestLocal = RequestLocal.NoCaching)</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (transactionalId == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 最终可以发现，producerId 是由 producerIdManager 来管理的。</span></span><br><span class="line">    val producerId = producerIdManager.generateProducerId()</span><br><span class="line">    responseCallback(InitProducerIdResult(producerId, producerEpoch = <span class="number">0</span>, Errors.NONE))</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionalId.isEmpty) &#123;</span><br><span class="line">      ...</span><br></pre></td></tr></table></figure>

<p>看代码可以发现 ProducerIdManager 是一个接口，它有两个实现类</p>
<ul>
<li>ZkProducerIdManager</li>
<li>RPCProducerIdManager</li>
</ul>
<p>ZkProducerIdManager 是通过 zk 来管理 producerId。</p>
<p>PID 端申请是向 ZooKeeper 申请，zk 中有一个 <code>latest_producer_id_block</code> 节点，每个 Broker 向 zk 申请一个 PID 段(默认情况下，每次申请 1000 个 PID)后，都会把自己申请的 PID 段信息写入到这个节点，这样当其他 Broker 再申请 PID 段时，会首先读写这个节点的信息，然后根据 block_end 选择一个 PID 段，最后再把信息写会到 zk 的这个节点，这个节点信息格式如下所示：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;version&quot;</span>:<span class="number">1</span>,<span class="attr">&quot;broker&quot;</span>:<span class="number">35</span>,<span class="attr">&quot;block_start&quot;</span>:<span class="string">&quot;4000&quot;</span>,<span class="attr">&quot;block_end&quot;</span>:<span class="string">&quot;4999&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>ProducerIdManager 申请 PID 段的流程如下：</p>
<ol>
<li>先从 zk 的 <code>latest_producer_id_block</code> 节点读取最新已经分配的 PID 段信息；</li>
<li>如果该节点不存在，直接从 0 开始分配，选择 0~1000 的 PID 段（ProducerIdManager 的 PidBlockSize 默认为 1000，即是每次申请的 PID 段大小）；</li>
<li>如果该节点存在，读取其中数据，根据 block_end 选择 这个 PID 段（如果 PID 段超过 Long 类型的最大值，这里会直接返回一个异常）；</li>
<li>在选择了相应的 PID 段后，将这个 PID 段信息写回到 zk 的这个节点中，如果写入成功，那么 PID 段就证明申请成功，如果写入失败（写入时会判断当前节点的 zkVersion 是否与步骤1获取的 zkVersion 相同，如果相同，那么可以成功写入，否则写入就会失败，证明这个节点被修改过），证明此时可能其他的 Broker 已经更新了这个节点（当前的 PID 段可能已经被其他 Broker 申请），那么从步骤 1 重新开始，直到写入成功。</li>
</ol>
<p>RPCProducerIdManager 是最新版本新实现的一个功能，新版本的kafka 移除zookeeper之后，producerId 将在控制器上分配。</p>
<h3 id="Sequence-Numbers"><a href="#Sequence-Numbers" class="headerlink" title="Sequence Numbers"></a>Sequence Numbers</h3><p>有了PID之后，在 PID+Partition 级别上再加上 sequence numbers 信息，就可以实现Producer的幂等性了。</p>
<p>ProducerBatch也提供了setProducerState() 方法（具体执行时机是在 RecordAccumulator 中的 drain 方法中），它可以给一个 batch 添加一些 meta 信息（pid、baseSequence、isTransactional），这些信息是会伴随着 ProduceRequest 发到 Server 端，Server 端也正是通过这些 meta 来做相应的判断。</p>
<h2 id="发送流程"><a href="#发送流程" class="headerlink" title="发送流程"></a>发送流程</h2><h3 id="客户端发送逻辑"><a href="#客户端发送逻辑" class="headerlink" title="客户端发送逻辑"></a>客户端发送逻辑</h3><p>当开通幂等功能之后，producer 的发送流程如下：</p>
<ol>
<li>客户端通过 KafkaProducer 的 send() 方法将数据添加到 RecordAccumulator 中，添加时会判断是否需要新建一个 ProducerBatch，这时这个 ProducerBatch 还是没有 PID 和 sequence number 信息的；</li>
<li>Producer 后台发送线程 Sender，在 run() 方法中，会先根据 TransactionManager 的 maybeResolveSequences() 方法判断当前的 PID 是否需要重置，重置的原因是因为：如果有 topic-partition 的 batch 重试多次失败最后因为超时而被移除，这时 sequence number 将无法做到连续，因为 sequence number 有部分已经分配出去，这时系统依赖自身的机制无法继续进行下去（因为幂等性是要保证不丢不重的），相当于程序遇到了一个 fatal 异常，PID 会进行重置，TransactionManager 相关的缓存信息被清空（Producer 不会重启），只是保存状态信息的 TransactionManager 做了 clear+new 操作，遇到这个问题时是无法保证 exactly once 的（有数据已经发送失败了，并且超过了重试次数）；</li>
<li>Sender 线程通过 bumpIdempotentEpochAndResetIdIfNeeded() 方法判断是否需要申请 PID，如果需要的话，会想服务端发送 InitProducerIdRequest</li>
<li>Sender 线程通过 sendProducerData() 方法发送数据，整体流程与之前的 Producer 流程相似，不同的地方是在 RecordAccumulator 的 drain() 方法中，在加了幂等性之后，drain() 方法多了如下几步判断：<ul>
<li>常规的判断：判断这个 topic-partition 是否可以继续发送（如果出现前面2中的情况是不允许发送的）、判断 PID 是否有效、如果这个 batch 是重试的 batch，那么需要判断这个 batch 之前是否还有 batch 没有发送完成，如果有，这里会先跳过这个 Topic-Partition 的发送，直到前面的 batch 发送完成，最坏情况下，这个 Topic-Partition 的 in-flight request 将会减少到1（这个涉及也是考虑到 server 端的一个设置，文章下面会详细分析）；</li>
<li>如果这个 ProducerBatch 还没有这个相应的 PID 和 sequence number 信息，会在这里进行相应的设置；</li>
</ul>
</li>
<li>最后 Sender 线程再调用 sendProduceRequests() 方法发送 ProduceRequest 请求，后面的就跟之前正常的流程保持一致了。</li>
</ol>
<h3 id="服务端处理逻辑"><a href="#服务端处理逻辑" class="headerlink" title="服务端处理逻辑"></a>服务端处理逻辑</h3><p>当 Broker 收到 ProduceRequest 请求之后，会通过 KafkaApis.handleProduceRequest() 做相应的处理，其处理流程如下（这里只讲述关于幂等性相关的内容）：</p>
<ol>
<li>先进行权限校验（这里还不是太理解校验权限的目的）<ul>
<li>如果请求是事务请求，检查是否对 TXN.id 有 Write 权限，没有的话返回 TRANSACTIONAL_ID_AUTHORIZATION_FAILED；</li>
<li>如果请求设置了幂等性，检查是否对 ClusterResource 有 IdempotentWrite 权限，没有的话返回 CLUSTER_AUTHORIZATION_FAILED；</li>
<li>验证对 topic 是否有 Write 权限以及 Topic 是否存在，否则返回 TOPIC_AUTHORIZATION_FAILED 或 UNKNOWN_TOPIC_OR_PARTITION 异常；</li>
</ul>
</li>
<li>检查是否有 PID 信息，没有的话走正常的写入流程；</li>
<li>UnifiedLog 对象会在 analyzeAndValidateProducerState()  方法先根据 batch 的 sequence number 信息检查这个 batch 是否重复（server 端会缓存 PID 对应这个 Topic-Partition 的最近5个 batch 信息），如果有重复，这里当做写入成功返回（不更新 LOG 对象中相应的状态信息，比如这个 replica 的 the end offset 等）；</li>
<li>有了 PID 信息，并且不是重复 batch 时，在更新 producer 信息时，会做以下校验：<ul>
<li>检查该 PID 是否已经缓存中存在</li>
<li>如果不存在，那么判断 sequence number 是否 从0 开始，是的话，在缓存中记录 PID 的 meta（PID，epoch， sequence number），并执行写入操作，否则返回 UnknownProducerIdException（PID 在 server 端已经过期或者这个 PID 写的数据都已经过期了，但是 Client 还在接着上次的 sequence number 发送数据）；</li>
<li>如果该 PID 存在，先检查 PID epoch 与 server 端记录的是否相同；</li>
<li>如果不同并且 sequence number 不从 0 开始，那么返回 OutOfOrderSequenceException 异常；</li>
<li>如果不同并且 sequence number 从 0 开始，那么正常写入；</li>
<li>如果相同，那么根据缓存中记录的最近一次 sequence number（currentLastSeq）检查是否为连续（会区分为 0、Int.MaxValue 等情况），不连续的情况下返回 OutOfOrderSequenceException 异常。</li>
</ul>
</li>
<li>下面与正常写入相同。</li>
</ol>
<p>幂等性时，Broker 在处理 ProduceRequest 请求时，多了一些校验操作，这里重点看一下其中一些重要实现，先看下 analyzeAndValidateProducerState() 方法的实现，如下所示：</p>
<blockquote>
<p>analyzeAndValidateProducerState() 到达路径：</p>
<ul>
<li>KafkaApis.handleProduceRequest()<ul>
<li>ReplicaManager.appendRecords() -&gt; appendToLocalLog() -&gt; appendRecordsToLeader()<ul>
<li>UnifiedLog.appendAsLeader() -&gt; append() -&gt; analyzeAndValidateProducerState</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<details class="tag-plugin folding" color="yellow" child="codeblock"><summary><span>analyzeAndValidateProducerState()</span></summary><div class="body"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">analyzeAndValidateProducerState</span><span class="params">(appendOffsetMetadata: LogOffsetMetadata,</span></span></span><br><span class="line"><span class="params"><span class="function">                                            records: MemoryRecords,</span></span></span><br><span class="line"><span class="params"><span class="function">                                            origin: AppendOrigin)</span>:</span></span><br><span class="line"><span class="function"><span class="params">(mutable.Map[Long, ProducerAppendInfo], List[CompletedTxn], Option[BatchMetadata])</span> </span>= &#123;</span><br><span class="line">  val updatedProducers = mutable.Map.empty[Long, ProducerAppendInfo]</span><br><span class="line">  val completedTxns = ListBuffer.empty[CompletedTxn]</span><br><span class="line">  <span class="keyword">var</span> relativePositionInSegment = appendOffsetMetadata.relativePositionInSegment</span><br><span class="line"></span><br><span class="line">  records.batches.forEach &#123; batch =&gt;</span><br><span class="line">    <span class="keyword">if</span> (batch.hasProducerId) &#123;</span><br><span class="line">      <span class="comment">// if this is a client produce request, there will be up to 5 batches which could have been duplicated.</span></span><br><span class="line">      <span class="comment">// If we find a duplicate, we return the metadata of the appended batch to the client.</span></span><br><span class="line">      <span class="keyword">if</span> (origin == AppendOrigin.Client) &#123;</span><br><span class="line">        val maybeLastEntry = producerStateManager.lastEntry(batch.producerId)</span><br><span class="line"></span><br><span class="line">        maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt;</span><br><span class="line">          <span class="keyword">return</span> (updatedProducers, completedTxns.toList, Some(duplicate))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// We cache offset metadata for the start of each transaction. This allows us to</span></span><br><span class="line">      <span class="comment">// compute the last stable offset without relying on additional index lookups.</span></span><br><span class="line">      val firstOffsetMetadata = <span class="keyword">if</span> (batch.isTransactional)</span><br><span class="line">        Some(LogOffsetMetadata(batch.baseOffset, appendOffsetMetadata.segmentBaseOffset, relativePositionInSegment))</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        None</span><br><span class="line"></span><br><span class="line">      val maybeCompletedTxn = updateProducers(producerStateManager, batch, updatedProducers, firstOffsetMetadata, origin)</span><br><span class="line">      maybeCompletedTxn.foreach(completedTxns += _)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    relativePositionInSegment += batch.sizeInBytes</span><br><span class="line">  &#125;</span><br><span class="line">  (updatedProducers, completedTxns.toList, None)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></details>

<p>如果这个 batch 有 PID 信息，会首先检查这个 batch 是否为重复的 batch 数据，其实现如下，batchMetadata 会缓存最新 5个 batch 的数据（如果超过5个，添加时会进行删除，这个也是幂等性要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5 的原因，与这个值的设置有关），根据 batchMetadata 缓存的 batch 数据来判断这个 batch 是否为重复的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">findDuplicateBatch</span><span class="params">(batch: RecordBatch)</span>: Option[BatchMetadata] </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (batch.producerEpoch != producerEpoch)</span><br><span class="line">     <span class="function">None</span></span><br><span class="line"><span class="function">  <span class="keyword">else</span></span></span><br><span class="line"><span class="function">    <span class="title">batchWithSequenceRange</span><span class="params">(batch.baseSequence, batch.lastSequence)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// Return the batch metadata of the cached batch having the exact sequence range, if any.</span></span></span><br><span class="line"><span class="function">def <span class="title">batchWithSequenceRange</span><span class="params">(firstSeq: Int, lastSeq: Int)</span>: Option[BatchMetadata] </span>= &#123;</span><br><span class="line">  val duplicate = batchMetadata.filter &#123; metadata =&gt;</span><br><span class="line">    firstSeq == metadata.firstSeq &amp;&amp; lastSeq == metadata.lastSeq</span><br><span class="line">  &#125;</span><br><span class="line">  duplicate.headOption</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">addBatchMetadata</span><span class="params">(batch: BatchMetadata)</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (batchMetadata.size == ProducerStateEntry.NumBatchesToRetain)</span><br><span class="line">    batchMetadata.dequeue() <span class="comment">//note: 只会保留最近 5 个 batch 的记录</span></span><br><span class="line">  batchMetadata.enqueue(batch) <span class="comment">//note: 添加到 batchMetadata 中记录，便于后续根据 seq id 判断是否重复</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果 batch 不是重复的数据，analyzeAndValidateProducerState() 会通过 updateProducers() 更新 producer 的相应记录，在更新的过程中，会做一步校验，校验方法如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 检查 seq number</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> def <span class="title">checkSequence</span><span class="params">(producerEpoch: Short, appendFirstSeq: Int)</span>: Unit </span>= &#123;</span><br><span class="line">  <span class="keyword">if</span> (producerEpoch != updatedEntry.producerEpoch) &#123; <span class="comment">//note: epoch 不同时</span></span><br><span class="line">    <span class="keyword">if</span> (appendFirstSeq != <span class="number">0</span>) &#123; <span class="comment">//note: 此时要求 seq number 必须从0开始（如果不是的话，pid 可能是新建的或者 PID 在 Server 端已经过期）</span></span><br><span class="line">      <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 不是-1，证明时原来的 pid 过期了）</span></span><br><span class="line">      <span class="keyword">if</span> (updatedEntry.producerEpoch != RecordBatch.NO_PRODUCER_EPOCH) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OutOfOrderSequenceException(s<span class="string">&quot;Invalid sequence number for new epoch: $producerEpoch &quot;</span> +</span><br><span class="line">          s<span class="string">&quot;(request epoch), $appendFirstSeq (seq. number)&quot;</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">//note: pid 已经过期（updatedEntry.producerEpoch 为-1，证明 server 端 meta 新建的，PID 在 server 端已经过期，client 还在接着上次的 seq 发数据）</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnknownProducerIdException(s<span class="string">&quot;Found no record of producerId=$producerId on the broker. It is possible &quot;</span> +</span><br><span class="line">          s<span class="string">&quot;that the last message with t（）he producerId=$producerId has been removed due to hitting the retention limit.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    val currentLastSeq = <span class="keyword">if</span> (!updatedEntry.isEmpty)</span><br><span class="line">      updatedEntry.<span class="function">lastSeq</span></span><br><span class="line"><span class="function">    <span class="keyword">else</span> <span class="title">if</span> <span class="params">(producerEpoch == currentEntry.producerEpoch)</span></span></span><br><span class="line"><span class="function">      currentEntry.lastSeq</span></span><br><span class="line"><span class="function">    <span class="keyword">else</span></span></span><br><span class="line"><span class="function">      RecordBatch.NO_SEQUENCE</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="params">(currentLastSeq == RecordBatch.NO_SEQUENCE &amp;&amp; appendFirstSeq != <span class="number">0</span>)</span> </span>&#123;</span><br><span class="line">      <span class="comment">//note: 此时期望的 seq number 是从 0 开始,因为 currentLastSeq 是 -1,也就意味着这个 pid 还没有写入过数据</span></span><br><span class="line">      <span class="comment">// the epoch was bumped by a control record, so we expect the sequence number to be reset</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> OutOfOrderSequenceException(s<span class="string">&quot;Out of order sequence number for producerId $producerId: found $appendFirstSeq &quot;</span> +</span><br><span class="line">        s<span class="string">&quot;(incoming seq. number), but expected 0&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!inSequence(currentLastSeq, appendFirstSeq)) &#123;</span><br><span class="line">      <span class="comment">//note: 判断是否连续</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> OutOfOrderSequenceException(s<span class="string">&quot;Out of order sequence number for producerId $producerId: $appendFirstSeq &quot;</span> +</span><br><span class="line">        s<span class="string">&quot;(incoming seq. number), $currentLastSeq (current end sequence number)&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><ol>
<li>Producer 在设置幂等性时，为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5，如果设置大于 5（不考虑 Producer 端参数校验的报错），会带来什么后果？</li>
<li>Producer 在设置幂等性时，如果我们设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，那么是否可以保证有序，如果可以，是怎么做到的？</li>
</ol>
<h3 id="为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5"><a href="#为什么要求-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-小于等于5" class="headerlink" title="为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5"></a>为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5</h3><p>之所以要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5 的主要原因是：</p>
<p>Server 端的 ProducerStateManager 实例会缓存每个 PID 在 Topic-Partition 上发送的最近 5 个batch 数据（这个 5 是写死的，至于为什么是 5，可能跟经验有关，当不设置幂等性时，当这个设置为 5 时，性能相对来说较高，社区是有一个相关测试文档，忘记在哪了），如果超过 5，ProducerStateManager 就会将最旧的 batch 数据清除。</p>
<p>假设应用将 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 6，假设发送的请求顺序是 1、2、3、4、5、6，这时候 server 端只能缓存 2、3、4、5、6 请求对应的 batch 数据，这时候假设请求 1 发送失败，需要重试，当重试的请求发送过来后，首先先检查是否为重复的 batch，这时候检查的结果是否，之后会开始 check 其 sequence number 值，这时候只会返回一个 OutOfOrderSequenceException 异常，client 在收到这个异常后，会再次进行重试，直到超过最大重试次数或者超时，这样不但会影响 Producer 性能，还可能给 Server 带来压力</p>
<h3 id="当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序"><a href="#当-MAX-IN-FLIGHT-REQUESTS-PER-CONNECTION-配置大于1时，是否保证有序" class="headerlink" title="当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序"></a>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序</h3><p>先来分析一下，在什么情况下 Producer 会出现乱序的问题？</p>
<p>没有幂等性时，乱序的问题是在重试时出现的，举个例子：client 依然发送了 6 个请求 1、2、3、4、5、6（它们分别对应了一个 batch），这 6 个请求只有 2-6 成功 ack 了，1 失败了，这时候需要重试，重试时就会把 batch 1 的数据添加到待发送的数据列队中），那么下次再发送时，batch 1 的数据将会被发送，这时候数据就已经出现了乱序，因为 batch 1 的数据已经晚于了 batch 2-6。</p>
<p>当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 1 时，是可以解决这个问题的，因为同时只允许一个请求正在发送，只有当前的请求发送完成（成功 ack 后），才能继续下一条请求的发送，类似单线程处理这种模式，每次请求发送时都会等待上次的完成，效率非常差，但是可以解决乱序的问题（当然这里有序只是针对单 client 情况，多 client 并发写是无法做到的）。</p>
<p>系统能提供的方案，基本上就是有序性与性能之间二选一，无法做到兼容，实际上系统出现请求重试的几率是很小的（一般都是网络问题触发的），可能连 0.1% 的时间都不到，但是就是为了这 0.1% 时间都不到的情况，应用需要牺牲性能问题来解决，在大数据场景下，我们是希望有更友好的方式来解决这个问题。简单来说，就是当出现重试时，max-in-flight-request 可以动态减少到 1，在正常情况下还是按 5 （5是举例说明）来处理，这有点类似于分布式系统 CAP 理论中关于 P 的考虑，当出现问题时，可以容忍性能变差，但是其他的情况下，我们希望的是能拥有原来的性能，而不是一刀切。令人高兴的，在 Kafka 2.0.0 版本中，如果 Producer 开始了幂等性，Kafka 是可以做到这一点的，如果不开启幂等性，是无法做到的，因为它的实现是依赖了 sequence number。</p>
<p>当请求出现重试时，batch 会重新添加到队列中，这时候是根据 sequence number 添加到队列的合适位置（有些 batch 如果还没有 sequence number，那么就保持其相对位置不变），也就是队列中排在这个 batch 前面的 batch，其 sequence number 都比这个 batch 的 sequence number 小，其实现如下，这个方法保证了在重试时，其 batch 会被放到合适的位置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Re-enqueue the given record batch in the accumulator to retry</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reenqueue</span><span class="params">(ProducerBatch batch, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    batch.reenqueued(now); <span class="comment">//note: 重试,更新相应的 meta</span></span><br><span class="line">    Deque&lt;ProducerBatch&gt; deque = getOrCreateDeque(batch.topicPartition);</span><br><span class="line">    <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>)</span><br><span class="line">            insertInSequenceOrder(deque, batch); <span class="comment">//note: 将 batch 添加到队列的合适位置（根据 seq num 信息）</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            deque.addFirst(batch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另外 Sender 在发送请求时，会首先通过 RecordAccumulator 的 drain() 方法获取其发送的数据，在遍历 Topic-Partition 对应的 queue 中的 batch 时，如果发现 batch 已经有了 sequence number 的话，则证明这个 batch 是重试的 batch，因为没有重试的 batch 其 sequence number 还没有设置，这时候会做一个判断，会等待其 in-flight-requests 中请求发送完成，才允许再次发送这个 Topic-Partition 的数据，其判断实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldStopDrainBatchesForPartition</span><span class="params">(ProducerBatch first, TopicPartition tp)</span> </span>&#123;</span><br><span class="line">    ProducerIdAndEpoch producerIdAndEpoch = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!transactionManager.isSendToPartitionAllowed(tp))</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">        producerIdAndEpoch = transactionManager.producerIdAndEpoch();</span><br><span class="line">        <span class="keyword">if</span> (!producerIdAndEpoch.isValid())</span><br><span class="line">            <span class="comment">// we cannot send the batch until we have refreshed the producer id</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!first.hasSequence()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (transactionManager.hasInflightBatches(tp) &amp;&amp; transactionManager.hasStaleProducerIdAndEpoch(tp)) &#123;</span><br><span class="line">                <span class="comment">// Don&#x27;t drain any new batches while the partition has in-flight batches with a different epoch</span></span><br><span class="line">                <span class="comment">// and/or producer ID. Otherwise, a batch with a new epoch and sequence number</span></span><br><span class="line">                <span class="comment">// 0 could be written before earlier batches complete, which would cause out of sequence errors</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (transactionManager.hasUnresolvedSequence(first.topicPartition))</span><br><span class="line">                <span class="comment">// Don&#x27;t drain any new batches while the state of previous sequence numbers</span></span><br><span class="line">                <span class="comment">// is unknown. The previous batches would be unknown if they were aborted</span></span><br><span class="line">                <span class="comment">// on the client after being sent to the broker at least once.</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 inFlightBatches 中第一个 batch 的 baseSequence, inFlightBatches 为 null 的话返回 RecordBatch.NO_SEQUENCE</span></span><br><span class="line">        <span class="keyword">int</span> firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition);</span><br><span class="line">        <span class="keyword">if</span> (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence()</span><br><span class="line">            &amp;&amp; first.baseSequence() != firstInFlightSequence)</span><br><span class="line">            <span class="comment">//重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight</span></span><br><span class="line">            <span class="comment">//queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）,</span></span><br><span class="line">            <span class="comment">//会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition）</span></span><br><span class="line">            <span class="comment">//这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义</span></span><br><span class="line">            <span class="comment">//这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送</span></span><br><span class="line">            <span class="comment">// If the queued batch already has an assigned sequence, then it is being retried.</span></span><br><span class="line">            <span class="comment">// In this case, we wait until the next immediate batch is ready and drain that.</span></span><br><span class="line">            <span class="comment">// We only move on when the next in line batch is complete (either successfully or due to</span></span><br><span class="line">            <span class="comment">// a fatal broker error). This effectively reduces our in flight request count to 1.</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>仅有 client 端这两个机制还不够，Server 端在处理 ProduceRequest 请求时，还会检查 batch 的 sequence number 值，它会要求这个值必须是连续的，如果不连续都会返回异常，Client 会进行相应的重试，举个栗子：假设 Client 发送的请求顺序是 1、2、3、4、5（分别对应了一个 batch），如果中间的请求 2 出现了异常，那么会导致 3、4、5 都返回异常进行重试（因为 sequence number 不连续），也就是说此时 2、3、4、5 都会进行重试操作添加到对应的 queue 中。</p>
<p>Producer 的 TransactionManager 实例的 TopicPartitionEntry.inflightBatchesBySequence 成员变量会维护这个 Topic-Partition 与目前正在发送的 batch 的对应关系（通过 addInFlightBatch() 方法添加 batch 记录），只有这个 batch 成功 ack 后，才会通过 removeInFlightBatch() 方法将这个 batch 从 inflightBatchesBySequence 中移除。</p>
<p>接着前面的例子，此时 inflightBatchesBySequence 中还有 2、3、4、5 这几个 batch（有顺序的，2 在前面），根据前面的 RecordAccumulator 的 drain() 方法可以知道只有这个 Topic-Partition 下次要发送的 batch 是 batch 2（跟 transactionManager 的这个 firstInFlightSequence() 方法获取 inFlightBatches 中第一个 batch 的 baseSequence 来判断） 时，才可以发送，否则会直接 break，跳过这个 Topic-Partition 的数据发送。这里相当于有一个等待，等待 batch 2 重新加入到 queue 中，才可以发送，不能跳过 batch 2，直接重试 batch 3、4、5，这是不允许的。</p>
<p>简单来说，其实现机制概括为：</p>
<ol>
<li>Server 端验证 batch 的 sequence number 值，不连续时，直接返回异常；</li>
<li>Client 端请求重试时，batch 在 reenqueue 时会根据 sequence number 值放到合适的位置（有序保证之一）；</li>
<li>Sender 线程发送时，在遍历 queue 中的 batch 时，会检查这个 batch 是否是重试的 batch，如果是的话，只有这个 batch 是最旧的那个需要重试的 batch，才允许发送，否则本次发送跳过这个 Topic-Partition 数据的发送等待下次发送。</li>
</ol>


<div class="article-footer reveal fs14"><section id="references"><div class="header"><span>References</span></div><div class="body"><ul><li class="post-title"><a href="http://matt33.com/2018/10/24/kafka-idempotent/#%E5%B9%82%E7%AD%89%E6%80%A7%E5%AE%9E%E7%8E%B0%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B" target="_blank" rel="external nofollow noopener noreferrer">Matt's Blog - Kafka 事务性之幂等性实现</a></li></ul></div></section><section id="license"><div class="header"><span>License</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">Newer</div><a href="/kafka/kafka-optimization/">Kafka 系列(七)：kafka 对性能的优化</a></div><div class="item" id="next"><div class="note">Older</div><a href="/kafka/kafka-reliability/">Kafka 系列(五)：如何保障数据可靠性？</a></div></section></div>






  <div class='related-wrap md-text reveal' id="comments">
    <div class='cmt-title cap theme'>
      Join the discussion
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="gaoyanliang/beaudar" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs14">Blog</span><a href="/">Recent Update</a><a href="/blog/categories/">Categories</a><a href="/blog/tags/">Tags</a><a href="/blog/archives/">Archives</a></div><div class="sitemap-group"><span class="fs14">Wiki</span><a href="/wiki/tags/%E6%8A%80%E6%9C%AF%E5%8A%A0%E6%B2%B9%E7%AB%99/">技术加油站</a><a href="/wiki/">...</a></div><div class="sitemap-group"><span class="fs14">Social</span><a href="/friends/">Friends</a><a href="/about/#comments">Comments</a><a target="_blank" rel="noopener" href="https://open.spotify.com/">Spotify</a></div><div class="sitemap-group"><span class="fs14">More</span><a href="/about/">About</a><a href="/wiki/resume">Resume</a><a target="_blank" rel="noopener" href="https://github.com/gyl-coder">GitHub</a></div></div><div class="text"><p>本站由 <a href="/">@yanliang</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.17.2';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.17.2';
  stellar.config = {
    date_suffix: {
      just: 'Just',
      min: 'minutes ago',
      hour: 'hours ago',
      day: 'days ago',
      month: 'months ago',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js"});
  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  
  // -------- start 自定义首页文章轮播
  if ('true' == 'true') {
    stellar.plugins.customSwiperTopArticle = Object.assign({"enable":true,"css":"https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@main/css/swiper/swiper.min.css","js":"https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@main/js/swiper/swiper.min.js","init_js":"https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@main/js/swiper/swiper_init.js"});
  }
  // -------- end 自定义首页文章轮播

  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://fastly.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://fastly.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://fastly.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
