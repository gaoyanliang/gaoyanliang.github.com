[{"title":"聊聊 Kubernetes","path":"/cloud_native/kubernetes/","content":"1. 什么是 kubernetesKubernetes，它是一个全新的基于容器技术的分布式架构方案，近些年在容器领域使用非常广泛，作为容器化部署实施的典型方案。 Kubernetes 是用于自动部署，扩展和管理容器化应用程序的开源系统，它将组成应用程序的容器组合成逻辑单元，以便于管理和服务发现。 Kubernetes，构建在 Docker 技术之上，为跨主机的容器化应用提供资源调度、服务发现、高可用管理和弹性伸缩等一整套功能，它提供了完善的管理工具，涵盖开发、部署测试、运维监控等各个环节。它的目标不仅仅是一个编排系统，更是提供一个规范，可以让你来描述集群的架构，定义服务的最终状态，Kubernetes可以帮你将系统自动达到和维持在这个状态。 2. 特性 服务发现与负载均衡： 无需修改您的应用程序即可使用陌生的服务发现机制。Kubernetes 为容器提供了自己的 IP 地址和一个 DNS 名称，并且可以在它们之间实现负载均衡。 自我修复： 重新启动失败的容器，在节点死亡时替换并重新调度容器，杀死不响应用户定义的健康检查的容器，并且在它们准备好服务之前不会将它们公布给客户端。 自动化上线和回滚： Kubernetes 会分步骤地将针对应用或其配置的更改上线，同时监视应用程序运行状况以确保你不会同时终止所有实例。如果出现问题，Kubernetes 会为你回滚所作更改。你应该充分利用不断成长的部署方案生态系统。 自动装箱： 根据资源需求和其他约束自动放置容器，同时避免影响可用性。将关键性工作负载和尽力而为性质的服务工作负载进行混合放置，以提高资源利用率并节省更多资源。 IPv4/IPv6 双协议栈： 为 Pod 和 Service 分配 IPv4 和 IPv6 地址。 水平扩缩： 使用一个简单的命令、一个 UI 或基于 CPU 使用情况自动对应用程序进行扩缩。 Service 拓扑： 基于集群拓扑的服务流量路由。可以让一个服务基于集群的Node拓扑进行流量路由。例如，一个服务可以指定流量是被优先路由到一个和客户端在同一个Node或者在同一可用区域的端点。 端点切片： Kubernetes 集群中网络端点的可扩展跟踪。 存储编排： 自动挂载所选存储系统，包括本地存储、诸如 GCP 或 AWS 之类公有云提供商所提供的存储或者诸如 NFS、iSCSI、Gluster、Ceph、Cinder 或 Flocker 这类网络存储系统。 Secret 和配置管理： 部署和更新 Secrets 和应用程序的配置而不必重新构建容器镜像，且不必将软件堆栈配置中的秘密信息暴露出来。 批量执行： 除了服务之外，Kubernetes 还可以管理你的批处理和 CI 工作负载，在期望时替换掉失效的容器。 3. 亮点3.1 一切以服务（Service）为中心Kubernetes以“一切以服务（Service）为中心，一切围绕服务运转”作为指导思想的创新型产品。 它在功能和架构设计上始终遵循着这一指导思想，构建在Kubernetes上的系统不仅可以独立运行在物理机、虚拟机集群或企业私有云上，也可以被托管在公有云上。 3.2 开放的开发平台Kubernetes是一个开放的开发平台。与 J2EE 不同，它不局限于任何一种语言，没有限定任何编程接口，所以不论是用 Java、Go、C++还是 Python 编写的程序，都可以被映射为Kubernetes的 Service，并通过标准的 TCP 通讯协议进行交互。此外，Kubernetes平台对现有的编程语言、编程框架、中间件没有任何侵入性，做到了零侵入，因此现有的系统也很容易改造升级并迁移到Kubernetes平台之上。 3.3 自动化Kubernetes的另一个亮点是自动化。在Kubernetes的解决方案中，一个可以自我扩展、自我诊断，并且容易升级，在收到服务扩容的请求后，Kubernetes会触发调度流程，最终在选定的目标节点上启动相应数据的服务实例副本，这些服务实例副本在启动成功后会自动加入负载均衡器中并生效，整个过程无须额外的人工操作。 另外，Kubernetes会定时巡查每个服务的所有实例的可用性，确保服务实例的数量始终保持为预期的数量，当它发现某个实例不可用时，会自动重启该实例或者其他节点上重新调度、运行一个新实例，这样一个复杂的过程无须人工干预即可全部自动完成。 3.4 分布式系统支撑平台Kubernetes是一个完备的分布式系统支撑平台。具备完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建的智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。 同时，Kubernetes提供了完善的管理工具，这些涵盖了包括开发、部署测试、运维监控在内的各个环节。因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支持平台。 随着容器化部署环境限制、语言差异、容器数量的庞大、负载均衡、故障检测、故障修复等问题，倘若将过多的精力、时间放在这些地方，其工作量将会多大，将会让很多企业、产品对容器望而止步。 在容器化的时代，Kubernetes足以免去上述面临的问题，让容器化使用变得的更加容易、轻松，只需花费更多的时间去完成业务功能的开发。 4. 为什么使用 kubernetes使用Kubernetes的理由很多，最重要的理由是，IT 行业从来都是由新技术驱动的。 4.1 一个平台搞定所有使用 Kubernetes部署任何应用都是小菜一碟。只要应用可以打包成镜像，能够容器部署，Kubernetes就一定能启动它。 不管什么语言、什么框架写的应用（如：Java, Python, Node.js），Kubernetes都可以在任何环境中安全的启动它，如：物理服务器、虚拟机、云环境。 4.2 云环境无缝迁移如果你有换云环境的需求，例如从 GCP 到 AWS，使用Kubernetes的话，你就不用有任何担心。 Kubernetes完全兼容各种云服务提供商，例如 Google Cloud、Amazon、Microsoft Azure，还可以工作在 CloudStack, OpenStack, OVirt, Photon, VSphere等。 4.3 高效的利用资源看下图，左边是 4 个虚拟机，黄色和蓝色部分是运行的应用，白色部分是未使用的内存和处理器资源。 右边，同样的应用打包运行在容器中。 Kubernetes如果发现有节点工作不饱和，便会重新分配pod，帮助我们节省开销，高效的利用内存、处理器等资源。 如果一个节点宕机了，Kubernetes会自动重新创建之前运行在此节点上的pod，在其他节点上运行。 4.4 开箱即用的自动缩放能力网络、负载均衡、复制等特性，对于Kubernetes都是开箱即用的。 pod 是无状态运行的，任何时候有 pod 宕了，立马会有其他 pod 接替它的工作，用户完全感觉不到。 如果用户量突然暴增，现有的 pod 规模不足了，那么会自动创建出一批新的 pod，以适应当前的需求。 反之亦然，当负载降下来的时候，Kubernetes也会自动缩减 pod 的数量。 4.5 使 CI/CD 更简单你不必精通于Chef 和 Ansible这类工具，只需要对 CI 服务写个简单的脚本然后运行它，就会使用你的代码创建一个新的 pod，并部署到 Kubernetes集群里面。 应用打包在容器中使其可以安全的运行在任何地方，例如你的 PC、一个云服务器，使得测试极其简单。 4.6 可靠性Kubernetes如此流行的一个重要原因是：应用会一直顺利运行，不会被 pod 或节点的故障所中断。 如果出现故障，Kubernetes会创建必要数量的应用镜像，并分配到健康的 pod 或节点中，直到系统恢复。 而且用户不会感到任何不适。 一个容器化的基础设施是有自愈能力的，可以提供应用程序的不间断操作，即使一部分基础设施出现故障。 kubernetes 组件当你部署完 Kubernetes，便拥有了一个完整的集群。 一组工作机器，称为 节点， 会运行容器化应用程序。每个集群至少有一个工作节点。 工作节点会托管 Pod ，而 Pod 就是作为应用负载的组件。 控制平面管理集群中的工作节点和 Pod。 在生产环境中，控制平面通常跨多台计算机运行， 一个集群通常运行多个节点，提供容错性和高可用性。 更详细的介绍参考：Kubernetes 组件","tags":["云原生","kubernetes"],"categories":["云原生","kubernetes"]},{"title":"何谓云原生？","path":"/cloud_native/cloud_native/","content":"什么是云原生不同的企业对于云原生有不同的解释，当前在业界具有广泛影响力的云原生计算基金会（Cloud Native Computing Foundation,CNCF）认为，云原生是一类技术的统称，通过云原生技术，我们可以构建出更易于弹性扩展的应用程序，这些应用可以被运行在不同的环境当中，比如说私有云、公有云、混合云、还有多云的场景。 通过云原生技术构建出来的应用程序，称之为云原生应用，底层基础架构的耦合比较轻，因此易于迁移，它可以充分地利用云所提供的能力，因此云原生应用的开发、部署、管理相对于传统的应用程序更加高效和便捷。 云原生涉及到许多技术领域，每一个技术领域都有相应的工具、框架与平台，来帮助落地具体的应用。 云原生主要包含了当前业界的一些热门的技术，比如容器、微服务、DevOps，服务网格、Serverless、API管理、不可变基础架构等。 CNCF维护了一个 云原生技术全景图，在其中收集了和云原生技术相关的工具、平台和项目，全景图的内容十分丰富，可谓种类繁多、琳琅满目。通过这个云原生全景图可以快速地了解到每一个技术领域当中流行的工具。 云原生的作用对于应用开发团队而言，原来云原生技术可以提升应用开发的效率，提升应用交付的质量。比如通过容器，技术开发团队可以更容易地获取开发所需要的环境与资源，开发出来的应用可以被运维团队更容易地部署和管理。通过DevOps的最佳实践，应用交付的速度和质量可以被有效的提升。 对于业务方来说，云原生的好处是所提交的需求，可以更快地被响应和实现。因为云原生技术可以有效地缩短应用交付的周期，让需求更快地变成代码，代码更快地变成线上的应用，最终为用户服务，实现价值。云原生应用可以更好地弹性扩展，满足不同业务的需求。例如容器应用提供的应用自愈能力，可以帮助减少应用的停机时间提升用户的体验。 云原生技术可以提升应用开发的交付效率，缩短应用上线所需要的时间，开发和业务团队人员可以有更多的时间和精力进行业务创新，有效地提升团队的创新能力，从而提升企业在市场的竞争能力。 如何使用云原生当一个企业拥抱云原生技术，具体要在什么方面来落实？ CNCF有一个建议的技术路线图（CNCF trail map）。这个图上列出了10个方面，比如说通过应用容器化，使得应用更易于迁移的交付，通过持续集成的区域部署提升云原生软件的质量，通过容器编排简化应用的部署。","tags":["云原生"],"categories":["云原生"]},{"title":"Go 系列(二)：context 源码分析","path":"/go/context/","content":"本文主要简单介绍了 Go 语言 (golang) 中的context包。给出了 context 的基本用法和使用建议，并从源码层面对其底层结构和具体实现原理进行分析。 以下分析基于 Go 1.17.1 1. 概述1.1 什么是 context上下文 context.Context在 Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。上下文与 Goroutine 有比较密切的关系，是 Go 语言中独特的设计，在其他编程语言中我们很少见到类似的概念。 context 用来解决 goroutine 之间退出通知、数据传递的功能。 注：这里的数据传递主要指全局数据，如 链路追踪里的 traceId 之类的数据，并不是普通的参数传递 (也非常不推荐用来传递参数)。 1.2 设计原理因为context.Context主要作用就是进行超时控制，然后外部程序监听到超时后就可以停止执行任务，取消 Goroutine。 网上有很多用 Context 来取消 Goroutine 的字眼，初学者 (比如笔者) 可能误会，以为 Context 可以直接取消 Goroutine。 实际，Context 只是完成了一个信号的传递，具体的取消逻辑需要由程序自己监听这个信号，然后手动处理。 Go 语言中的 Context 通过构建一颗 Context 树，从而将没有层级的 Goroutine 关联起来。如下图所示： 所有 Context 都依赖于 BackgroundCtx 或者 TODOCtx，其实这二者都是一个 emptyCtx，只是语义上不一样。 在超时或者手动取消的时候信号都会从最顶层的 Goroutine 一层一层传递到最下层。这样该 Context 关联的所有 Goroutine 都能收到信号，然后进入自定义的退出逻辑。 比如这里手动取消了 ctxB1，然后 ctxB1 的两个子 ctx(C1 和 C2) 也会收到取消信号，这样 3 个 Goroutine 都能收到取消信号进行退出了。 1.3 使用场景最常见的就是 后台 HTTP/RPC Server。 在 Go 的 server 里，通常每来一个请求都会启动若干个 goroutine 同时工作：有些去数据库拿数据，有些调用下游接口获取相关数据, 具体如下图： 而客户端一般不会无限制的等待，都会被请求设定超时时间，比如 100ms。 比如这里 GoroutineA 消耗 80ms，GoroutineB3 消耗 30ms，已经超时了，那么后续的 GoroutineCDEF 都没必要执行了，客户端已经超时返回了，服务端就算计算出结果也没有任何意义了。 所以这里就可以使用 Context 来在多个 Goroutine 之间进行超时信号传递。 同时引入超时控制后有两个好处： 1）客户端可以快速返回，提升用户体验 2）服务端可以减少无效的计算 2. 使用案例2.1 WithCancel返回一个可以手动取消的 Context，手动调用 cancel() 方法以取消该 context。 123456789101112131415161718192021222324252627282930313233343536// 启动一个 worker goroutine 一直产生随机数，知道找到满足条件的数时，手动调用 cancel 取消 ctx，让 worker goroutine 退出func main() &#123; rand.Seed(time.Now().UnixNano()) ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*100) // defer cancel() // 一般推荐 defer 中调用cancel() ret := make(chan int) go RandWithCancel(ctx, ret) for r := range ret &#123; // 当找到满足条件的数时就退出 if r ==20 &#123; fmt.Println(&quot;find r:&quot;, r) break &#125; &#125; cancel() // 这里测试就手动调用cancel() 取消context time.Sleep(time.Second) // sleep 等待 worker goroutine 退出&#125;func RandWithCancel(ctx context.Context, ret chan int) &#123; defer close(ret) timer := time.NewTimer(time.Millisecond) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;ctx cancel&quot;) timer.Stop() return case &lt;-timer.C: r := rand.Intn(100) ret &lt;- r timer.Reset(time.Millisecond) &#125; &#125;&#125; 2.2 WithDeadline &amp; WithTimeout可以自定义超时时间，时间到了自动取消 context。 其实 WithTimeout 就是对 WithDeadline 的一个封装： 123func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; 1234567891011121314151617181920212223242526272829303132333435// 启动一个 worker goroutine 一直产生随机数，直到 ctx 超时后退出func main() &#123; rand.Seed(time.Now().UnixNano()) // ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*100) ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Millisecond*100)) // defer cancel() // 一般推荐 defer 中调用cancel() ret := make(chan int) go RandWithTimeout(ctx, ret) for r := range ret &#123; // 当找到满足条件的数时就退出 if r == 20 &#123; fmt.Println(&quot;find r:&quot;, r) break &#125; &#125; cancel() // 这里测试就手动调用cancel() 取消context time.Sleep(time.Second) // sleep 等待 worker goroutine 退出&#125;func RandWithTimeout(ctx context.Context, ret chan int) &#123; defer close(ret) timer := time.NewTimer(time.Millisecond) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;ctx cancel&quot;) timer.Stop() return case &lt;-timer.C: r := rand.Intn(100) ret &lt;- r timer.Reset(time.Millisecond) &#125; &#125;&#125; 在这个案例中，因为限制了超时时间，所以并不是每次都能找到满足条件的 r 值。 2.3 WithValue可以传递数据的 context，携带关键信息，为全链路提供线索，比如接入 elk 等系统，需要来一个 trace_id，那 WithValue 就非常适合做这个事。 1234567891011121314151617181920212223242526272829303132333435// 通过 ctx 进行超时控制的同时，在 ctx 中存放 traceId 进行链路追踪。func main() &#123; withTimeout, cancel := context.WithTimeout(context.Background(), time.Millisecond*1) defer cancel() ctx := context.WithValue(withTimeout, &quot;traceId&quot;, &quot;id12345&quot;) r := f1(ctx) fmt.Println(&quot;r:&quot;, r)&#125;func f1(ctx context.Context) int &#123; fmt.Println(&quot;f1 traceId:&quot;, fromCtx(ctx)) var ret = make(chan int, 1) go f2(ctx, ret) r1 := rand.Intn(10) fmt.Println(&quot;r1:&quot;, r1) select &#123; case &lt;-ctx.Done(): return r1 case r2 := &lt;-ret: return r1 + r2 &#125;&#125;func f2(ctx context.Context, ret chan int) &#123; fmt.Println(&quot;f2 traceId:&quot;, fromCtx(ctx)) // sleep 模拟耗时逻辑 time.Sleep(time.Millisecond * 10) r2 := rand.Intn(10) fmt.Println(&quot;r2:&quot;, r2) ret &lt;- r2&#125;func fromCtx(ctx context.Context) string &#123; return ctx.Value(&quot;traceId&quot;).(string)&#125; 为了进行超时控制，本就需要在多个 goroutine 之前传递 ctx，所以把 traceId 这种信息存放到 ctx 中是非常方便的。 3. 源码分析Context 在 Go 1.7 版本引入标准库中，主要内容可以概括为： 1 个接口 Context 4 种实现 emptyCtx cancelCtx timerCtx valueCtx 6 个方法 Background TODO WithCancel WithDeadline WithTimeout WithValue 整体类图如下： 3.1 1 个接口12345678910111213type Context interface &#123; // 当 context 被取消或者到了 deadline，返回一个被关闭的 channel Done() &lt;-chan struct&#123;&#125; // 在 channel Done 关闭后，返回 context 取消原因 Err() error // 返回 context 是否会被取消以及自动取消时间（即 deadline） Deadline() (deadline time.Time, ok bool) // 获取 key 对应的 value Value(key interface&#123;&#125;) interface&#123;&#125;&#125; Context 是一个接口，定义了 4 个方法，它们都是幂等的。也就是说连续多次调用同一个方法，得到的结果都是相同的。 Done()： 返回一个 只读channel，可以表示 context 被取消的信号：当这个 channel 被关闭时，说明 context 被取消了。读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 receive-only 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。 Err()： 返回一个错误，表示 channel 被关闭的原因。例如是被取消，还是超时。 Deadline()： 返回 context 的截止时间，通过此时间，函数就可以决定是否进行接下来的操作，如果时间太短，就可以不往下做了，否则浪费系统资源。当然，也可以用这个 deadline 来设置一个 I/O 操作的超时时间。 Value(key)：返回 key 对应的 value，是协程安全的 同时包中也定义了提供 cancel 功能需要实现的接口。这个主要是后文会提到的 “取消信号、超时信号” 需要去实现。 123456// A canceler is a context type that can be canceled directly. The// implementations are *cancelCtx and *timerCtx.type canceler interface &#123; cancel(removeFromParent bool, err error) Done() &lt;-chan struct&#123;&#125;&#125; 实现了上面定义的两个方法的 Context，就表明该 Context 是可取消的。源码中有两个类型实现了 canceler 接口：*cancelCtx 和 *timerCtx。注意是加了 * 号的，是这两个结构体的指针实现了 canceler 接口。 Context 接口设计成这个样子的原因： “取消”操作应该是建议性，而非强制性 caller 不应该去关心、干涉 callee 的情况，决定如何以及何时 return 是 callee 的责任。caller 只需发送“取消”信息，callee 根据收到的信息来做进一步的决策，因此接口并没有定义 cancel 方法。 “取消”操作应该可传递 “取消”某个函数时，和它相关联的其他函数也应该“取消”。因此，Done() 方法返回一个只读的 channel，所有相关函数监听此 channel。一旦 channel 关闭，通过 channel 的“广播机制”，所有监听者都能收到。 3.2 4 种实现为了更方便的创建 Context，包里定义了 Background 来作为所有 Context 的根，它是一个 emptyCtx 的实例。 3.2.1 emptyCtx这也是最简单的一个 ctx 1234567891011121314151617type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (*emptyCtx) Err() error &#123; return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil&#125; 空方法实现了 context.Context 接口，它没有任何功能。 Background 和 TODO 这两个方法都会返回预先初始化好的私有变量 background 和 todo，它们会在同一个 Go 程序中被复用： 1234567891011var ( background = new(emptyCtx) todo = new(emptyCtx) )func Background() Context &#123; return background&#125;func TODO() Context &#123; return todo&#125; 从源代码来看，context.Background 和 context.TODO 和也只是互为别名，没有太大的差别，只是在使用和语义上稍有不同： context.Background 是上下文的默认值，所有其他的上下文都应该从它衍生出来； context.TODO 应该仅在不确定应该使用哪种上下文时使用； 在多数情况下，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递。 3.2.2 cancelCtx这是一个带 cancel 功能的 context。 123456789type cancelCtx struct &#123; // 直接嵌入了一个 Context，那么可以把 cancelCtx 看做是一个 Context Context mu sync.Mutex // protects following fields done atomic.Value // of chan struct&#123;&#125;, created lazily, closed by first cancel call children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125; 同时 cancelCtx 还实现了 canceler 接口，提供了 cancel 方法，可以手动取消： 1234type canceler interface &#123; cancel(removeFromParent bool, err error) Done() &lt;-chan struct&#123;&#125;&#125; 实现了上面定义的两个方法的 Context，就表明该 Context 是可取消的。 创建 cancelCtx 的方法如下： 1234567891011func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; c := newCancelCtx(parent) propagateCancel(parent, &amp;c) return &amp;c, func() &#123; c.cancel(true, Canceled) &#125;&#125;func newCancelCtx(parent Context) cancelCtx &#123; return cancelCtx&#123;Context: parent&#125;&#125; 这是一个暴露给用户的方法，传入一个父 Context（这通常是一个 background，作为根节点），返回新建的 context，并通过闭包的形式，返回了一个 cancel 方法。 newCancelCtx将传入的上下文包装成私有结构体context.cancelCtx。 propagateCancel则会构建父子上下文之间的关联，形成树结构，当父上下文被取消时，子上下文也会被取消： 123456789101112131415161718192021222324252627282930313233343536373839404142434445func propagateCancel(parent Context, child canceler) &#123; // 1.如果 parent ctx 是不可取消的 ctx，则直接返回 不进行关联 done := parent.Done() if done == nil &#123; return // parent is never canceled &#125; // 2.接着判断一下 父ctx 是否已经被取消 select &#123; case &lt;-done: // 2.1 如果 父ctx 已经被取消了，那就没必要关联了 // 然后这里也要顺便把子ctx给取消了，因为父ctx取消了 子ctx就应该被取消 // 这里是因为还没有关联上，所以需要手动触发取消 // parent is already canceled child.cancel(false, parent.Err()) return default: &#125; // 3. 从父 ctx 中提取出 cancelCtx 并将子ctx加入到父ctx 的 children 里面 if p, ok := parentCancelCtx(parent); ok &#123; p.mu.Lock() // double check 一下，确认父 ctx 是否被取消 if p.err != nil &#123; // 取消了就直接把当前这个子ctx给取消了 // parent has already been canceled child.cancel(false, p.err) &#125; else &#123; // 否则就添加到 children 里面 if p.children == nil &#123; p.children = make(map[canceler]struct&#123;&#125;) &#125; p.children[child] = struct&#123;&#125;&#123;&#125; &#125; p.mu.Unlock() &#125; else &#123; // 如果没有找到可取消的父 context。新启动一个协程监控父节点或子节点取消信号 atomic.AddInt32(&amp;goroutines, +1) go func() &#123; select &#123; case &lt;-parent.Done(): child.cancel(false, parent.Err()) case &lt;-child.Done(): &#125; &#125;() &#125;&#125; 上述函数总共与父上下文相关的三种不同的情况： 1）当 parent.Done() == nil，也就是 parent 不会触发取消事件时，当前函数会直接返回； 2）当 child 的继承链包含可以取消的上下文时，会判断 parent 是否已经触发了取消信号； 如果已经被取消，child 会立刻被取消； 如果没有被取消，child 会被加入 parent 的 children 列表中，等待 parent 释放取消信号； 3）当父上下文是开发者自定义的类型、实现了 context.Context 接口并在 Done() 方法中返回了非空的管道时； 运行一个新的 Goroutine 同时监听 parent.Done() 和 child.Done() 两个 Channel； 在 parent.Done() 关闭时调用 child.cancel 取消子上下文； propagateCancel 的作用是在 parent 和 child 之间同步取消和结束的信号，保证在 parent 被取消时，child 也会收到对应的信号，不会出现状态不一致的情况。 1234567891011121314151617181920func parentCancelCtx(parent Context) (*cancelCtx, bool) &#123; done := parent.Done() // 如果 done 为 nil 说明这个ctx是不可取消的 // 如果 done == closedchan 说明这个ctx不是标准的 cancelCtx，可能是自定义的 if done == closedchan || done == nil &#123; return nil, false &#125; // 然后调用 value 方法从ctx中提取出 cancelCtx p, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx) if !ok &#123; return nil, false &#125; // 最后再判断一下cancelCtx 里存的 done 和 父ctx里的done是否一致 // 如果不一致说明parent不是一个 cancelCtx pdone, _ := p.done.Load().(chan struct&#123;&#125;) if pdone != done &#123; return nil, false &#125; return p, true&#125; cancelCtx 的 done 方法肯定会返回一个 chan struct&#123;&#125; 123456789101112131415func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; d := c.done.Load() if d != nil &#123; return d.(chan struct&#123;&#125;) &#125; c.mu.Lock() defer c.mu.Unlock() d = c.done.Load() if d == nil &#123; d = make(chan struct&#123;&#125;) c.done.Store(d) &#125; return d.(chan struct&#123;&#125;)&#125;var closedchan = make(chan struct&#123;&#125;) c.done 是“懒汉式”创建，只有调用了 Done() 方法的时候才会被创建。再次说明，函数返回的是一个只读的 channel，而且没有地方向这个 channel 里面写数据。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。 123456func (c *cancelCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if key == &amp;cancelCtxKey &#123; return c &#125; return c.Context.Value(key)&#125; 所以这里parent.Value(&amp;cancelCtxKey)返回值就是 parent 内部的 cancelCtx。 parentCancelCtx 其实就是判断 parent context 里面有没有一个 cancelCtx，有就返回，让子 context 可以 “挂靠” 到 parent context 上，如果不是就返回 false，不进行挂靠，自己新开一个 goroutine 来监听。 最后再看一下比较重要的 cancel 方法。 1234567891011121314151617181920212223242526272829303132333435func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; // 参数校验 调用 cancel 必须传一个 err 进来，说明 cancel 的原因 if err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;) &#125; c.mu.Lock() if c.err != nil &#123; // 如果 err 不为空，说明已经取消过了，直接返回 c.mu.Unlock() return // already canceled &#125; c.err = err // 然后更新 done 的值 d, _ := c.done.Load().(chan struct&#123;&#125;) if d == nil &#123; // 如果为空就直接赋值为一个已经关闭的chan c.done.Store(closedchan) &#125; else &#123; // 如果有值就把对应chan直接关闭 close(d) &#125; // 接下来就是循环调用 取消掉 子context for child := range c.children &#123; // NOTE: acquiring the child&#x27;s lock while holding parent&#x27;s lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() // 最后更加参数来确定是否需要将该context从父content.children 中移除 if removeFromParent &#123; // 大部分情况下该参数都为 true 因为取消子context后肯定要和父context解开关联 // 只有当前子context还没添加到父context时，父context就被取消了，这种情况下会传false进来 removeChild(c.Context, c) &#125;&#125; 总体来看，cancel() 方法的功能就是关闭 channel：c.done；递归地取消它的所有子节点；从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。goroutine 接收到取消信号的方式就是 select 语句中的读 c.done 被选中。 3.2.3 timerCtxtimerCtx 内部不仅通过嵌入 cancelCtx 的方式承了相关的变量和方法，还通过持有的定时器 timer 和截止时间 deadline 实现了定时取消的功能： 1234567891011121314151617181920212223type timerCtx struct &#123; cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true&#125;func (c *timerCtx) cancel(removeFromParent bool, err error) &#123; c.cancelCtx.cancel(false, err) if removeFromParent &#123; removeChild(c.cancelCtx.Context, c) &#125; c.mu.Lock() if c.timer != nil &#123; c.timer.Stop() c.timer = nil &#125; c.mu.Unlock()&#125; timerCtx.cancel 不仅调用了 cancelCtx.cancel 方法，还会停止持有的定时器减少不必要的资源浪费。 实际上对外提供了 WithTimeout 方法只是 WithDeadline 的封装： 1234567891011121314151617181920212223242526272829303132333435func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125;func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; // The current deadline is already sooner than the new one. // 如果父节点 context 的 deadline 早于指定时间。直接构建一个可取消的 context。 // 原因是一旦父节点超时，自动调用 cancel 函数，子节点也会随之取消。 // 所以不用单独处理子节点的计时器时间到了之后，自动调用 cancel 函数 // 毕竟如果父节点1分钟后过期，那不可能在这个父节点下创建一个两分钟后过期的子节点 return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; propagateCancel(parent, c) dur := time.Until(d) if dur &lt;= 0 &#123; c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() &#123; c.cancel(false, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125; 和 WithCancel 大致逻辑是相同的，除了多了一个 timer 来定时取消： 123c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) 里面的一个 deadLine 判断也比较有意思： 123if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(deadline)&#123; return WithCancel(parent) &#125; 如果父节点 context 的 deadline 早于本次创建子节点的 deadline ，那就没必要给子节点创建一个 timerCtx 了，因为根据 deadline 来看，父节点肯定会早与这个子节点取消，而父节点取消后，子节点也会跟着被取消，所以没必要给子节点创建 timer，直接创建一个 cancelCtx 将子节点挂到父节点上就行了，效果是一样的，还剩下一个 timer。 1234type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125; 3.2.4 valueCtxvalueCtx 则是多了 key、val 两个字段来存数据。 123456789101112func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; if key == nil &#123; panic(&quot;nil key&quot;) &#125; if !reflectlite.TypeOf(key).Comparable() &#123; panic(&quot;key is not comparable&quot;) &#125; return &amp;valueCtx&#123;parent, key, val&#125;&#125; 直接基于 parent 构建了一个 valueCtx，比较简单。注意点是这个方法对 key 的要求是**可比较的 (comparable)**，因为之后需要通过 key 取出 context 中的值，可比较是必须的。 取值的过程，实际上是一个递归查找的过程： 123456func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 如果 key 和当前 ctx 中存的 value 一致就直接返回，没有就去 parent 中找。最终找到根节点（一般是 emptyCtx），直接返回一个 nil。所以用 Value 方法的时候要判断结果是否为 nil。 因为这里要比较两个 key 是否一致，所以创建的时候必须要求 key 是 comparable。 类似于一个链表，其实效率是很低的，不建议用来传参数。 4. 使用建议在官方博客里，对于使用 context 提出了几点建议： Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. The Context should be the first parameter, typically named ctx. Do not pass a nil Context, even if a function permits it. Pass context.TODO if you are unsure about which Context to use. Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions. The same Context may be passed to functions running in different goroutines; Contexts are safe for simultaneous use by multiple goroutines. 翻译过来就是： 不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo。 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。 同一个 context 可能会被传递到多个 goroutine，别担心，context 是并发安全的。","tags":["Go","context"],"categories":["Go"]},{"title":"Go 系列(一)：chan 源码分析","path":"/go/channel/","content":"本文主要介绍了 Go 语言 (golang) 中的 channel，并从源码层面分析其具体实现，包括创建 channel，发送数据，接收数据以及相关调度等。 以下分析基于 Go 1.17.5 1. 概述官方对 chan 的描述如下： A channel provides a mechanism for concurrently executing functions to communicate by sending and receivingvalues of a specified element type. The value of an uninitialized channel is nil. chan 提供了一种并发通信机制，用于生产和消费某一指定类型数据，未初始化的 chan 的值是 nil。 Chan 是 Go 里面的一种数据结构，具有以下特性： goroutine-safe，多个 goroutine 可以同时访问一个 channel 而不会出现并发问题 hchan mutex，通过加锁来避免数据竞争。 可以用于在 goroutine 之间存储和传递值 copying into and out of hchan buffer 其语义是先入先出（FIFO） 可以导致 goroutine 的 block 和 unblock 通过 sudog queues 来记录阻塞的 goroutine。 通过 runtime scheduler(gopark, goready) 来实现阻塞与唤醒。 Channel 字面意义是“通道”，类似于 Linux 中的管道。声明 channel 的语法如下： 123chan T // 声明一个双向通道chan&lt;- T // 声明一个只能用于发送的通道&lt;-chan T // 声明一个只能用于接收的通道 单向通道的声明，用 &lt;- 来表示，它指明通道的方向。 因为 channel 是一个引用类型，所以在它被初始化之前，它的值是 nil，channel 使用 make 函数进行初始化。可以向它传递一个 int 值，代表 channel 缓冲区的大小（容量），构造出来的是一个缓冲型的 channel；不传或传 0 的，构造的就是一个非缓冲型的 channel。 12345// 无缓冲ch1 := make(chan int)// 缓冲区为 3ch2 := make(chan int, 3) chan（即 hchan 结构体） 默认会被分配在堆上，make 返回的只是一个指向该对象的指针。 无缓冲 channel 无缓冲的 channel（unbuffered channel），其缓冲区大小则默认为 0。在功能上其接受者会阻塞等待并阻塞应用程序，直至收到通信和接收到数据。 （引用 William Kennedy 的图） 缓冲 channel 有缓存的 channel（buffered channel），其缓存区大小是根据所设置的值来调整。在功能上，若缓冲区未满则不会阻塞，会源源不断的进行传输。当缓冲区满了后，发送者就会阻塞并等待。而当缓冲区为空时，接受者就会阻塞并等待，直至有新的数据： （引用 William Kennedy 的图） 2. 数据结构本质上 channel 在设计上就是环形队列。其包含发送方队列、接收方队列，加上互斥锁 mutex 等结构。 channel 是一个有锁的环形队列： 123456789101112131415161718192021222324252627282930313233343536// src/runtime/chan.gotype hchan struct &#123; closed uint32 // channel是否关闭的标志 elemtype *_type // channel中的元素类型 // channel分为无缓冲和有缓冲两种。 // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组 // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移 // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置 buf unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区） qcount uint // 循环数组中的元素数量 dataqsiz uint // 循环数组的长度 elemsize uint16 // 元素的大小 sendx uint // 下一次写下标的位置 recvx uint // 下一次读下标的位置 // 尝试读取channel或向channel写入数据而被阻塞的goroutine recvq waitq // 读等待队列 sendq waitq // 写等待队列 lock mutex //互斥锁，保证读写channel时不存在并发竞争问题&#125;type waitq struct &#123; first *sudog last *sudog&#125;type sudog struct &#123; g *g // 指向当前的 goroutine。 next *sudog // 指向下一个 g。 prev *sudog // 指向上一个 g。 elem unsafe.Pointer // 数据元素，可能会指向堆栈。 c *hchan ...&#125; 3. 实现原理3.1 创建 chan在源码中通道的创建由 makechan 方法实现： 123456789101112131415161718// 通用创建方法func makechan(t *chantype, size int) *hchan// 类型为 int64 的进行特殊处理func makechan64(t *chantype, size int64) *hchan//go:linkname reflect_makechan reflect.makechanfunc reflect_makechan(t *chantype, size int) *hchan &#123; return makechan(t, size)&#125;func makechan64(t *chantype, size int64) *hchan &#123; if int64(int(size)) != size &#123; panic(plainError(&quot;makechan: size out of range&quot;)) &#125; return makechan(t, int(size))&#125; 内部都是调用的 makechan 方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // 编译器检查 typesize 和 align if elem.size &gt;= 1&lt;&lt;16 &#123; throw(&quot;makechan: invalid channel element type&quot;) &#125; if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123; throw(&quot;makechan: bad alignment&quot;) &#125; // 计算存放数据元素的内存大小以及是否溢出 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem &gt; maxAlloc-hchanSize || size &lt; 0 &#123; panic(plainError(&quot;makechan: size out of range&quot;)) &#125; var c *hchan switch &#123; case mem == 0: // chan的size为0，或者每个元素占用的大小为0（比如struct&#123;&#125;大小就是0，不占空间） // 这种情况就不需要单独为buf分配空间 c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.ptrdata == 0: // 如果队列中不存在指针，那么每个元素都需要被存储并占用空间，占用大小为前面乘法算出来的mem // 同时还要加上hchan本身占用的空间大小，加起来就是整个hchan占用的空间大小 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) // 把buf指针指向空的hchan占用空间大小的末尾 c.buf = add(unsafe.Pointer(c), hchanSize) default: // 如果chan中的元素是指针类型的数据，为buf单独开辟mem大小的空间，用来保存所有的数据 c = new(hchan) c.buf = mallocgc(mem, elem, true) &#125; // 元素大小、类型以及缓冲区大小赋值 c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) // 初始化锁 lockInit(&amp;c.lock, lockRankHchan) return c&#125; 具体流程如下： 1）首先是编译器检查，包括通道元素类型的 size 以及通道和元素的对齐，然后计算存放数据元素的内存大小以及是否溢出 2）然后根据不同条件进行内存分配 总体的原则是：总内存大小 = hchan 需要的内存大小 + 元素需要的内存大小 队列为空或元素大小为 0：只需要开辟的内存空间为 hchan 本身的大小 元素不是指针类型：需要开辟的内存空间 = hchan 本身大小 + 每个元素的大小 * 申请的队列长度 元素是指针类型：这种情况下 buf 需要单独开辟空间，buf 占用内存大小为每个元素的大小 * 申请的队列长度3）最后则对 chan 的其他字段赋值 3.2 发送数据发送数据到 channel 时，直观的理解是将数据放到 chan 的环形队列中，不过 go 做了一些优化： 先判断是否有等待接收数据的 groutine，如果有，直接将数据发给 Groutine，唤醒 groutine，就不放入队列中了。 这样省去了两次内存拷贝和加锁的开销 当然还有另外一种情况就是：队列如果满了，那就只能放到队列中等待，直到有数据被取走才能发送。 chan 的发送逻辑涉及到 5 个方法： 12345func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) &#123;&#125;func chansend1(c *hchan, elem unsafe.Pointer) &#123;…&#125;func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123;…&#125;func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123;…&#125;func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) &#123;…&#125; chansend1 方法是 go 编译代码中c &lt;- x这种写法的入口点，即当我们编写代码 c &lt;- x其实就是调用此方法。 这四个方法的调用关系：chansend1 -&gt; chansend -&gt; send -&gt; sendDirect 具体发送逻辑在chansend这个方法里，然后真正使用的方法其实是对该方法的一层包装。 1234567func chansend1(c *hchan, elem unsafe.Pointer) &#123; chansend(c, elem, true, getcallerpc())&#125;func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) &#123; return chansend(c, elem, false, getcallerpc())&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; // 判断 channel 是否为 nil if c == nil &#123; if !block &#123;// 如果非阻塞，直接返回 false return false &#125; // 当向 nil channel 发送数据时，会调用 gopark // 而 gopark 会将当前的 goroutine 休眠，并用过第一个参数的 unlockf 来回调唤醒 // 但此处传递的参数为 nil，因此向 channel 发送数据的 goroutine 和接收数据的 goroutine 都会阻塞，进而死锁 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; if raceenabled &#123; racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) &#125; // 对于不阻塞的 send，快速检测失败场景 // 如果 channel 未关闭且 channel 没有多余的缓冲空间。这可能是： // 1. channel 是非缓冲型的，且等待接收队列里没有 goroutine // 2. channel 是缓冲型的，但循环数组已经装满了元素 // 主要用于 select 语句中，涉及到指令重排队+可观测性 if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; // 加锁,避免竞争 lock(&amp;c.lock) // 检查 channel 是否已关闭，不允许向关闭的 channel 发送数据 if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) // 直接panic &#125; // 从 recvq 队首取出一个接收者，如果存在接收者，就绕过环形队列（buf）直接把 ep 拷贝给 sg，并释放锁 // 这就是前面提到的，官方做的一个优化，如果有goroutine在等待就直接把数据给该goroutine，没必要在写到buf，然后接收者又从buf中拷贝出来 if sg := c.recvq.dequeue(); sg != nil &#123; send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; // 到这里说明当前没有等待状态的接收者 // 如果环形队列还未满 if c.qcount &lt; c.dataqsiz &#123; // 拿到 sendx 索引的位置 qp := chanbuf(c, c.sendx) if raceenabled &#123; racenotify(c, c.sendx, nil) &#125; // 直接把数据从 qp 拷贝到 qp，就是把数据拷贝到环形队列中 typedmemmove(c.elemtype, qp, ep) // 维护 snedx 的值，因为是环形队列，所以到最大值时就重置为0 c.sendx++ if c.sendx == c.dataqsiz &#123; c.sendx = 0 &#125; //qcount即当前chan中的元素个数 c.qcount++ unlock(&amp;c.lock) return true &#125; // 到这里说明环形队列已经满了 // 如果还是要非阻塞的方式发送，就只能返回错误了 if !block &#123; unlock(&amp;c.lock) return false &#125; // 到这里说明缓存队列满了，然后调用法指定是阻塞方式进行发送 // channel 满了，发送方会被阻塞。接下来会构造一个 sudog gp := getg() // 获取当前 goroutine mysg := acquireSudog()// 从对象池获取 sudog mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // 把发送的数据(ep)、当前g(gp)、已经当前这个chan(c)都存到sudog中 mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c // 保存当前 sudog，下面要用到做校验 gp.waiting = mysg gp.param = nil // 把这个sudog存入sendq队列 c.sendq.enqueue(mysg) atomic.Store8(&amp;gp.parkingOnChan, 1) // 调用gopark，挂起当前的 g，将当前的 g 移出调度器的队列 gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // 等到有接收者从chan中取值的时候，这个发送的g又会被重新调度，然后从这里开始继续执行 KeepAlive(ep) // 检验是否为当前的 sudog if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false // 这里sudog中的success表示的是当前这个通道上是否进行过通信 // 为 true 则说明是真正的唤醒，chan上有活动（有数据写进来，或者有数据被读取出去） // 为 false 则说明是假的唤醒，即当前唤醒是否关闭chan导致的 // 这里主要根据这个值判断chan是否被关闭了 closed := !mysg.success gp.param = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil // 将 sudog 放回对象池 releaseSudog(mysg) if closed &#123; // 如果chan被关闭了也是直接panic if c.closed == 0 &#123; throw(&quot;chansend: spurious wakeup&quot;) &#125; panic(plainError(&quot;send on closed channel&quot;)) &#125; return true&#125; 核心逻辑 如果 recvq 不为空，从 recvq 中取出一个等待接收数据的 Groutine，直接将数据发送给该 Groutine 如果 recvq 为空，才将数据放入 buf 中 如果 buf 已满，则将要发送的数据和当前的 Groutine 打包成 Sudog 对象放入 sendq，并将 groutine 置为等待状态 等 goroutine 再次被调度时程序继续执行 然后追踪一下 send 方法： 1234567891011121314151617func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123; // 忽略 race 检查.. if sg.elem != nil &#123; // 直接拷贝到接受者内存，使用写屏障 sendDirect(c.elemtype, sg, ep) sg.elem = nil &#125; gp := sg.g // 取出sudog中记录的g，这里的g就是被阻塞接收者 unlockf() gp.param = unsafe.Pointer(sg) // 更新接收者g的param字段，在recv方法中会用到 sg.success = true if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; // 最后把被阻塞的接收者g唤醒 goready(gp, skip+1)&#125; 继续看 sendDirect 方法： 1234567891011func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) &#123; // src 在当前 goroutine 的栈上，dst 是另一个 goroutine 的栈 // 直接进行内存&quot;搬迁&quot; // 如果目标地址的栈发生了栈收缩，当我们读出了 sg.elem 后 // 就不能修改真正的 dst 位置的值了 // 因此需要在读和写之前加上一个屏障 dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // 拷贝内存 memmove(dst, src, t.size)&#125; 这里涉及到一个 goroutine 直接写另一个 goroutine 栈的操作，一般而言，不同 goroutine 的栈是各自独有的。而这也违反了 GC 的一些假设。为了不出问题，写的过程中增加了写屏障，保证正确地完成写操作。这样做的好处是减少了一次内存 copy：不用先拷贝到 channel 的 buf，直接由发送者到接收者，没有中间商赚差价，效率得以提高，完美。 3.3 接收数据从 channel 读取数据的流程和发送的类似，基本是发送操作的逆操作。 这里同样存在和 send 一样的优化：从 channel 读取数据时，不是直接去环形队列中去数据，而是先判断是否有等待发送数据的 groutine。如果有，直接将 groutine 出队列，取出数据返回，并唤醒 groutine。如果没有等待发送数据的 groutine，再从环形队列中取数据。 chan 的接收涉及到 7 个方法： 1234567func reflect_chanrecv(c *hchan, nb bool, elem unsafe.Pointer) (selected bool, received bool) &#123;&#125;func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected, received bool) &#123;&#125;func chanrecv1(c *hchan, elem unsafe.Pointer) &#123;…&#125;，func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123;…&#125;func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123;…&#125;func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123;…&#125;func recvDirect(t *_type, sg *sudog, dst unsafe.Pointer) &#123;…&#125; 按照发送时的套路可知，只有 chanrecv 是具体逻辑，上面几个都是包装方法： 1234567891011121314151617//go:linkname reflect_chanrecv reflect.chanrecvfunc reflect_chanrecv(c *hchan, nb bool, elem unsafe.Pointer) (selected bool, received bool) &#123; return chanrecv(c, elem, !nb)&#125;func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected, received bool) &#123; return chanrecv(c, elem, false)&#125;//go:nosplitfunc chanrecv1(c *hchan, elem unsafe.Pointer) &#123; chanrecv(c, elem, true)&#125;//go:nosplitfunc chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123; _, received = chanrecv(c, elem, true) return&#125; 接收操作有两种写法，一种带 “ok”，反应 channel 是否关闭； 一种不带 “ok”，这种写法，当接收到相应类型的零值时无法知道是真实的发送者发送过来的值，还是 channel 被关闭后，返回给接收者的默认类型的零值。 两种写法，都有各自的应用场景。 经过编译器的处理后，这两种写法最后对应源码里的就是不带ok的chanrecv1和带ok的chanrecv2这两个函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141// chanrecv 函数接收 channel c 的元素并将其写入 ep 所指向的内存地址。// 如果 ep 是 nil，说明忽略了接收值。比如 &lt;-ch 这样，没有接收取到的值// 如果 block == false，即非阻塞型接收，在没有数据可接收的情况下，返回 (false, false)// 否则，如果 c 处于关闭状态，将 ep 指向的地址清零，返回 (true, false)// 否则，用返回值填充 ep 指向的内存地址。返回 (true, true)// 如果 ep 非空，则应该指向堆或者函数调用者的栈func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // 如果是一个 nil 的 channel if c == nil &#123; // 如果不阻塞，直接返回 (false, false) if !block &#123; return &#125; // 否则，接收一个 nil 的 channel，调用gopark将goroutine 挂起 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) // 被挂起之后不会执行到这一句 &#125; // 这块主要用在 select 语句中，先大概了解下，比较难懂。。。 // 快速路径: 在不需要锁的情况下检查失败的非阻塞操作 // 注意到 channel 不能由已关闭转换为未关闭，则失败的条件是： // 1. channel 是非缓冲型的，recvq 队列为空 // 2. channel 是缓冲型的，buf 为空 if !block &amp;&amp; empty(c) &#123; // 此处的 c.closed 必须在条件判断之后进行验证， // 因为指令重排后，如果先判断 c.closed，得出 channel 未关闭，无法判断失败条件中channel 是已关闭还是未关闭（从而需要 atomic 操作） if atomic.Load(&amp;c.closed) == 0 &#123; return &#125; // 再次检查 channel 是否为空 if empty(c) &#123; // 接收者不为 nil 时返回该类型的零值 if ep != nil &#123; // typedmemclr 逻辑是根据类型清理相应地址的内存 typedmemclr(c.elemtype, ep) &#125; // 返回（true,fasle） // 返回值1--true：表示被 select case 选中， // 返回值2--fasle 表示是否正常收到数据 return true, false &#125; &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; // 加锁，保证并发安全 lock(&amp;c.lock) // channel 已关闭，并且循环数组 buf 里没有元素 // 这里可以处理非缓冲型关闭 和 缓冲型关闭但 buf 无元素的情况 // 也就是说即使是关闭状态，但在缓冲型的 channel， // buf 里有元素的情况下还能接收到元素 if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; // 等待发送队列里有 goroutine 存在，说明 buf 是满的 // 这有可能是： // 1. 非缓冲型的 channel // 2. 缓冲型的 channel，但 buf 满了 // 针对 1，直接进行内存拷贝（从 sender goroutine -&gt; receiver goroutine） // 针对 2，接收到循环数组头部的元素，并将发送者的元素放到循环数组尾部 if sg := c.sendq.dequeue(); sg != nil &#123; recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; // chan的buf 里有元素，可以正常接收 if c.qcount &gt; 0 &#123; // 直接从循环数组里找到要接收的元素 qp := chanbuf(c, c.recvx) // ep != nil表示代码里，没有忽略要接收的值 // 即接收的代码不是 &quot;&lt;- ch&quot;，而是 &quot;val &lt;- ch&quot;这种，ep 指向 val if ep != nil &#123; typedmemmove(c.elemtype, ep, qp) &#125; // 清理掉循环数组里相应位置的值 typedmemclr(c.elemtype, qp) // 维护接收游标 c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; // buf 数组里的元素个数减 1 c.qcount-- // 处理完成，解锁返回 unlock(&amp;c.lock) return true, true &#125; // 到这里说明chan的buf里没有数据了，如果是非阻塞接收就直接返回了 if !block &#123; unlock(&amp;c.lock) return false, false &#125; // 接下来就是要被阻塞的情况了 // 和发送类似的，构造一个 sudog gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // 这里需要注意一下，ep就是我们用来接收值得对象 // 这里把ep直接存到sudog.elem字段上 mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg // 这个waiting同样是用来唤醒后做校验的 mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil // 加入到chan的recvq队列里 c.recvq.enqueue(mysg) atomic.Store8(&amp;gp.parkingOnChan, 1) // 将当前 goroutine 挂起 gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // 唤醒后，继续往下执行 // 同样是进行数据校验 if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; // 又是mysg.success，如果chan活动过就是true，否则是false success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg)// 将 sudog 放回对象池 // 到这里如果goroutine被正常唤醒肯定是可以取到数据的 // 因为recvq的数据是由发送的时候直接copy过来了 return true, success&#125; 继续追踪一下 recv 方法 123456789101112131415161718192021222324252627282930313233343536373839func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123; // 非缓冲型的 channel if c.dataqsiz == 0 &#123; // 并且需要接收值 if ep != nil &#123; // 直接进行内存拷贝 recvDirect(c.elemtype, sg, ep) &#125; &#125; else &#123; // 需要注意：进入recv方法说明sendq队列里是有值的 // 那么对缓冲型的 channel来说，sendq有值就意味着buf满了 // 也就是 recvx和sendx重合了都 // 这里要做的就是先从buf中读一个数据出来，然后再把发送者发送的数据写入buf qp := chanbuf(c, c.recvx) // 将接收游标处的数据拷贝给接收者 if ep != nil &#123; typedmemmove(c.elemtype, ep, qp) &#125; // 从发送者把数据写入 recvx typedmemmove(c.elemtype, qp, sg.elem) // 然后修改 recvx和sendx 的位置 c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz &#125; sg.elem = nil gp := sg.g // 解锁 unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; // 最后唤醒发送的 goroutine goready(gp, skip+1)&#125; 再看一下 recvDirect： 1234567func recvDirect(t *_type, sg *sudog, dst unsafe.Pointer) &#123; // 如果是非缓冲型的，就直接从发送者的栈拷贝到接收者的栈。 // 和sendDirect一样的需要加内存屏障 src := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) memmove(dst, src, t.size)&#125; 看了接收部分代码后，整个流程就更新清晰了。 根据前面的发送逻辑可以知道，不管是接收还是发送只要被阻塞了，加入到了 sendq 或者 recvq 之后，那么后续的发送或者接收都是由对方进行处理了。 比如接收被阻塞了，当前 g 构成成一个 sudog 然后加入到 recvq，接着调用了 gopark 就已经阻塞了，啥也干不了了。 只能等到有发送者来的时候直接从 recvq 里把这个 sudog 取出来，并且直接把要他发送的值拷贝到这个 sudog.elem 字段上，也就是调用 chan 接收方法是传进来的哪个值. 最后发送方再调用 goready 把这个 g 给唤醒，这样再把剩下的逻辑走完，这个被阻塞了一会的接收者就可以拿着数据返回了。 核心逻辑： 1）如果有等待发送数据的 groutine，从 sendq 中取出一个等待发送数据的 Groutine，取出数据 2）如果没有等待的 groutine，且环形队列中有数据，从队列中取出数据 3）如果没有等待的 groutine，且环形队列中也没有数据，则阻塞该 Groutine，并将 groutine 打包为 sudogo 加入到 recevq 等待队列中 3.4 关闭 chanclose 就比较简单了，相关方法就两个： 12345//go:linkname reflect_chanclosefunc reflect_chanclose(c *hchan) &#123; closechan(c)&#125;func closechan(c *hchan)&#123;&#125; 其中一个还是包装方法，真正逻辑就在 clsoechan 里。 每个逻辑都有一个 reflect_xxx 的方法，根据名字猜测是反射的时候用的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071func closechan(c *hchan) &#123; // 关闭一个nil的chan直接panic if c == nil &#123; panic(plainError(&quot;close of nil channel&quot;)) &#125; // 同样是先加锁 lock(&amp;c.lock) // 判断一下是否被关闭过了，关闭一个已经关闭的chan也是直接panic if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;close of closed channel&quot;)) &#125; // 修改closed标记为，表示chan已经被关闭了 c.closed = 1 // gList 是通过 g.schedlink 链接 G 的列表，一个 G 只能是一次在一个 gQueue 或 gList 上 // gList 模拟的是栈操作（FILO） // gQueue 模拟的是队列操作（FIFO） var glist gList // 释放所有的接收者 for &#123; sg := c.recvq.dequeue() // sg == nil，表示接收队列已为空，跳出循环 if sg == nil &#123; break &#125; // 如果 elem 不为空说明未忽略接收值，赋值为该类型的零值 if sg.elem != nil &#123; typedmemclr(c.elemtype, sg.elem) sg.elem = nil &#125; if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; // release all writers (they will panic) // 释放所有的发送者，抛出异常 for &#123; sg := c.sendq.dequeue() if sg == nil &#123; break &#125; sg.elem = nil if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; unlock(&amp;c.lock) // 循环读取 glist 里面的数据，挨个唤醒 for !glist.empty() &#123; gp := glist.pop() gp.schedlink = 0 goready(gp, 3) &#125;&#125; 核心流程： 设置关闭状态 唤醒所有等待读取 chanel 的协程 所有等待写入 channel 的协程，抛出异常 4. 进阶4.1 操作 chan总结一下操作 channel 的结果： 操作 nil channel closed channel not nil, not closed channel close panic panic 正常关闭 读 &lt;- ch 阻塞 读到对应类型的零值 阻塞或正常读取数据。缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞 写 ch &lt;- 阻塞 panic 阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞 总结一下，发生 panic 的情况有三种：向一个关闭的 channel 进行写操作；关闭一个 nil 的 channel；重复关闭一个 channel。 读、写一个 nil channel 都会被阻塞。 4.2 发送和接收元素的本质Channel 发送和接收元素的本质是什么？参考资料【深入 channel 底层】里是这样回答的： Remember all transfer of value on the go channels happens with the copy of value. 就是说 channel 的发送和接收操作本质上都是 “值的拷贝”，无论是从 sender goroutine 的栈到 chan buf，还是从 chan buf 到 receiver goroutine，或者是直接从 sender goroutine 到 receiver goroutine。 这里再引用文中的一个例子，我会加上更加详细地解释。 12345678910111213141516171819202122232425262728293031323334type user struct &#123; name string age int8&#125;var u = user&#123;name: &quot;Ankur&quot;, age: 25&#125;var g = &amp;ufunc modifyUser(pu *user) &#123; fmt.Println(&quot;modifyUser Received Vaule&quot;, pu) pu.name = &quot;Anand&quot;&#125;func printUser(u &lt;-chan *user) &#123; time.Sleep(2 * time.Second) fmt.Println(&quot;printUser goRoutine called&quot;, &lt;-u)&#125;func main() &#123; c := make(chan *user, 5) c &lt;- g fmt.Println(g) // modify g g = &amp;user&#123;name: &quot;Ankur Anand&quot;, age: 100&#125; go printUser(c) go modifyUser(g) time.Sleep(5 * time.Second) fmt.Println(g)&#125;&amp;&#123;Ankur 25&#125;modifyUser Received Value &amp;&#123;Ankur Anand 100&#125;printUser goRoutine called &amp;&#123;Ankur 25&#125;&amp;&#123;Anand 100&#125; 一开始构造一个结构体 u，地址是 0x56420，图中地址上方就是它的内容。接着把 &amp;u 赋值给指针 g，g 的地址是 0x565bb0，它的内容就是一个地址，指向 u。 main 程序里，先把 g 发送到 c，根据 copy value 的本质，进入到 chan buf 里的就是 0x56420，它是指针 g 的值（不是它指向的内容），所以打印从 channel 接收到的元素时，它就是 &amp;{Ankur 25}。因此，这里并不是将指针 g “发送” 到了 channel 里，只是拷贝它的值而已。 4.3 资源泄漏Channel 可能会引发 goroutine 泄漏。 泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。同时，垃圾回收器也不会回收此类资源，进而导致 gouroutine 会一直处于等待队列中，不见天日。","tags":["Go","chan","channel"],"categories":["Go"]},{"title":"Docker 系列(三)：Docker 核心原理","path":"/docker/docker_core/","content":"本文主要介绍了 Docker容器的核心实现原理，包括 Namespace、Cgroups、rootfs 等。 容器与进程 进程就是程序运行起来后的计算机执行环境的总和。 即：计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。 对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而 Namespace 技术则是用来修改进程视图的主要方法。 隔离与限制 NamespaceNamespace 技术实际上修改了应用进程看待整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些指定的内容。但对于宿主机来说，这些被 “隔离” 来的进程和其他进程没有什么不同。 在 Linux 下可以根据隔离的属性不同分为不同的 Namespace ： Mount Namespace（CLONE_NEWNS / Linux 2.4.19） UTS Namespace（CLONE NEWUTS / Linux 2.6.19） IPC Namespace（CLONE NEWIPC / Linux 2.6.19） PID Namespace（CLONE NEWPID / Linux 2.6.24） Network Namespace（CLONE NEWNET / 始于Linux 2.6.24完成于 Linux 2.6.29） User Namespace（CLONE NEWUSER / 始于 Linux 2.6.23 完成于 Linux 3.8） Time Namespace UTS Namespace Namespace 存在的问题 最大的问题就是隔离得不彻底。 首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。 尽管可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。 而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来。 其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就 是：时间。 这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。 下面通过一个案例，来看下 Namespace 的效果： 1234567891011# 使用 python3.6.8 的官方镜像，建立了一个运行 django 的环境# 进入该容器后，使用 ps 命令，查看运行的进程root@8729260f784a:/src# ps -A PID TTY TIME CMD 1 ? 00:01:22 gunicorn 22 ? 00:01:20 gunicorn 23 ? 00:01:24 gunicorn 25 ? 00:01:30 gunicorn 27 ? 00:01:16 gunicorn 41 pts/0 00:00:00 bash 55 pts/0 00:00:00 ps 可以看到，容器内 PID =1 的进程，是 gunicorn 启动的 django 应用。熟悉 Linux 的同学都知道，PID =1 的进程是系统启动时的第一个进程，也称 init 进程。其他的进程，都是由它管理产生的。而此时，PID=1 确实是 django 进程。 接着，退出容器，在宿主机执行 ps 命令 12345678# 环境为 Centos7[root@localhost ~]# ps -ef | grep gunicornroot 9623 8409 0 21:29 pts/0 00:00:00 grep --color=auto gunicornroot 30828 30804 0 May28 ? 00:01:22 /usr/local/bin/python /usr/local/bin/gunicorn -c gunicorn_config.py ctg.wsgiroot 31171 30828 0 May28 ? 00:01:20 /usr/local/bin/python /usr/local/bin/gunicorn -c gunicorn_config.py ctg.wsgiroot 31172 30828 0 May28 ? 00:01:24 /usr/local/bin/python /usr/local/bin/gunicorn -c gunicorn_config.py ctg.wsgiroot 31174 30828 0 May28 ? 00:01:30 /usr/local/bin/python /usr/local/bin/gunicorn -c gunicorn_config.py ctg.wsgiroot 31176 30828 0 May28 ? 00:01:16 /usr/local/bin/python /usr/local/bin/gunicorn -c gunicorn_config.py ctg.wsgi 如果以宿主机的视角，发现 django 进程 PID 变成了 30828. 这也就不难证明，在容器中，确实做了一些处理。把明明是 30828 的进程，变成了容器内的第一号进程，同时在容器还看不到宿主机的其他进程。这也说明容器内的环境确实是被隔离了。 这种处理，其实就是 Linux 的 Namespace 机制。比如，上述将 PID 变成 1 的方法就是通过PID Namespace。在 Linux 中创建线程的方法是 clone, 在其中指定 CLONE_NEWPID 参数，这样新创建的进程，就会看到一个全新的进程空间。而此时这个新的进程，也就变成了 PID=1 的进程。 1int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 在 Linux 类似于 PID Namespace 的参数还有很多，比如： Namespace Flag Page Isolates Cgroup CLONE_NEWCGROUP cgroup_namespaces Cgroup root directory IPC CLONE_NEWIPC ipc_namespaces System V IPC,POSIX message queues 隔离进程间通信 Network CLONE_NEWNET network_namespaces Network devices,stacks, ports, etc. 隔离网络资源 Mount CLONE_NEWNS mount_namespaces Mount points 隔离文件系统挂载点 PID CLONE_NEWPID pid_namespaces Process IDs 隔离进程的 ID Time CLONE_NEWTIME time_namespaces Boot and monotonic clocks User CLONE_NEWUSER user_namespaces User and group IDs 隔离用户和用户组的 ID UTS CLONE_NEWUTS uts_namespaces Hostname and NIS domain name 隔离主机名和域名信息 Cgroups通过上面的 Linux Namespace 已经可以创建 “容器” 了，但是会存在 资源抢占 的问题。 还是以 PID Namespace 为例，来给你解释这个问题。 虽然容器内的第1号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器)占用的。当然，这个 100号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。 而 Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。 Linux Cgroups 的全称是 Linux Control Group 主要的作用就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。 此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。在本文中，只重点探讨它与容器关系最紧密的“限制”能力，并通过一组实践来带你认识一下 Cgroups。 每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我可以用 mount 指令把它们展示出来，这条命令是： 12345678910111213#查看 cgroups 相关文件$ mount -t cgroupcgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids) 它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那就需要自己去挂载 Cgroups，具体做法可以自行 Google。 在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，就可以看到该类资源具体可以被限制的方法。 比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是： 1234ls /sys/fs/cgroup/cpu# 目录下大概有这么一些内容assist cgroup.event_control cgroup.sane_behavior cpuacct.stat cpuacct.usage_percpu cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat notify_on_release system.slicecgroup.clone_children cgroup.procs cpuacct.usage cpu.cfs_period_us cpu.rt_period_us cpu.shares release_agent tasks 下面以限制 cpu 为例，展示 Cgroups 是如何进行资源限制的： 首先在 cpu 子系统下面创建一个目录 container，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下： 123[root@iz2ze0ephck4d0aztho5r5z cpu]# mkdir container[root@iz2ze0ephck4d0aztho5r5z cpu]# ls container/cgroup.clone_children cgroup.event_control cgroup.procs cpuacct.stat cpuacct.usage cpuacct.usage_percpu cpu.cfs_period_us cpu.cfs_quota_us cpu.rt_period_us cpu.rt_runtime_us cpu.shares cpu.stat notify_on_release tasks container 这个目录就称为一个“控制组”。操作系统会在你新创建的 container 目录下，自动生成 该子系统对应的资源限制文件。 现在，我们在后台执行这样一条脚本: 12$ while : ; do : ; done &amp;[1] 27218 上面的脚本执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 27218。 查看一下CPU占用 1234$ topPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 27218 root 20 0 115680 672 152 R 99.9 0.0 2:07.07 bash 果然这个PID=27218的进程占用了差不多100%的 CPU 资源。 接下来我们就通过 Cgroups 对其进行限制，就用前面创建的 container 这个“控制组”。 我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）： 1234$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us -1$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 100000 文件功能说明(设定CPU使用周期使用时间上限): cpu.cfs_period_us：设定周期时间，必须与cfs_quota_us配合使用。 cpu.cfs_quota_us ：设定周期内最多可使用的时间。这里的配置指task对单个cpu的使用上限，若cfs_quota_us是cfs_period_us的两倍，就表示在两个核上完全使用。数值范围为1000 - 1000,000（微秒）。其他功能说明可参考：https://blog.csdn.net/zhonglinzhang/article/details/64905759 接下来，我们可以通过修改这些文件的内容来设置限制。比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）： 1$ echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 这样意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。 接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了： 1$ echo 27218 &gt; /sys/fs/cgroup/cpu/container/tasks 使用 top 指令查看一下 1234$ topPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 27218 root 20 0 115680 672 152 R 20 0.0 2:07.07 bash 可以看到，计算机的 CPU 使用率立刻降到了 20% (%Cpu0 : 20.3 us) 除 CPU 子系统外，Cgroups 的每一个子系统都有其独有的资源限制能力，比如： blkio，为块设备设定I/O 限制，一般用于磁盘等设备； cpuset，为进程分配单独的 CPU 核和对应的内存节点； memory，为进程设定内存使用的限制。 Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。 而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。 而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令： 1$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash 在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认： 1234$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000 5d5c9f67d 其实就是我们运行的一个 Docker 容器，启动这个容器时，Docker 会为这个容器创建一个与容器标识符相同的 CGroup，在当前的主机上 CGroup 就会有以下的层级关系： 12cpu --- docker --- 5d5c9f67d | --- ... Cgroups 存在的问题 跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。 Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。 但是，如果在容器里执行 top 指令，会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。 造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。 在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。 解决方案: 使用 lxcfs top 命令是从 /prof/stats 目录下获取数据，所以从道理上来讲，容器不挂载宿主机的 /prof/stats 目录就可以了。 lxcfs 就是来实现这个功能的，做法是把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的 /proc/meminfo 位置后。容器中进程读取相应文件内容时，LXCFS 的 FUSE 实现会从容器对应的Cgroup中读取正确的内存限制。从而使得应用获得正确的资源约束设定。kubernetes环境下，也能用，以 ds 方式运行 lxcfs ，自动给容器注入争取的 proc 信息。 容器镜像 上面介绍了，Namespace 的作用是“隔离”，它让应用进程只能看到该 Namespace 内的“世界”；而 Cgroups 的作用是“限制”，它给这个“世界”围上了一圈看不 见的墙。这么一折腾，进程就真的被“装”在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用“沙盒”。 可是，还有一个问题不知道你有没有仔细思考过：这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？换句话说，容器里的进程看到的文件系统又是什么样子的呢？ 以 Dorcker 容器为例： Docker 镜像是一个只读的 Docker 容器模板，含有启动 Docker 容器所需的文件系统结构及其内容，因此是启动一个 Docker 容器的基础。Docker 镜像的文件内容以及一些运行 Docker 容器的配置文件组成了 Docker 容器的静态文件系统运行环境一rootfs。 可以这么理解，Docker镜像是Docker容器的静态视角，Docker容器是Docker像的运行状态。 rootfsrootfs 是Docker容器在启动时内部进程可见的文件系统，即Docker容器的根目录。rootfs 通常包含一个操作系统运行所需的文件系统，例如可能包含典型的类Unix操作系统中的目录系统，如/dev, /proc, /bin, /etc, /lib, /usr, /tmp及运行Docke容器所需的配置文件、工具等。 在Docker架构中，当Docker daemon 为Docker容器挂载rootfs时，沿用了Linux内核启动时的方法，即将rootfs设为只读模式。在挂载完毕之后，利用联合挂载(union mount )技术在已有的只读rootfs上再挂载一个读写层。这样，可读写层处于Docker容器文件系统的最顶层，其下可能联合挂载多个只读层，只有在Docker容器运行过程中文件系统发生变化时，才会把变化的文件内容写到可读写层，并隐藏只读层中的老版本文件。 镜像的主要特点分层 Docker镜像是采用分层的方式构建的，每个镜像都由一系列的“镜像层”组成。分层结构是Docker镜像如此轻量的重要原因，当需要修改容器镜像内的某个文件时，只对处于最上方的读写层进行变动，不覆写下层已有文件系统的内容，已有文件在只读层中的原始版本仍然存在，但会被读写层中的新版文件所隐藏。当使用docker commit提交这个修改过的容器文件系统为一个新的镜像时，保存的内容仅为最上层读写文件系统中被更新过的文件。分层达到了在不同镜像之间共享镜像层的效果。 写时复制 Docker镜像使用了写时复制(copy-on-write)策略，在多个容器之间共享镜像，每个容器在启动的时候并不需要单独复制一份镜像文件，而是将所有镜像层以只读的方式挂载到一个挂载点，再在上面覆盖一个可读写的容器层。在未更改文件内容时，所有容器共享同一份数据，只有在Docker容器运行过程中文件系统发生变化时，才会把变化的文件内容写到可读写层，并隐藏只读层中的老版本文件。写时复制配合分层机制减少了镜像对磁盘空间的占用和容器启动时间。 内容寻址 内容寻址存储( content-addressable storage)的机制，根据文件内容来索引镜像和镜像层。docker对镜像层的内容计算校验和，生成一个内容哈希值，并以此哈希值代替之前的UUID作为镜像层的唯一标志。该机制主要提高了镜像的安全性，并在pull, push, load和save操作后检测数据的完整性。另外，基于内容哈希来索引镜像层，在一定程度上减少了ID的冲突并且增强了镜像层的共享。对于来自不同构建的镜像层，只要拥有相同的内容哈希，也能被不同的镜像共享。 联合挂载 通俗地讲，联合挂载技术可以在一个挂载点同时挂载多个文件系统，将挂载点的原目录与被挂载内容进行整合，使得最终可见的文件系统将会包含整合之后的各层的文件和目录。实现这种联合挂载技术的文件系统通常被称为联合文件系统(union filesystem )。 如下图所示，以运行Ubuntu:14.04镜像后容器中的aufs文件系统为例。由于初始挂载时读写层为空，所以从用户的角度看，该容器的文件系统与底层的rootfs没有差别;然而从内核的角度来看，则是显式区分开来的两个层次。当需要修改镜像内的某个文件时，只对处于最上方的读写层进行了变动，不覆写下层已有文件系统的内容，已有文件在只读层中的原始版本仍然存在，但会被读写层中的新版文件所隐藏，当docker commit这个修改过的容器文件系统为一个新的镜像时，保存的内容仅为最上层读写文件系统中被更新过的文件。 解答灵魂三问 (1). docker 镜像的本质是什么？ 答：是一个分层的文件系统。 (2). docker中一个centos镜像大约200M左右，为什么一个centos系统的iso安装文件要好几个G？ 答：centos的iso文件包括bootfs和rootfs，而docker的centos镜像复用操作系统的bootfs。 (3). docker中一个tomcat镜像大约500M左右，为什么一个tomcat安装包不足100M呢？ 答：docker中的镜像是分层的，tomcat虽然只有70多M，但是它需要依赖父镜像和基础镜像，所有整个对外暴露的tomcat镜像大约500M左右。","tags":["container","容器","Docker"],"categories":["Docker"]},{"title":"Docker 系列(二)：Dockerfile & Docker Compose","path":"/docker/docker_compose/","content":"什么是 Dockerfile？ Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 下面通过一个具体的案例来展示如何使用 Dockerfile 来构建镜像。 1、下面以定制一个 nginx 镜像（构建好的镜像内会有一个 /usr/share/nginx/html/index.html 文件） 在一个空目录下，新建一个名为 Dockerfile 文件，并在文件内添加以下内容： 12FROM nginxRUN echo &#x27;这是一个本地构建的nginx镜像&#x27; &gt; /usr/share/nginx/html/index.html 2、开始构建镜像 在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。 注：最后的 . 代表本次执行的上下文路径，下一节会介绍。 1$ docker build -t nginx:v3 . Dockerfile 中所用到的命令可参考： Dockerfile | 菜鸟教程https://www.runoob.com/docker/docker-dockerfile.html Dockerfilehttps://docs.docker.com/engine/reference/builder/ Docker Compose Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 其代码目前在 https://github.com/docker/compose上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 docker-compose.yml 的配置案例如下（配置参数参考下文）： 12345678910111213141516# yaml 配置实例version: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redisvolumes: logvolume01: &#123;&#125; Docker Compose 中所用到的命令可参考： Docker Compose | 菜鸟教程https://www.runoob.com/docker/docker-compose.html Docker Composehttps://docs.docker.com/compose/","tags":["container","容器","Docker"],"categories":["Docker"]},{"title":"为什么说容器是单进程模型？","path":"/docker/docker_single_process/","content":"僵尸进程/孤儿进程 在继续讲解之前，我介绍几个概念： 父进程：父进程拥有一系列的子进程。 子进程：父进程所管理的进程称为子进程。当一个子进程结束时，正常的情况下，父进程会对子进程进行善后处理（获取终止子进程的有关信息、释放它仍占用的资源）。 僵尸进程：当一个子进程终止时，其父进程没有对其进行善后处理，此时我们称这个子进程为僵尸进程。僵尸进程会一直等待父进程来处理自己，如果父进程没有对其进行处理，会造成资源的浪费。 孤儿进程：一个进程都有一个父进程来管理（系统进程除外），如果父进程在子进程结束之前终止，那么我们就称这个子进程为孤儿进程（失去了父亲）。 容器为单进程的原因 我们说 Docker 容器是”单进程模型”，并不代表容器只能运行一个进程，而是指容器没有回收孤儿进程的能力。 通常容器会起一个/bin/sh 进程（称为容器的 1 号进程），如果我们继续在容器中创建进程，那么新的进程都是这个 1 号进程的子进程。Docker 判断一个容器是否启动正常，是判断 Docker 容器的 1 号进程的状态，如果 1 号进程启动正常，那么就认为容器运行正常，否则，容器运行失败。 因此，如果在容器内部启动了过多的进程，那么当容器的 1 号进程结束之后，由于 1 号进程不具有管理多进程，多线程的能力，所以在容器内部创建的其他进程都会处于没有人接管的状态，此时这些进程都会变为孤儿进程。","tags":["container","容器"],"categories":["Docker"]},{"title":"Docker 系列(一)：什么是容器？","path":"/docker/container/","content":"容器，到底是怎么一回事？ 容器其实是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把你的应用 “装” 起来的技术。这样，应用于应用之间，就因为有了边界而不至于互相干扰；而被装进集装箱的应用，也可以被方便的搬来搬去。 容器技术的核心功能，就是通过约束和修改进程（应用）的动态表现，从而为其创造一个 “边界” 动态表现：应用程序启动之后的设涉及到的数据和状态的总和。 在 Linux 中，实现容器的边界，主要有两种技术 Cgroups 和 Namespace. Cgroups 用于对运行的容器进行资源的限制； Namespace 则会将容器隔离起来，实现边界。 所以，容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，为它加上了各种各样的 Namespace 参数。 这时，容器进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，而对于宿主机以及其他不相关的程序，它就完全看不到了。 这样看来，容器只是一种被限制的了特殊进程而已。 虚拟机 vs 容器虚拟机：指的是在一个宿主机上搭建出来的一个完全隔离的环境，这个环境的特点就是，从底层的硬件开始逐级的进行虚拟，虚拟机中的 cpu 内存 硬盘等均进行虚拟（甚至包括网卡 显卡 声卡等也是虚拟的）在这一套虚拟的硬件基础上建立一个虚拟的操作系统，然后在这个虚拟的操作系统里运行应用程序。整套环境和宿主系统完全没有关系的。（可以在 windows 上跑一个 linux） Docker（容器技术）：不会虚拟硬件层，应用软件和系统之间仅隔着一个用于任务调度的 docker engine，docker engine 就是利用 linux 内核技术中的 namespace 和 cgroup（control group） 来隔离进程和资源。进而为宿主和容器，以及容器与容器创建相对独立的环境。这里的环境指的是文件系统，cpu，网络，内存等一系列的资源。这些资源并非独立于宿主之外的一套硬件系统，而是和宿主共用的。 应用程序和宿主共用一套内核空间 虚拟机：虚拟硬件，独立环境； 容器：资源隔离，半独立环境。 虚拟机和容器，两者没有绝对的好与坏，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而 Docker通常用于隔离不同的应用 ，例如前端，后端以及数据库。 什么是 Docker说实话关于Docker是什么并太好说，下面我通过四点向你说明Docker到底是个什么东西。 Docker 是世界领先的软件容器平台。 Docker 是 Google 公司推出的，用 Go 语言进行开发实现，基于 Linux 内核的Cgroup，Namespace，以及 UnionFS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于 LXC. Docker 能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。 Docker 使用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker 是容器技术的一种实现，并不是唯一的。只不过 docker 做的太成功了。所以一提容器技术就会想到 docker 。 docker 成功的地方就在于它将应用程序进行了打包生成镜像，并且提供了一个集中的发行平台。 docker 的侧重点：如果快速部署一个应用 Docker 容器特点 轻量：在一台机器上运行的多个 Docker 容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。 标准：Docker 容器基于开放式标准，能够在所有主流 Linux 版本、Microsoft Windows 以及包括 VM、裸机服务器和云在内的任何基础设施上运行。 安全：Docker 赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker 默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。 Docker 存在的问题 资源隔离不彻底（使用 namesapce 和 cgroup 来实现资源隔离，但依然存在一个无法隔离的东西，例如系统时间，如果一个容器是以一个比较高的权限在运行时，可能会将该容器中的病毒传染给宿主系统） 跨平台受限（和技术实现方式有关，因为资源隔离用的是 linux 内核的技术） 容器间资源抢夺 为什么要用 Docker ? 一致的运行环境：Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 “这段代码在我机器上没问题啊” 这类问题。 更快速的启动时间：可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 隔离性：避免公用的服务器，资源会容易受到其他用户的影响。 弹性伸缩，快速扩展： 善于处理集中爆发的服务器使用压力。 迁移方便：可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 持续交付和部署：使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。 Docker 概念Docker 包括三个基本概念: 镜像（Image）：Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器（Container）：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 仓库（Repository）：仓库可看成一个代码控制中心，用来保存镜像。 Docker 使用客户端-服务器 (C/S) 架构模式，使用远程API来管理和创建Docker容器。 Docker 容器通过 Docker 镜像来创建。 镜像(Image):一个特殊的文件系统操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而Docker 镜像（Image），就相当于是一个 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。 Docker 设计时，就充分利用 Union FS的技术，将其设计为分层存储的架构 。 镜像实际是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。　比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器(Container):镜像运行时的实体镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。前面讲过镜像使用的是分层存储，容器也是如此。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新 run ，数据却不会丢失。 仓库(Repository):集中存放镜像文件的地方镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 一个 Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签.。","tags":["container","容器","Docker"],"categories":["Docker"]},{"title":"实现微服务高可用的种种手段","path":"/design/highly-available/","content":"1. 什么是高可用在定义什么是高可用之前，我们可以先定义下什么是不可用：一个网站的内容最终呈现在用户面前需要经过若干个环节，而其中只要任何一个环节出现了故障，都可能导致网站页面不可访问，这个也就是网站不可用的情况。 参考维基百科，看看维基怎么定义高可用： 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。 这个难点或是重点在于 “无中断”，要做到 7x24 小时无中断无异常的服务提供。 2. 为什么需要高可用一套对外提供服务的系统是需要硬件、软件相结合，但是我们的硬件总是会出故障，软件会有 Bug，硬件会慢慢老化，网络总是不稳定，软件会越来越复杂和庞大。 除了硬件软件在本质上无法做到 “无中断”，外部环境也可能导致服务的中断，例如断电，地震，火灾，光纤被挖掘机挖断，这些影响的程度可能更大。 3. 高可用的评价纬度在业界有一套比较出名的评定网站可用性的指标，常用 N 个 9 来量化可用性，可以直接映射到网站正常运行时间的百分比上： 之前就职的一家互联网公司也是按照这个指标去界定可用性，不过在执行的过程中也碰到了一些问题。 例如，有一些服务的升级或数据迁移明明可以在深夜停机或停服务进行，然而考虑到以后的报告要显示出我们的系统达到了多少个 9 的高可用，而放弃停服务这种简单的解决方案，例如停机 2 个小时，就永远也达不到 4 个 9。 然而在一些高并发的场合，例如在秒杀或拼团，虽然服务停止了几分钟，但是这个对整个公司业务的影响可能是非常重大的，分分钟丢失的订单可能是一个庞大的数量。 所以 N 个 9 来量化可用性其实也得考虑业务的情况。 4. 微服务高可用设计手段高可用是一个比较复杂的命题，基本上在所有的处理中都会涉及到高可用，所有在设计高可用方案也涉及到了方方面面，如服务冗余、负载均衡、服务限流等。 这中间将会出现的细节是多种多样的，所以我们需要对这样一个微服务高可用方案进行一个顶层的设计，围绕服务高可用，先检查下我们手里有多少张牌。 4.1 服务冗余4.1.1 冗余策略每一个访问可能都会有多个服务组合而成，每个机器每个服务都可能出现问题，所以第一个考虑到的就是每个服务必须不止一份可以是多份。 所谓多份一致的服务就是服务的冗余，这里说的服务泛指了机器的服务，容器的服务，还有微服务本身的服务。 在机器服务层面需要考虑，各个机器间的冗余是否有在物理空间进行隔离冗余。 例如是否所有机器分别部署在不同机房，如果在同一个机房是否做到了部署在不同的机柜，如果是 Docker 容器是否部署在分别不同的物理机上面。 采取的策略其实也还是根据服务的业务而定，所以需要对服务进行分级评分，从而采取不同的策略。 不同的策略安全程度不同，伴随着的成本也是不同，安全等级更高的服务可能还不止考虑不同机房，还需要把各个机房所处的区域考虑进行。 例如，两个机房不要处在同一个地震带上等等。 4.1.2 无状态化服务的冗余会要求我们可以随时对服务进行扩容或者缩容，有可能我们会从 2 台机器变成 3 台机器。 想要对服务进行随时随地的扩缩容，就要求我们的服务是一个无状态化，所谓无状态化就是每个服务的服务内容和数据都是一致的。 例如，从我们的微服务架构来看，我们总共分水平划分了好几个层，正因为我们每个层都做到了无状态，所以在这个水平架构的扩张是非常的简单。 假设，我们需要对网关进行扩容，我们只需要增加服务就可以，而不需要去考虑网关是否存储了一个额外的数据。 网关不保存任何的 Session 数据，不提供会造成一致性的服务，将不一致的数据进行几种存储，借助更加擅长数据同步的中间件来完成。 这个是目前主流的方案，服务本身尽可能提供逻辑的服务，将数据的一致性保证集中式处理，这样就可以把 “状态” 抽取出来，让网关保持一个“无状态”。 这里仅仅是举了网关的例子，在微服务基本所有的服务，都应该按照这种思路去做。 如果服务中有状态，就应该把状态抽取出来，让更加擅长处理数据的组件来处理，而不是在微服务中去兼容有数据的状态。 4.2 数据存储高可用之前上面说的服务冗余，可以简单的理解为计算的高可用，计算高可用只需要做到无状态既可简单的扩容缩容，但是对于需要存储数据的系统来说，数据本身就是有状态。 跟存储与计算相比，有一个本质的差别：将数据从一台机器搬到另一台机器，需要经过线路进行传输。 网络是不稳定的，特别是跨机房的网络，Ping 的延时可能是几十几百毫秒，虽然毫秒对于人来说几乎没有什么感觉，但是对于高可用系统来说，就是本质上的不同，这意味着整个系统在某个时间点上，数据肯定是不一致的。 按照 “数据 + 逻辑 = 业务” 的公式来看，数据不一致，逻辑一致，最后的业务表现也会不一致。 举个例子： 无论是正常情况下的传输延时，还是异常情况下的传输中断，都会导致系统的数据在某个时间点出现不一致。 而数据的不一致又会导致业务出现问题，但是如果数据不做冗余，系统的高可用无法保证。 所以，存储高可用的难点不在于怎么备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。 分布式领域中有一个著名的 CAP 定理，从理论上论证了存储高可用的复杂度，也就是说，存储高可用不可能同时满足 “一致性，可用性，分区容错性”。 最多只能满足 2 个，其中分区容错在分布式中是必须的，就意味着，我们在做架构设计时必须结合业务对一致性和可用性进行取舍。 存储高可用方案的本质是将数据复制到多个存储设备中，通过数据冗余的方式来实现高可用，其复杂度主要呈现在数据复制的延迟或中断导致数据的不一致性。 我们在设计存储架构时必须考虑到以下几个方面： 数据怎么进行复制 架构中每个节点的职责是什么 数据复制出现延迟怎么处理 当架构中节点出现错误怎么保证高可用 4.2.1 数据主从复制主从复制是最常见的也是最简单的存储高可用方案，例如 MySQL，Redis 等等。 其架构的优点就是简单，主机复制写和读，而从机只负责读操作，在读并发高时候可用扩张从库的数量减低压力，主机出现故障，读操作也可以保证读业务的顺利进行。 缺点就是客户端必须感知主从关系的存在，将不同的操作发送给不同的机器进行处理。 而且主从复制中，从机器负责读操作，可能因为主从复制时延大，出现数据不一致性的问题。 4.2.2 数据主从切换刚说了主从复制存在两个问题： 主机故障写操作无法进行。 需要人工将其中一台从机器升级为主机。 为了解决这个两个问题，我们可以设计一套主从自动切换的方案，其中涉及到对主机的状态检测，切换的决策，数据丢失和冲突的问题。 主机状态检测： 需要多个检查点来检测主机的机器是否正常，进程是否存在，是否出现超时，是否写操作不可执行，是否读操作不可执行，将其进行汇总，交给切换决策。 切换决策： 确定切换的时间决策，什么情况下从机就应该升级为主机，是进程不存在，是写操作不可行，连续检测多少失败次就进行切换。 应该选择哪一个从节点升级为主节点，一般来说或应该选同步步骤最大的从节点来进行升级。切换是自动切换还是半自动切换，通过报警方式，让人工做一次确认。 数据丢失和数据冲突： 数据写到主机，还没有复制到从机，主机就挂了，这个时候怎么处理，这个也得考虑业务的方式，是要确保 CP 或 AP。 还要考虑一个数据冲突的问题，这个问题在 MySQL 中大部分是由自增主键引起。 就算不考虑自增主键会引起数据冲突的问题，其实自增主键还要引起很多的问题，这里不细说，避免使用自增主键。 4.2.3 数据分片上述的数据冗余可以通过数据的复制来进行解决，但是数据的扩张需要通过数据的分片来进行解决（如果在关系型数据库是分表）。 何为数据分片（Segment、Fragment、Shard、 Partition），就是按照一定的规则，将数据集划分成相互独立、正交的数据子集，然后将数据子集分布到不同的节点上。 HDFS ， MongoDB 的 Sharding 模式也基本是基于这种分片的模式去实现。 我们在设计分片主要考虑到的点是： 做数据分片，如何将数据映射到节点。 数据分片的特征值，即按照数据中的哪一个属性（字段）来分片。 数据分片的元数据的管理，如何保证元数据服务器的高性能、高可用，如果是一组服务器，如何保证强一致性。 4.3 柔性化 / 异步化4.3.1 异步化在每一次调用，时间越长存在超时的风险就越大，逻辑越复杂执行的步骤越多，存在失败的风险也就越大。 如果在业务允许的情况下，用户调用只给用户必须要的结果，而不是需要同步的结果可以放在另外的地方异步去操作，这就减少了超时的风险也把复杂业务进行拆分减低复杂度。 当然异步化的好处是非常多，例如削峰解耦等等，这里只是从可用的角度出发。 异步化大致有这三种的实现方式： 服务端接收到请求后，创建新的线程处理业务逻辑，服务端先回应答给客户端。 服务端接收到请求后，服务端先回应答给客户端，再继续处理业务逻辑。 服务端接收到请求后，服务端把信息保存在消息队列或者数据库，回应答给客户端，服务端业务处理进程再从消息队列或者数据库上读取信息处理业务逻辑。 4.3.2 柔性化什么是柔性化？想象一个场景，我们的系统会给每个下单的用户增加他们下单金额对应的积分，当一个用户下单完毕后，我们给他增加积分的服务出现了问题。 这个时候，我们是要取消掉这个订单还是先让订单通过，积分的问题通过重新或者报警来处理呢？ 所谓的柔性化，就是在我们业务中允许的情况下，做不到给予用户百分百可用的，通过降级的手段给到用户尽可能多的服务，而不是非得每次都交出去要么 100 分或 0 分的答卷。 怎么去做柔性化，更多其实是对业务的理解和判断，柔性化更多是一种思维，需要对业务场景有深入的了解。 在电商订单的场景中，下单，扣库存，支付是一定要执行的步骤，如果失败则订单失败。 但是加积分，发货，售后是可以柔性处理，就算出错也可以通过日志报警让人工去检查，没必要为加积分损失整个下单的可用性。 4.4 兜底 / 容错兜底可能是我们经常谈论的一种降级的方案，方案是用来实施，但是这里兜底可能更多是一种思想，更多的是一种预案，每个操作都可以犯错，我们也可以接受犯错。 但是每个犯错我们都必须有一个兜底的预案，这个兜底的预案其实就是我们的容错或者说最大程度避免更大伤害的措施，实际上也是一个不断降级的过程。 举个例子： 例如我们首页请求的用户个性化推荐商品的接口，发现推荐系统出错，我们不应该去扩大（直接把异常抛给用户）或保持调用接口的错误，而是应该兼容调用接口的错误，做到更加柔性化。 这时候可以选择获取之前没有失败接口的缓存数据，如果没有则可以获取通用商品不用个性化推荐，如果也没有可以读取一些静态文字进行展示。 由于我们架构进行了分层，分层 App，网关，业务逻辑层，数据访问层等等，在组织结构也进行了划分，与之对应的是前端组，后端业务逻辑组，甚至有中台组等等。 既然有代码和人员架构的层级划分，那么每一层都必须有这样的思想：包容下一层的错误，为上一层提供尽可能无错的服务。 举个例子： 商品的美元售价假设要用商品人民币售价 / 汇率，这个时候错误发生在低层的数据层，上一层如果直接进行除，肯定就抛出 java.lang.ArithmeticException: / by zero。 本着我们对任何一层调用服务都不可信的原则，应该对其进行容错处理，不能让异常扩散，更要保证我们这一层对上一次尽可能的作出最大努力确定的服务。 4.5 负载均衡相信负载均衡这个话题基本已经深入每个做微服务开发或设计者的人心，负载均衡的实现有硬件和软件。 硬件有 F5，A10 等机器；软件有 LVS，Nginx，HAProxy 等等，负载均衡的算法有 Random，RoundRobin，ConsistentHash 等等。 4.5.1 Nginx 负载均衡故障转移 转移流程：Nginx 根据给定好的负载均衡算法进行调度，当请求到 Tomcat1，Nginx 发现 Tomcat1 出现连接错误（节点失效），Nginx 会根据一定的机制将 Tomcat1 从调用的负载列表中清除。 在下一次请求，Nginx 不会分配请求到有问题的 Tomcat1 上面，会将请求转移到其他的 Tomcat 之上。 节点失效： Nginx 默认判断节点失效是以 connect refuse 和 timeout 为标准，在对某个节点进行 fails 累加，当 fails 大于 max_fails 时，该节点失效。 节点恢复： 当某个节点失败的次数大于 max_fails 时，但不超过 fail_timeout，Nginx 将不再对该节点进行探测，直到超过失效时间或者所有的节点都失效，Nginx 会对节点进行重新探测。 4.5.2 zookeeper 负载均衡故障转移 在使用 zookeeper 作为注册中心时，故障的发现是由 ZK 去进行发现，业务逻辑层通过 Watch 的心跳机制将自己注册到 ZK 上，网关对 ZK 进行订阅就可以知道有多少可以调用的列表。 当业务逻辑层在重启或者被关闭时就会跟 ZK 断了心跳，ZK 会更新可调用列表。 使用 ZK 作为负载均衡的协调器，最大的问题是 ZK 对于服务是否可用是基于 Pingpong 的方式。 只要服务心跳存在，ZK 就认为服务是处在可用状态，但是服务如果处在假死的状态，ZK 是无从得知的。这个时候，业务逻辑服务是否真正可用只能够由网关知道。 幂等设计： 为何会牵出幂等设计的问题，主要是因为负载均衡的 Failover 策略，就是对失败的服务会进行重试。 一般来说，如果是读操作的服务，重复执行也不会出问题，但想象一下，如果是一个创建订单减库存的操作，第一次调用也 Tomcat1 超时，再重新调用了 Tomcat2。 这个时候我们都不能确认超时调用的 Tomcat1 是否真的被调用，有可能根本就调用不成功，有可能已经调用成功但是因为某些原因返回超时而已。 所以，很大程度这个接口会被调用 2 次。如果我们没有保证幂等性，就有可能一个订单导致了减少 2 次的库存。 所谓的幂等性，就是得保证在同一个业务中，一个接口被调用了多次，其导致的结果都是一样的。 4.6 服务限流降级熔断先来讲讲微服务中限流 / 熔断的目的是什么，微服务后，系统分布式部署，系统之间通过 RPC 框架通信，整个系统发生故障的概率随着系统规模的增长而增长，一个小的故障经过链路的传递放大，有可能会造成更大的故障。 限流跟高可用的关系是什么？假定我们的系统最多只能承受 500 个人的并发访问，但某个时候突然增加到 1000 个人进来，一下子就把整个系统给压垮了。 本来还有 500 个人能享受到我们系统的服务，突然间变成了所有人都无法得到服务。 与其让 1000 人都无法得到服务，不如就让 500 个人得到服务，拒绝掉另外 500 个人。限流是对访问的隔离，是保证了部门系统承受范围内用户的可用性。 熔断跟高可用的关系是什么？上面说了微服务是一个错综复杂的调用链关系，假设模块 A 调用模块 B，模块 B 又调用了模块 C，模块 C 调用了模块 D。 这个时候，模块 D 出了问题出现严重的时延，这个时候，整个调用链就会被模块 D 给拖垮。 A 等 B，B 等 C，C 等 D，而且 A B C D 的资源被锁死得不到释放，如果流量大的话还容易引起雪崩。 熔断，主动丢弃模块 D 的调用，并在功能上作出一些降级才能保证到我们系统的健壮性。熔断是对模块的隔离，是保证了最大功能的可用性。 4.7 服务治理4.7.1 服务模块划分服务模块与服务模块之间有着千丝万缕的关系，但服务模块在业务中各有权重。 例如订单模块可能是一家电商公司的重中之重，如果出问题将会直接影响整个公司的营收。 而一个后台的查询服务模块可能也重要，但它的重要等级绝对是没有像订单这么重要。 所以，在做服务治理时，必须明确各个服务模块的重要等级，这样才能更好的做好监控，分配好资源。 这个在各个公司有各个公司的一个标准，例如在电商公司，确定服务的级别可能会更加倾向对用户请求数和营收相关的作为指标。 可能真正的划分要比这个更为复杂，必须根据具体业务去定，这个可以从平时服务模块的访问量和流量去预估。 往往更重要的模块也会提供更多的资源，所以不仅要对技术架构了如指掌，还要对公司各种业务形态了然于心才可以。 服务分级不仅仅在故障界定起到重要主要，而且决定了服务监控的力度，服务监控在高可用中起到了一个保障的作用。 它不仅可以保留服务崩溃的现场以等待日后复盘，更重要的是它可以起到一个先知，先行判断的角色，很多时候可以预先判断危险，防范于未然。 4.7.2 服务监控服务监控是微服务治理的一个重要环节，监控系统的完善程度直接影响到我们微服务质量的好坏。 我们的微服务在线上运行的时候有没有一套完善的监控体系能去了解到它的健康情况，对整个系统的可靠性和稳定性是非常重要，可靠性和稳定性是高可用的一个前提保证。 服务的监控更多是对于风险的预判，在出现不可用之间就提前的发现问题，如果系统获取监控报警系统能自我修复则可以将错误消灭在无形，如果系统发现报警无法自我修复则可以通知人员提早进行接入。 一个比较完善的微服务监控体系需要涉及到哪些层次？如下图，大致可以划分为五个层次的监控： 基础设施监控： 例如网络，交换机，路由器等低层设备，这些设备的可靠性稳定性就直接影响到上层服务应用的稳定性。所以需要对网络的流量，丢包情况，错包情况，连接数等等这些基础设施的核心指标进行监控。 系统层监控： 涵盖了物理机，虚拟机，操作系统这些都是属于系统级别监控的方面，对几个核心指标监控，如 CPU 使用率，内存占用率，磁盘 IO 和网络带宽情况。 应用层监控： 例如对 URL 访问的性能，访问的调用数，访问的延迟，还有对服务提供性能进行监控，服务的错误率。对 SQL 也需要进行监控，查看是否有慢 SQL，对于 Cache 来说，需要监控缓存的命中率和性能，每个服务的响应时间和 QPS 等等。 业务监控： 比方说一个电商网站，需要关注它的用户登录情况，注册情况，下单情况，支付情况。这些直接影响到实际触发的业务交易情况，这个监控可以提供给运营和公司高管他们需要关注的数据，直接可能对公司战略产生影响。 端用户监控： 用户通过浏览器，客户端打开连到到我们的服务，那么在用户端用户的体验是怎么样，用户端的性能是怎么样，有没有产生错误，这些信息也是需要进行监控并记录下来。如果没有监控，有可能用户因为某些原因出错或者性能问题造成体验非常的差，而我们并没有感知。 这里面包括了，监控用户端的使用性能，返回码，在哪些城市地区他们的使用情况是怎么样，还有运营商的情况，包括电信，联通用户的连接情况。 我们需要进一步去知道是否有哪些渠道哪些用户接入的时候存在着问题，包括我们还需要知道客户端使用的操作系统浏览器的版本。 5. 总结出了那么多张牌，出牌只是术，真正的道还是得静下心来看看整个服务高可用的本质是什么。 随着微服务架构的相互调用越来越复杂，环节只会越来越多，只有建立清晰的架构和层次才能理清楚每个环节高可用的保障，保持简单。 5.1 从手段看高可用主要使用的技术手段是服务和数据的冗余备份和失效转移，一组服务或一组数据都能在多节点上，之间相互备份。 当一台机器宕机或出现问题的时候，可以从当前的服务切换到其他可用的服务，不影响系统的可用性，也不会导致数据丢失。 5.2 从架构看高可用保持简单的架构，目前多数网站采用的是比较经典的分层架构，应用层，服务层，数据层。 应用层是处理一些业务逻辑，服务层提供一些数据和业务紧密相关服务，数据层负责对数据进行读写。 简单的架构可以使应用层，服务层可以保持无状态化进行水平扩展，这个属于计算高可用。 相比计算高可用，在数据层思考的高可用则属于数据高可用，数据高可用相比计算高可用需要考虑到数据的一致性问题会更加的复杂。 这个时候 CAP 理论在里面会发挥关键的作用，究竟是选择 AP 或 CP，这个得根据业务去选择模型。 5.3 从硬件看高可用首先得确认硬件总是可能坏的，网络总是不稳定的。解决它的方法也是一个服务器不够就来多几个，一个机柜不够就来几个，一个机房不够就来几个。 5.4 从软件看高可用软件的开发不严谨，发布不规范也是导致各种不可用出现，通过控制软件开发过程质量监控，通过测试，预发布，灰度发布等手段也是减少不可用的措施。 5.5 从治理看高可用一个系统在线上跑的好好的，但我们也不能确保它在下一秒会不会出现不可用状态。 将服务规范化，事前做好服务分割，做好服务监控，预判不可用的出现，在不可用出现之前发现问题，解决问题。","tags":["高可用","微服务"],"categories":["高可用","微服务"]},{"title":"Redis 持久化： AOF & RDB","path":"/redis/redis_persistence/","content":"Redis 的一个普遍使用场景是把它当作缓存使用，因为它把后端数据库中的数据存储在内存中，然后直接从内存中读取数据，响应速度会非常快。但是，这里也有一个绝对不能忽略的问题：一旦服务器宕机，内存中的数据将全部丢失。 很容易想到的一个解决方案是，从后端数据库恢复这些数据，但这种方式存在两个问题：一是，需要频繁访问数据库，会给数据库带来巨大的压力；二是，这些数据是从慢速数据库中读取出来的，性能肯定比不上从 Redis 中读取，导致使用这些数据的应用程序响应变慢。所以，对 Redis 来说，实现数据的持久化，避免从后端数据库中进行恢复，是至关重要的。目前，Redis 的持久化主要有两大机制，即 AOF（Append Only File）日志和 RDB 快照。 AOF说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志，如下图所示： AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。 我们以 Redis 收到“set testkey testvalue”命令后记录的日志为例，看看 AOF 日志的内容。 其中，“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。 好处 避免额外的检查命令开销 不会阻塞当前的写操作 风险 数据丢失：如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。 阻塞风险：AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。 仔细分析的话，这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。 三种写回策略AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值。 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘； Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 “同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能； 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了； “每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。 想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。 AOF 重写AOF 是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大。这也就意味着，我们一定要小心 AOF 文件过大带来的性能问题。 这里的“性能问题”，主要在于以下三个方面： 一是，文件系统本身对文件大小有限制，无法保存过大的文件； 二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低； 三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。 所以，我们就要采取一定的控制手段，这个时候，AOF 重写机制就登场了。 简单来说，AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。 比如说，当读取了键值对“testkey”: “testvalue”之后，重写机制会记录 set testkey testvalue 这条命令。这样，当需要恢复时，可以重新执行该命令，实现“testkey”: “testvalue”的写入。 虽然 AOF 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。 和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。 我把重写的过程总结为“一个拷贝，两处日志”。 “一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。 “两处日志”又是什么呢？ 因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。 总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。 RDBAOF 是每次执行只需要记录操作命令，需要持久化的数据量不大。一般而言，只要你采用的不是 always 的持久化策略，就不会对性能造成太大影响。但是，也正因为记录的是操作命令，而不是实际的数据，所以，用 AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响到正常使用。 RDB 采用的是内存快照的方式。所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。对 Redis 来说，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。 和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。 全量快照Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。 这样做的好处是，一次性记录了所有数据，一个都不少。当你给一个人拍照时，只用协调一个人就够了，但是，拍 100 人的大合影，却需要协调 100 个人的位置、状态，等等，这当然会更费时费力。同样，给内存的全量数据做快照，把它们全部写入磁盘也会花费很多时间。而且，全量数据越多，RDB 文件就越大，往磁盘上写数据的时间开销就越大。 Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。 save：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。 除此之外，Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。 此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本（键值对 C’）。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。 这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。 增量快照对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。 但是，如果频繁地执行全量快照，也会带来两方面的开销。 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。 此时，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。 增量快照的问题：如果我们对每一个键值对的修改，都做个记录，那么，如果有 1 万个被修改的键值对，我们就需要有 1 万条额外的记录。而且，有的时候，键值对非常小，比如只有 32 字节，而记录它被修改的元数据信息，可能就需要 8 字节，这样的画，为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的 Redis 来说，有些得不偿失。 混合快照Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。 这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。 总结最后，关于 AOF 和 RDB 的选择问题，有三点建议： 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。","tags":["可靠性","redis","持久化"],"categories":["Redis"]},{"title":"Mysql 性能优化","path":"/mysql/performance_optimization/","content":"数据库优化维度有四个： 硬件升级 系统配置 表结构设计 SQL语句及索引 优化选择： 优化成本：硬件升级 &gt; 系统配置 &gt; 表结构设计 &gt; SQL语句及索引。 优化效果：硬件升级 &lt; 系统配置 &lt; 表结构设计 &lt; SQL语句及索引。 系统配置优化从内存中读取数据MySQL 会在内存中保存一定的数据，通过LRU算法将不常访问的数据保存在硬盘文件中。尽可能的扩大内存中的数据量，将数据保存在内存中，从内存中读取数据，可以提升MySQL性能。 扩大innodb_buffer_pool_size，能够全然从内存中读取数据。最大限度降低磁盘操作。 123456789101112mysql&gt; show global status like &#x27;innodb_buffer_pool_pages_%&#x27;;+----------------------------------+-------+| Variable_name | Value |+----------------------------------+-------+| Innodb_buffer_pool_pages_data | 8190 || Innodb_buffer_pool_pages_dirty | 0 || Innodb_buffer_pool_pages_flushed | 12646 || Innodb_buffer_pool_pages_free | 0 | 0 表示已经被用光| Innodb_buffer_pool_pages_misc | 1 || Innodb_buffer_pool_pages_total | 8191 |+----------------------------------+-------+ innodb_buffer_pool_size默认为128M，理论上可以扩大到内存的3/4或4/5。 预热数据默认情况，仅在某条数据被读取一次之后，才会缓存在 innodb_buffer_pool。所以，数据库刚刚启动，须要进行数据预热，将磁盘上的数据尽可能缓存到内存中。 数据预热能够提高读取速度。 对于InnoDB数据库，进行数据预热的脚本是: loadtomem.sql1234567891011121314151617181920212223242526SELECT DISTINCT CONCAT(&#x27;SELECT &#x27;,ndxcollist,&#x27; FROM &#x27;,db,&#x27;.&#x27;,tb,&#x27; ORDER BY &#x27;,ndxcollist,&#x27;;&#x27;) SelectQueryToLoadCacheFROM ( SELECT engine,table_schema db,table_name tb, index_name,GROUP_CONCAT(column_name ORDER BY seq_in_index) ndxcollist FROM ( SELECT B.engine,A.table_schema,A.table_name, A.index_name,A.column_name,A.seq_in_index FROM information_schema.statistics A INNER JOIN ( SELECT engine,table_schema,table_name FROM information_schema.tables WHERE engine=&#x27;InnoDB&#x27; ) B USING (table_schema,table_name) WHERE B.table_schema NOT IN (&#x27;information_schema&#x27;,&#x27;mysql&#x27;) ORDER BY table_schema,table_name,index_name,seq_in_index ) A GROUP BY table_schema,table_name,index_name ) AAORDER BY db,tb; 在需要数据预热时（比如重启数据库）执行命令： 1mysql -uroot &lt; /root/loadtomem.sql &gt; /dev/null 2&gt;&amp;1 减少磁盘写入次数1. 增大redolog，减少落盘次数 innodb_log_file_size 设置为 0.25 * innodb_buffer_pool_size 2. 关闭通用查询日志、慢查询日志 ，开启binlog 生产中不开通用查询日志，遇到性能问题开慢查询日志 3. 写redolog策略 innodb_flush_log_at_trx_commit设置为0或2 如果不涉及非常高的安全性 (金融系统)，或者基础架构足够安全，或者事务都非常小，都能够用 0或者 2 来减少磁盘操作。 提高磁盘读写性能使用SSD或者内存磁盘 表结构优化1. 设计中间表 设计中间表，一般针对于统计分析功能，或者实时性不高的需求（OLTP、OLAP） 2. 设计冗余字段 为减少关联查询，创建合理的冗余字段（创建冗余字段还需要注意数据一致性问题） 3. 拆表 对于字段太多的大表，考虑拆表（比如一个表有100多个字段） 对于表中经常不被使用的字段或者存储数据比较多的字段，考虑拆表 4. 主键优化 每张表建议都要有一个主键（主键索引），而且主键类型最好是int类型，建议自增主键。 5. 字段的设计 数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。 尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。 SQL语句及索引优化1. SQL语句中IN包含的值不应过多 MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。 2. SELECT语句务必指明字段名称 SELECT * 增加很多不必要的消耗（CPU、IO、内存、网络带宽）；减少了使用覆盖索引的可能性；当表结构发生改变时，前端也需要更新。所以要求直接在select后面接上字段名。 12345678910111213141516171819mysql&gt; explain select * from tbiguser ;+----+-------------+----------+------+---------------+------+---------+------+---------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+------+---------------+------+---------+------+---------+-------+| 1 | SIMPLE | tbiguser | ALL | NULL | NULL | NULL | NULL | 9754360 | NULL |+----+-------------+----------+------+---------------+------+---------+------+---------+-------+1 row in set (0.00 sec)mysql&gt; explain select id,nickname from tbiguser ;+----+-------------+----------+-------+---------------+--------------+---------+------+---------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+-------+---------------+--------------+---------+------+---------+-------------+| 1 | SIMPLE | tbiguser | index | NULL | idx_nickname | 768 | NULL | 9754360 | Using index |+----+-------------+----------+-------+---------------+--------------+---------+------+---------+-------------+1 row in set (0.00 sec) 3. 当只需要一条数据的时候，使用limit 1 limit 是可以停止全表扫描 12345678910111213141516171819mysql&gt; select * from tbiguser limit 1;+----+----------+-----------+------+------+--------+---------+| id | nickname | loginname | age | sex | status | address |+----+----------+-----------+------+------+--------+---------+| 1 | zy1 | zhaoyun1 | 23 | 1 | 1 | beijing |+----+----------+-----------+------+------+--------+---------+1 row in set (0.00 sec)mysql&gt; explain select * from tbiguser limit 1;+----+-------------+----------+------+---------------+------+---------+------+---------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+------+---------------+------+---------+------+---------+-------+| 1 | SIMPLE | tbiguser | ALL | NULL | NULL | NULL | NULL | 9754360 | NULL |+----+-------------+----------+------+---------------+------+---------+------+---------+-------+1 row in set (0.00 sec) 4. 排序字段加索引 1234567891011121314151617mysql&gt; explain select * from tbiguser where loginname = &#x27;zhaoyun9999999&#x27; order by id ;+----+-------------+----------+-------+---------------+---------+---------+------+---------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+-------+---------------+---------+---------+------+---------+-------------+| 1 | SIMPLE | tbiguser | index | NULL | PRIMARY | 4 | NULL | 9754360 | Using where |+----+-------------+----------+-------+---------------+---------+---------+------+---------+-------------+1 row in set (0.01 sec)mysql&gt; explain select * from tbiguser where loginname = &#x27;zhaoyun9999999&#x27; order by loginname ;+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+| 1 | SIMPLE | tbiguser | ALL | NULL | NULL | NULL | NULL | 9754360 | Using where |+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+1 row in set (0.00 sec) 5. 如果限制条件中其他字段没有索引，尽量少用or or两边的字段中，如果有一个不是索引字段，会造成该查询不走索引的情况。 12345678mysql&gt; explain select * from tbiguser where nickname=&#x27;zy1&#x27; or loginname=&#x27;zhaoyun3&#x27;;+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+| 1 | SIMPLE | tbiguser | ALL | idx_nickname | NULL | NULL | NULL | 9754360 | Using where |+----+-------------+----------+------+---------------+------+---------+------+---------+-------------+1 row in set (0.00 sec) 6. 尽量用union all代替union union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。 7. 不使用ORDER BY RAND() ORDER BY RAND() 不走索引 12345678910111213141516171819202122232425mysql&gt; select * from tbiguser order by rand() limit 10;+---------+-----------+----------------+------+------+--------+---------+| id | nickname | loginname | age | sex | status | address |+---------+-----------+----------------+------+------+--------+---------+| 416412 | zy416412 | zhaoyun416412 | 23 | 1 | 1 | beijing || 4338012 | zy4338012 | zhaoyun4338012 | 23 | 1 | 1 | beijing || 4275017 | zy4275017 | zhaoyun4275017 | 23 | 1 | 1 | beijing || 8572779 | zy8572779 | zhaoyun8572779 | 23 | 1 | 1 | beijing || 2500546 | zy2500546 | zhaoyun2500546 | 23 | 1 | 1 | beijing |+---------+-----------+----------------+------+------+--------+---------+10 rows in set (10.86 sec)mysql&gt; select * from tbiguser t1 join (select rand()*(select max(id) from tbiguser) nid ) t2 on t1.id&gt;t2.nid limit 10;+---------+-----------+----------------+------+------+--------+---------+-------------------+| id | nickname | loginname | age | sex | status | address | nid |+---------+-----------+----------------+------+------+--------+---------+-------------------+| 6580156 | zy6580156 | zhaoyun6580156 | 23 | 1 | 1 | beijing | 6580155.591089424 || 6580157 | zy6580157 | zhaoyun6580157 | 23 | 1 | 1 | beijing | 6580155.591089424 || 6580158 | zy6580158 | zhaoyun6580158 | 23 | 1 | 1 | beijing | 6580155.591089424 || 6580159 | zy6580159 | zhaoyun6580159 | 23 | 1 | 1 | beijing | 6580155.591089424 || 6580160 | zy6580160 | zhaoyun6580160 | 23 | 1 | 1 | beijing | 6580155.591089424 |+---------+-----------+----------------+------+------+--------+---------+-------------------+10 rows in set (0.01 sec) 8. 区分in和exists、not in和not exists 区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。 关于not in和not exists，推荐使用not exists，不仅仅是效率问题，not in可能存在逻辑问题。如何高效的写出一个替代not exists的SQL语句？ 原SQL语句： 1select colname … from A表 where a.id not in (select b.id from B表) 高效的SQL语句： 1select colname … from A表 Left join B表 on where a.id = b.id where b.id is null 9. 使用合理的分页方式以提高分页的效率 分页使用 limit m,n 尽量让m 小。利用主键的定位，可以减小m的值 12345678910111213141516171819mysql&gt; select * from tbiguser limit 9999998, 2;+----------+------------+-----------------+------+------+--------+---------+| id | nickname | loginname | age | sex | status | address |+----------+------------+-----------------+------+------+--------+---------+| 9999999 | zy9999999 | zhaoyun9999999 | 23 | 1 | 1 | beijing || 10000000 | zy10000000 | zhaoyun10000000 | 23 | 1 | 1 | beijing |+----------+------------+-----------------+------+------+--------+---------+2 rows in set (4.72 sec)mysql&gt; select * from tbiguser where id&gt;9999998 limit 2;+----------+------------+-----------------+------+------+--------+---------+| id | nickname | loginname | age | sex | status | address |+----------+------------+-----------------+------+------+--------+---------+| 9999999 | zy9999999 | zhaoyun9999999 | 23 | 1 | 1 | beijing || 10000000 | zy10000000 | zhaoyun10000000 | 23 | 1 | 1 | beijing |+----------+------------+-----------------+------+------+--------+---------+2 rows in set (0.00 sec) 10. 分段查询 一些用户选择页面中，可能一些用户选择的范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。 11. 不建议使用%前缀模糊查询 例如LIKE“%name”或者LIKE“%name%”，这种查询会导致索引失效而进行全表扫描。但是可以使用LIKE“name%”。 那么如何解决这个问题呢，答案：使用全文索引或ES全文检索 12. 避免在where子句中对字段进行表达式操作 1select user_id,user_project from user_base where age*2=36; 中对字段就行了算术运算，这会造成引擎放弃使用索引，建议改成： 1select user_id,user_project from user_base where age=36/2; 13. 避免隐式类型转换 where子句中出现column字段的类型和传入的参数类型不一致的时候发生的类型转换，建议先确定where中的参数类型。 where age=’18’ 14. 对于联合索引来说，要遵守最左前缀法则 举列来说索引含有字段id、name、school，可以直接用id字段，也可以id、name这样的顺序，但是name;school都无法使用这个索引。所以在创建联合索引的时候一定要注意索引字段顺序，常用的查询字段放在最前面。 15. 必要时可以使用force index来强制查询走某个索引 有的时候MySQL优化器采取它认为合适的索引来检索SQL语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用forceindex来强制优化器使用我们制定的索引。 16. 注意范围查询语句 对于联合索引来说，如果存在范围查询，比如between、&gt;、&lt;等条件时，会造成后面的索引字段失效。 17. 使用JOIN优化 LEFT JOIN A表为驱动表，INNER JOIN MySQL会自动找出那个数据少的表作用驱动表，RIGHT JOIN B表为驱动表。 注意： MySQL中没有full join，可以用以下方式来解决： 尽量使用inner join，避免left join： 参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。 合理利用索引： 被驱动表的索引字段作为on的限制字段。 利用小表去驱动大表： 从原理图能够直观的看出如果能够减少驱动表的话，减少嵌套循环中的循环次数，以减少 IO总量及CPU运算的次数。","tags":["性能优化","Mysql"],"categories":["Mysql"]},{"title":"SQL 语句使用了索引, 却还是慢查询？","path":"/mysql/slow-query/","content":"为什么 SQL 语句明明使用了索引，但却还是会记录到慢查询中？ 我有一个大概 13 亿行数据的 MySQL 表 t_people，其中包括字段 ID、AGE、NAME、ADDRESS 等，现在我想查询所有年龄在 10 到 15 岁之间的小朋友，为了提高查询效率，于是我给 AGE 字段建立了索引。 但建完索引之后，我使用 SQL 语句 select * from t_people where age between 10 and 15 开始查询，查询之后发现这条语句居然是个慢查询。 你知道为什么吗？我应该如何优化？ 什么是慢查询为了便于说明，先创建一张表 123456789101112mysql&gt; CREATE TABLE &#x27;t&#x27; ( -&gt; &#x27;id&#x27; int(11) NOT NULL, -&gt; &#x27;a&#x27; int(11) DEFAULT NULL, -&gt; &#x27;b&#x27; int(11) DEFAULT NULL, -&gt; PRIMARY KEY (&#x27;id&#x27;) -&gt; KEY &#x27;a&#x27; (&#x27;a&#x27;) -&gt; ) ENGINE=InnoDB;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t values(1,1,1),(2,2,2);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0 mysql判断sql语句是不是慢查询，是根据语句的执行时间来衡量的. mysql会用语句的执行时间和 long_query_time 这个系统参数做比较. 如果语句执行时间大于long_query_time，都会把这个语句记录到慢查询日志里面。long_query_time的默认值是10s，一般生产环境不会设置这么大的值，一般设置1秒。 语句是否用到索引，是指语句在执行的时候有没有用到表的索引。 在上图所示的样例中， 图一: 未用到索引 图二: 使用主键索引 图三: 使用了 ‘a’ 索引。 图二用到了主键索引，并且是等值查询，可以看到explain的执行中只扫描了一行。但是极端情况下（例如数据库上的CPU压力非常高），那么该sql执行的时间也有可能超过long_query_time，会记录到慢查询日期里面 图三虽然用到了普通索引 a, 但是扫描了整个 a 的索引树，如果数据库中的数据非常多（例如 大于100W）效率就会变慢。 是否执行索引只是表示了一个SQL语句执行的过程，而是否记录到慢查询，是由执行时间决定的，而这个执行时间，可能会受外部因素的影响。 也就是说是否使用索引，和是否记录慢查询之间并没有必然的联系。 什么叫做使用了索引InnoDB 是索引组织表。所有的数据都是存储在索引树上面的。如上面建立的表结构中，共建立了两个索引，一个主键索引，一个普通索引 a，在innoDB里数据是放在主键索引里的。 数据索引示意图如下： 如果执行 explanin select * from t where id &gt; 0 如下图：但是从数据上这个sql一定是做了全表扫描，但是优化器认为，这个sql的执行过程中需要根据主键索引定位到第一个满足 id&gt;0 的值。即便这个sql使用到了索引，实际上也可能是全表扫描。 因此innoDB只有一种情况没有使用到索引，就是从主键索引的最左边的叶子节点开始，向右扫描整个索引树. 也就是说没有使用索引并不是一个准确的描述，你可以用全表扫描表示一个查询遍历了整个主键索引树，也可以用全索引扫描说明像 select a from t这样的查询，它扫描了整个普通的索引树，而像 select * from t where id=2 这样的语句，才是我们平时说的使用了索引，它表示的意思是: 我们使用了索引的快速搜索功能，并且有效的减少了扫描行数。 索引的过滤性假设现在维护了一张记录了整个中国人的基本信息表，假设你要查询所有年龄在10到15岁之间的基本信息，通常语句就会是：select * from t_people where age between 10 and 15 一般都会在age这个字段增加一个索引，否则就是一个全表扫描,但是在建了age上的索引后，这个语句还是执行慢，因为满足这个条件的数据有超过1亿行。建立索引表的组织结构图如下： 那么上面的sql语句执行流程是，从索引age上用树搜索，取出第一个age=10的记录，得到它的主键ID的值，根据ID值去主键索引树取整行的信息，作为结果集的一部分返回，在索引age上向右扫描，取出下一个ID值，到主键索引上取出整行信息，作为结果集的一部分返回。重复改操作，只到碰到第一个 age &gt; 15 的记录。 其实最终我们关心的是扫描行数，对于一个大表，不止要有索引，索引的过滤性也要足够好，像刚才的例子age这个索引，它的过滤性就不够好，在设计表结构的时候，我们要让索引的过滤性足够好，也就是区分度比较高。 那么过滤性好了，是不是标识查询的扫描行数就一定少呢？在看一个例子，参考下图： 如果有一个索引是姓名、年龄的联合索引，那这个联合索引的过滤性应该不错，如果你的执行语句是：select * from t_people where name =&#39;张三&#39; and age = 8 就可以在联合索引上快速找到第一个姓名是张三，并且年龄是8的小朋友. 这样的数据应该不会很多，因此向右扫描的行数也很少，查询效率就很高，但是在查询的过滤性和索引的过滤性不一定是一样的，如果现在你的需求是查出所有名字第一个字是张，并且年龄是8的所有小朋友，SQL语句通常这样写：select * from t_people where name like &#39;张%&#39; and age = 8 在mysql5.5之前的版本中，这个语句的执行流程是这样的： 从联合索引树上找到第一个姓名字段上第一个姓张的记录，取出主键ID，然后到主键索引上，根据ID取出整行的值，判断年龄是否等于8，如果是就做为结果集的一行返回，如果不是就丢弃。 我们把根据ID到主键索引上查找整行数据的这个动作，叫做回表，在联合索引上向右遍历，并重复做回表和判断的逻辑。直到碰到联合索引树上，第一个姓名第一个字不是张的记录为止。 可以看到这个执行过程里面，最耗时的步骤就是回表。假设全国名字第一个字姓张的人有8000W，那么这个该过程就回表8000W次。在定位第一行记录的时候，只能使用索引和联合索引的最左前缀，称为最左前缀原则。 可以看到这个执行过程它的回表次数特别多，性能不够好，有没有优化的方法呢？ 在Mysql5.6版本引入了index condition pushdown 的优化。优化的执行流程是： 从联合索引树上找到第一个年龄字段是张开头的记录，判断这个索引记录上的年龄值是不是8，如果是就回表，取出整行数据，做为结果集返回的一部分，如果不是就就丢弃，不需要回表，在联合索引树上向右遍历，并判断年龄字段后，根据需要做回表，知道碰到联合索引树上，名字的第一个字不是张的记录为止。 这个过程跟上面的过程的差别，是在遍历联合索引的过程中，将age=8这个条件下推到索引遍历的过程中，减少了回表次数。假设全国名字第一个字是张的人里面，有100W个年龄是8的小朋友，那么这个查询过程中，在联合索引里要遍历8000W次，而回表只需要100w次。 可以看到index condition pushdown优化的效果还是很不错的，但是这个优化还是没有绕开最左前缀原则的限制，因此在联合索引里，还是要扫描8000W行，有没有更进一步的优化呢？ 虚拟列可以采用虚拟列的优化方式。 把名字的第一个字，和年龄做一个联合索引，可以使用 mysql5.7 引入的虚拟列来实现，对应的修改表结构的sql语句是这么写的： 1alert table t_people add name_first varchar(2) generated always as (left(name,1)),add index(name_first,age); 虚拟列的值，总是等于 name 字段的前两个字节，虚拟列在插入数据的时候，不能指定值，在更新的时候也不能主动修改，它的值会根据定义自动生成，在那么字段修改的时候，也会自动跟着修改。有了这个新的联合索引，我们再找名字的第一个字是张，并且年龄是8的小朋友的时候，这个SQL语句就可以这么写： 1select * from t_people where name_first=&#x27;张&#x27; and age=8; 这个SQL语句执行的过程，就只需要扫描联合索引的100W行，并回表100W次，这个优化的本质是我么创建了一个更紧凑的索引，来加速了查询的过程。 使用sql优化的过程，往往就是减少扫描行数的过程","tags":["Mysql","索引","慢查询"],"categories":["Mysql"]},{"title":"GitHub不再支持密码验证解决方案：SSH免密与Token登录配置","path":"/tools/github-login-with-token/","content":"问题描述今天提交代码，push到GitHub上，突然出现这个问题。 1234remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.... 官方的解释：https://github.blog/changelog/2021-08-12-git-password-authentication-is-shutting-down/ As previously announced, starting on August 13, 2021, at 09:00 PST, we will no longer accept account passwords when authenticating Git operations on GitHub.com. Instead, token-based authentication (for example, personal access, OAuth, SSH Key, or GitHub App installation token) will be required for all authenticated Git operations. Please refer to this blog post for instructions on what you need to do to continue using git operations securely. Removal August 13, 2021, at 09:00 PST 大致意思是，密码验证于2021年8月13日不再支持，也就是今天intellij不能再用密码方式去提交代码。请用使用 personal access token 替代。 解决方案GitHub Token打开自己的GitHub主页，点击自己的头像找到Settings并进入，在左边目录栏找到Personal access tokens，点击Generate new token，按照步骤申请即可，过程简单。 Scopes（范围）那里建议勾选 ‘repo’ 即可。 创建Token成功后复制这个Token： 以下操作针对于Window操作系统，首先打开控制面板，将查看方式切换到“小图标”，再打开“凭据管理”。 选择“Window凭据”： 向下滑动找到“github”： 点击编辑，再将刚刚复制的Token粘贴到密码处点击保存： 再次操作就不会出现刚才的报错了，其他操作系统也有相应的修改凭据操作，可以尝试一下。","tags":["开发工具","github"],"categories":["开发工具"]},{"title":"二维码扫码登录原理","path":"/framework/scan-qr-code-to-login/","content":"在日常生活中，二维码出现在很多场景，比如超市支付、系统登录、应用下载等等。了解二维码的原理，可以为技术人员在技术选型时提供新的思路。 二维码最常用的场景之一就是通过手机端应用扫描 PC 或者 WEB 端的二维码，来登录同一个系统。 比如手机微信扫码登录 PC 端微信，手机淘宝扫码登录 PC 端淘宝。那么就让我们来看一下，二维码登录是怎么操作的！ 二维码登录的本质二维码登录本质上也是一种登录认证方式。既然是登录认证，要做的也就两件事情！ 告诉系统我是谁 向系统证明我是谁 那么扫码登录是怎么做到这两件事情的呢？ 手机端应用扫PC端二维码，手机端确认后，账号就在PC端登录成功了！这里，PC端登录的账号肯定与手机端是同一个账号。不可能手机端登录的是账号A，而扫码登录以后，PC端登录的是账号B。 所以，第一件事情，告诉系统我是谁，是比较清楚的！通过扫描二维码，把手机端的账号信息传递到PC端，至于是怎么传的，我们后面再说 第二件事情，向系统证明我是谁。扫码登录过程中，用户并没有去输入密码，也没有输入验证码，或者其他什么码。那是怎么证明的呢？ 有些同学会想到，是不是扫码过程中，把密码传到了PC端呢？ 但这是不可能的。因为那样太不安全的，客户端也根本不会去存储密码。 其实手机端APP它是已经登录过的，就是说手机端是已经通过登录认证。所以说只要扫码确认是这个手机且是这个账号操作的，其实就能间接证明我谁。 认识二维码那么如何做确认呢？我们后面会详细说明，在这之前我们需要先认识一下二维码！ 在认识二维码之前我们先看一下一维码！ 所谓一维码，也就是条形码，超市里的条形码–这个相信大家都非常熟悉，条形码实际上就是一串数字，它上面存储了商品的序列号。 二维码其实与条形码类似，只不过它存储的不一定是数字，还可以是任何的字符串，你可以认为，它就是字符串的另外一种表现形式. 系统认证机制认识了二维码，我们了解一下移动互联网下的系统认证机制。 前面我们说过，为了安全，手机端它是不会存储你的登录密码的。 但是在日常使用过程中，我们应该会注意到，只有在你的应用下载下来后，第一次登录的时候，才需要进行一个账号密码的登录， 之后即使这个应用进程被杀掉，或者手机重启，都是不需要再次输入账号密码的，它可以自动登录。 其实这背后就是一套基于token的认证机制，我们来看一下这套机制是怎么运行的， 账号密码登录时，客户端会将设备信息一起传递给服务端， 如果账号密码校验通过，服务端会把账号与设备进行一个绑定，存在一个数据结构中，这个数据结构中包含了账号ID，设备ID，设备类型等等 12345const token = &#123; acountid:&#x27;账号ID&#x27;, deviceid:&#x27;登录的设备ID&#x27;, deviceType:&#x27;设备类型，如 iso,android,pc......&#x27;,&#125; 然后服务端会生成一个 token，用它来映射数据结构，这个 token 其实就是一串有着特殊意义的字符串，它的意义就在于，通过它可以找到对应的账号与设备信息。 客户端得到这个 token 后，需要进行一个本地保存，每次访问系统 API 都携带上 token 与设备信息。 服务端就可以通过 token 找到与它绑定的账号与设备信息，然后把绑定的设备信息与客户端每次传来的设备信息进行比较，如果相同，那么校验通过，返回 API 接口响应数据， 如果不同，那就是校验不通过拒绝访问 客户端不会也没必要保存你的密码，相反，它是保存了 token。 这个 token 这么重要，万一被别人知道了怎么办? 实际上，知道了也没有影响， 因为设备信息是唯一的，只要你的设备信息别人不知道， 别人拿其他设备来访问，验证也是不通过的。 客户端登录的目的，就是获得属于自己的token。 token 和 设备信息一起发送给服务器。既然可以截获token, 是不是也可以截获设备信息呢？如果都两者都拿到了呢？魔高一尺，道高一丈，没有最安全，只有更安全。系统的安全除了token外，还需要其他的保障，技术上比如SSL/TLS通信加密，业务上异常地点登陆验证等。 那么在扫码登录过程中，PC端是怎么获得属于自己的token呢？ 不可能手机端直接把自己的token给PC端用！token只能属于某个客户端私有，其他人或者是其他客户端是用不了的。 下面先梳理一下，扫描二维码登录的一般步骤是什么样的。 扫描二维码登录的一般步骤 扫码前，手机端应用是已登录状态，PC端显示一个二维码，等待扫描 手机端打开应用，扫描PC端的二维码，扫描后，会提示”已扫描，请在手机端点击确认” 用户在手机端点击确认，确认后PC端登录就成功了 可以看到，二维码在中间有三个状态， 待扫描，已扫描待确认，已确认。 基于上面的分析，可以想象 二维码的背后它一定存在一个唯一性的 ID，当二维码生成时，这个 ID 也一起生成，并且绑定了 PC 端的设备信息 手机去扫描这个二维码 二维码切换为 已扫描待确认状态， 此时就会将账号信息与这个 ID 绑定 当手机端确认登录时，它就会生成 PC 端用于登录的 token，并返回给 PC 端 到这里，基本思路就已经清晰了，接下来我们把整个过程再具体化一下 1. 二维码准备按二维码不同状态来看， 首先是等待扫描状态，用户打开PC端，切换到二维码登录界面时。 PC 端向服务端发起请求，告诉服务端，我要生成用户登录的二维码，并且把 PC 端设备信息也传递给服务端 服务端收到请求后，它生成二维码 ID，并将二维码 ID 与 PC 端设备信息进行绑定 然后把二维码 ID 返回给 PC 端 PC 端收到二维码 ID 后，生成二维码(二维码中肯定包含了 ID) 为了及时知道二维码的状态，客户端在展现二维码后，PC 端不断的轮询服务端，比如每隔一秒就轮询一次，请求服务端告诉当前二维码的状态及相关信息 2. 扫描状态切换 用户用手机去扫描PC端的二维码，通过二维码内容取到其中的二维码ID 再调用服务端API将移动端的身份信息与二维码ID一起发送给服务端 服务端接收到后，它可以将身份信息与二维码ID进行绑定，生成临时token。然后返回给手机端 因为PC端一直在轮询二维码状态，所以这时候二维码状态发生了改变，它就可以在界面上把二维码状态更新为已扫描 为什么需要返回给手机端一个临时token呢？ 临时token与token一样，它也是一种身份凭证，不同的地方在于它只能用一次，用过就失效。 在第三步骤中返回临时token，为的就是手机端在下一步操作时，可以用它作为凭证。以此确保扫码，登录两步操作是同一部手机端发出的， 3. 状态确认 手机端在接收到临时 token 后会弹出确认登录界面，用户点击确认时，手机端携带临时 token 用来调用服务端的接口，告诉服务端，我已经确认 服务端收到确认后，根据二维码 ID 绑定的设备信息与账号信息，生成用户 PC 端登录的 token 这时候 PC 端的轮询接口，它就可以得知二维码的状态已经变成了”已确认”。并且从服务端可以获取到用户登录的 token 到这里，登录就成功了， PC 端就可以用 token 去访问服务端的资源了。","tags":["二维码","扫码登录"],"categories":["细节"]},{"title":"kafka的listeners配置错误导致主线程阻塞","path":"/kafka/kafka-listeners-config/","content":"问题背景我们在用kafka的时候，偶尔会遇到这样这样一个问题。 我们写的kafka的客户端程序，在启动的时候，会无缘无故的 卡住（阻塞） 如下图所示： 这时程序会长时间阻塞在这里，无法继续进行后续操作。 问题排查因为日志没有任何报错信息，但是又可以肯定当前项目并没有完全启动成功。感觉像是程序当中有个地方卡到了。通过 VisualVM 工具dump 线程相关的信息，很快发现了问题所在。原来卡在了consumer初始化的地方。 一下是我这边的处理方式，大家可以参考下。如果有更好的方式欢迎大家相互交流。 以下方法是在初始化Consumer的时候进行处理的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public KafkaConsumerImpl init() &#123; if (group == null || group.isEmpty()) &#123; throw new RuntimeException(&quot;phoenix.mq.group is empty&quot;); &#125; Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, namesrvAddr); props.put(ConsumerConfig.GROUP_ID_CONFIG, group); // 是否允许自动提交offset，这里设为false，下面手动提交 props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;); // ... consumer = new KafkaConsumer&lt;&gt;(props); // consumer 订阅的topic及partition topicPartition = new TopicPartition(this.topic, this.partitionId); this.partitions = Collections.singletonList(topicPartition); // 元数据初始化和连接测试，3次失败后抛出异常 Callable&lt;Boolean&gt; call = new Callable&lt;Boolean&gt;() &#123; boolean res = false; int tryTimes = 3; @Override public Boolean call() throws Exception &#123; while (tryTimes-- &gt; 0) &#123; try &#123; consumer.assign(partitions); // 默认初始化offset当前最大值 nextBeginOffset = consumer.position(topicPartition); res = true; break; &#125; catch (Exception e) &#123; if (e instanceof InterruptedException) &#123; break; // 如果position在阻塞状态时，调用了 task.cancel 会抛出此异常。直接退出即可 &#125; LOG.error(e.getMessage(), e); LOG.error(&quot; ==&gt; error when trying to fetch metadata for kafka. topic&lt;&#123;&#125;&gt;, partition&lt;&#123;&#125;&gt;&quot;, topic, partitionId); &#125; // sleep try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return res; &#125; &#125;; FutureTask&lt;Boolean&gt; task = new FutureTask&lt;&gt;(call); new Thread(task).start(); boolean isOk = false; try &#123; isOk = task.get(10000, TimeUnit.MILLISECONDS); &#125; catch (Exception e) &#123; LOG.error(&quot;Get task result timeout&quot;, e); &#125; task.cancel(true); if (isOk) &#123; LOG.info(&quot; ==&gt; init kafka consumer succeed: servers&lt;&#123;&#125;&gt;, topic&lt;&#123;&#125;&gt;, partition&lt;&#123;&#125;&gt;, nextBeginOffset&lt;&#123;&#125;&gt;&quot;, namesrvAddr, topic, partitionId, nextBeginOffset); &#125; else &#123; throw new RuntimeException(String.format( &quot; ==&gt; init kafka consumer failed. please check the conf (listeners or advertised.listeners or ...) and try to ping the host name in the conf value&quot;)); &#125; return this;&#125; 利用 FutureTask 的特性，定义一个定时任务， 在初始化Consumer的时候，尝试去连接kafka，如果配置的kafka的地址有误，或者配置出错在这里可以通过抛出错误体现出来。 最后通过task.get() 方法返回的结果来判断 Consumer 是否成功初始化。","tags":["kafka","线程阻塞"],"categories":["kafka"]},{"title":"[转] kafka 如何体现消息的顺序性","path":"/kafka/kafka-sequence/","content":"顺序消息包括以下两方面： 全局顺序 局部顺序 全局顺序全局顺序，这种要求比较严格。例如Mysql数据库中的binlog日志传输：mysql binlog日志传输要求全局的顺序，不能有任何的乱序。 这种的解决办法通常是最为保守的方式： 全局使用一个生产者 全局使用一个消费者（并严格到一个消费线程） 全局使用一个分区（当然不同的表可以使用不同的分区或者topic实现隔离与扩展） 局部顺序在大部分业务场景下，只需要保证消息局部有序即可，什么是局部有序？ 局部有序是指在某个业务功能场景下保证消息的发送和接收顺序是一致的。如：订单场景，要求订单的创建、付款、发货、收货、完成消息在同一订单下是有序发生的，即消费者在接收消息时需要保证在接收到订单发货前一定收到了订单创建和付款消息。 kafka 中消息顺序性的保障Kafka只能保证单分区内消息顺序有序，无法保证全局有序（同一topic的消息有序） Apache Kafka官方保证了partition内部的数据有效性（追加写、offset读）；为了提高Topic的并发吞吐能力，可以提高Topic的partition数，并通过设置partition的replica来保证数据高可靠，但是在多个Partition时，不能保证Topic级别的数据有序性。 生产者：通过分区的leader副本负责数据顺序写入，来保证消息顺序性 消费者：同一个分区内的消息只能被一个group里的一个消费者消费，保证分区内消费有序 针对这种场景的处理思路是： topic设置一个分区，发送端和消费端开启多线程生产和消费 优缺点： 实现简单 容易遇到瓶颈，服务端压力大 topic设置多个分区，自定义发送端的分区策略，数据发送到同一个分区中，消费端开启多线程消费 优缺点： 扩展多个分区分摊了非同类数据写入同个分区的压力 相同业务的数据在同一个分区依然有热点瓶颈的问题 topic设置多个分区，自定义发送端的分区策略，数据发送不同分区，消费时按发送分区的顺序消费，发送和消费端都启动多线程来提高并发度 自义分区器，使得消息按分区号大小顺序依次发送相同数量大小的数据 发送端和消费端启动多个消费线程进行生产和消费 线程之间按分区号大小顺序消费数据 优缺点： 消费性能极大下降，无法真正并发 消息重试对顺序消息的影响 对于一个有着先后顺序的消息A、B，正常情况下应该是A先发送完成后再发送B，但是在异常情况下，在A发送失败的情况下，B发送成功，而A由于重试机制在B发送完成之后重试发送成功了。这时对于本身顺序为AB的消息顺序变成了BA消息producer在发送消息的时候，对于同一个broker连接是存在多个未确认的消息在同时发送的，也就是存在上面场景说到的情况，虽然A和B消息是顺序的，但是由于存在未知的确认关系，有可能存在A发送失败，B发送成功，A需要重试的时候顺序关系就变成了BA。简之一句就是在发送B时A的发送状态是未知的。针对以上的问题，严格的顺序消费还需要以下参数支持：max.in.flight.requests.per.connection","tags":["kafka","顺序消息"],"categories":["kafka"]},{"title":"Kafka Rebalance机制分析","path":"/kafka/kafka-rebalance/","content":"Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 consumer 如何达成一致，来分配订阅 Topic 的每个分区。 例如：某 Group 下有 20 个 consumer 实例，它订阅了一个具有 100 个 partition 的 Topic 。正常情况下，kafka 会为每个 Consumer 平均的分配 5 个分区。这个分配的过程就是 Rebalance。 触发 Rebalance 的时机Rebalance 的触发条件有3个。 1）组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，亦或是有 Consumer 实例崩溃被“踢出”组。 2）订阅主题数发生变更。Consumer Group 可以使用正则表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance。 3）订阅主题的分区数发生变更。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。 假设目前某个 Consumer Group 下有两个 Consumer，比如 A 和 B，当第三个成员 C 加入时，Kafka 会触发 Rebalance，并根据默认的分配策略重新为 A、B 和 C 分配分区，如下图所示： Rebalance 发生时，Group 下所有 consumer 实例都会协调在一起共同参与，kafka 能够保证尽量达到最公平的分配。但是 Rebalance 过程对 consumer group 会造成比较严重的影响。在 Rebalance 的过程中 consumer group 下的所有消费者实例都会停止工作，等待 Rebalance 过程完成。 Rebalance 过程分析Rebalance 过程分为两步：Join 和 Sync。 Join 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求加入消费组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。 Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。 Rebalance 场景分析新成员加入组 组成员“崩溃”组成员崩溃和组成员主动离开是两个不同的场景。因为在崩溃时成员并不会主动地告知coordinator此事，coordinator有可能需要一个完整的session.timeout周期(心跳周期)才能检测到这种崩溃，这必然会造成consumer的滞后。可以说离开组是主动地发起rebalance；而崩溃则是被动地发起rebalance。 组成员主动离开组 提交位移 Rebalance 的弊端在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病的一个方面。 其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。 其实更高效的做法是尽量减少分配方案的变动。例如实例 A 之前负责消费分区 1、2、3，那么 Rebalance 之后，如果可能的话，最好还是让实例 A 继续消费分区 1、2、3，而不是被重新分配其他的分区。这样的话，实例 A 连接这些分区所在 Broker 的 TCP 连接就可以继续用，不用重新创建连接其他 Broker 的 Socket 资源。 最后，Rebalance 实在是太慢了。 曾经，有个国外用户的 Group 内有几百个 Consumer 实例，成功 Rebalance 一次要几个小时！这完全是不能忍受的。最悲剧的是，目前社区对此无能为力，至少现在还没有特别好的解决方案。 因此一些大数据框架都使用的 standalone consumer。 如何避免不必要的rebalance要避免 Rebalance，还是要从 Rebalance 发生的时机入手。我们在前面说过，Rebalance 发生的时机有三个： 组成员数量发生变化 订阅主题数量发生变化 订阅主题的分区数发生变化 后两个我们大可以人为的避免，发生rebalance最常见的原因是消费组成员的变化。 消费者成员正常的添加和停掉导致rebalance，这种情况无法避免，但是时在某些情况下，Consumer 实例会被 Coordinator 错误地认为 “已停止” 从而被“踢出”Group。从而导致rebalance。 当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。如果某个 Consumer 实例不能及时地发送这些心跳请求，Coordinator 就会认为该 Consumer 已经 “死” 了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。这个时间可以通过Consumer 端的参数 session.timeout.ms进行配置。默认值是 10 秒。 除了这个参数，Consumer 还提供了一个控制发送心跳请求频率的参数，就是 heartbeat.interval.ms。这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance，因为，目前 Coordinator 通知各个 Consumer 实例开启 Rebalance 的方法，就是将 REBALANCE_NEEDED 标志封装进心跳请求的响应体中。 除了以上两个参数，Consumer 端还有一个参数，用于控制 Consumer 实际消费能力对 Rebalance 的影响，即 max.poll.interval.ms 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起 “离开组” 的请求，Coordinator 也会开启新一轮 Rebalance。 通过上面的分析，我们可以看一下那些rebalance是可以避免的： 第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被 “踢出”Group 而引发的。这种情况下我们可以设置 session.timeout.ms 和 heartbeat.interval.ms 的值，来尽量避免rebalance的出现。（以下的配置是在网上找到的最佳实践，暂时还没测试过） 设置 session.timeout.ms = 6s。 设置 heartbeat.interval.ms = 2s。 要保证 Consumer 实例在被判定为 “dead” 之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &gt;= 3 * heartbeat.interval.ms。 将 session.timeout.ms 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer，早日把它们踢出 Group。 第二类非必要 Rebalance 是 Consumer 消费时间过长导致的。此时，max.poll.interval.ms 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。 最后 Consumer 端的因为 GC 设置不合理导致程序频发 Full GC 也可能引发非预期 Rebalance。 总之，要为业务处理逻辑留下充足的时间。这样，Consumer 就不会因为处理这些消息的时间太长而引发 Rebalance 。 小结，调整以下 4 个参数以避免无效 Rebalance： session.timeout.ms heartbeat.interval.ms max.poll.interval.ms GC 参数 相关概念coordinatorGroup Coordinator是一个服务，每个Broker在启动的时候都会启动一个该服务。Group Coordinator的作用是用来存储Group的相关Meta信息，并将对应Partition的Offset信息记录到Kafka内置Topic(__consumer_offsets)中。Kafka在0.9之前是基于Zookeeper来存储Partition的Offset信息(consumers/{group}/offsets/{topic}/{partition})，因为ZK并不适用于频繁的写操作，所以在0.9之后通过内置Topic的方式来记录对应Partition的Offset。 每个Group都会选择一个Coordinator来完成自己组内各Partition的Offset信息，选择的规则如下： 1，计算Group对应在__consumer_offsets上的Partition 2，根据对应的Partition寻找该Partition的leader所对应的Broker，该Broker上的Group Coordinator即就是该Group的Coordinator Partition计算规则： 1partition-Id(__consumer_offsets) = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount) 其中groupMetadataTopicPartitionCount对应offsets.topic.num.partitions参数值，默认值是50个分区。","tags":["kafka"],"categories":["kafka"]},{"title":"Kafka有哪几处地方有分区分配的概念?","path":"/kafka/kafka-partition-alocation/","content":"在 kafka 中，分区分配是一个很重要的概念，它会影响Kafka整体的性能均衡。kafka 中一共有三处地方涉及此概念，分别是： 生产者发送消息 消费者消费消息 创建主题。 虽然这三处的对应操作都可以被称之为 分区分配，但是其实质上所包含的内容却并不相同。 生产者的分区分配用户在使用 kafka 客户端发送消息时，调用 send 方法发送消息之后，消息就自然而然的发送到了 broker 中。 其实这一过程需要经过拦截器、序列化器、分区器等一系列作用之后才能被真正发往 broker。消息在发往 broker 之前需要确认它需要发送到的分区，如果 ProducerRecord 中指定了 partition 字段，那就不需要分区器的作用，因为 partition 就代表的是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。 Kafka中提供的默认分区器是DefaultPartitioner，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器），其中的partition方法就是用来实现具体的分区分配逻辑： 12public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); 默认情况下，如果消息的key不为null，那么默认的分区器会对key进行哈希（采用MurmurHash2算法，具备高运算性能及低碰撞率），最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息将会以轮询的方式发往 topic 的各个可用分区。 注意：如果key不为null，那么计算得到的分区号会是所有分区中的任意一个；如果key为null并且有可用分区，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的差别。 消费者的分区分配在Kafka的默认规则中，每一个分区只能被同一个消费组中的一个消费者消费。消费者的分区分配是指为消费组中的消费者分配所订阅主题中的分区。 如图所示，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。 对于消费者的分区分配而言，Kafka自身提供了三种策略，分别为 RangeAssignor、 RoundRobinAssignor 以及 StickyAssignor ，其中 RangeAssignor 为默认的分区分配策略。 RangeAssignorRangeAssignor策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。 对于每一个topic，RangeAssignor策略会将消费组内所有订阅这个topic的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。 假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。 为了更加通俗的讲解RangeAssignor策略，我们不妨再举一些示例。假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有4个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t0p3、t1p0、t1p1、t1p2、t1p3。最终的分配结果为： 12消费者C0：t0p0、t0p1、t1p0、t1p1消费者C1：t0p2、t0p3、t1p2、t1p3 这样分配的很均匀，那么此种分配策略能够一直保持这种良好的特性呢？我们再来看下另外一种情况。假设上面例子中2个主题都只有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为： 12消费者C0：t0p0、t0p1、t1p0、t1p1消费者C1：t0p2、t1p2 可以明显的看到这样的分配并不均匀，如果将类似的情形扩大，有可能会出现部分消费者过载的情况。对此我们再来看下另一种RoundRobinAssignor策略的分配效果如何。 RoundRobinAssignorRoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。RoundRobinAssignor策略对应的partition.assignment.strategy参数值为：org.apache.kafka.clients.consumer.RoundRobinAssignor。 如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor策略的分区分配会是均匀的。举例，假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为： 12消费者C0：t0p0、t0p2、t1p1消费者C1：t0p1、t1p0、t1p2 如果同一个消费组内的消费者所订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个topic，那么在分配分区的时候此消费者将分配不到这个topic的任何分区。 举例，假设消费组内有3个消费者C0、C1和C2，它们共订阅了3个主题：t0、t1、t2，这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果为： 123消费者C0：t0p0消费者C1：t1p0消费者C2：t1p1、t2p0、t2p1、t2p2 可以看到RoundRobinAssignor策略也不是十分完美，这样分配其实并不是最优解，因为完全可以将分区t1p1分配给消费者C1。 StickyAssignor我们再来看一下StickyAssignor策略，“sticky”这个单词可以翻译为“粘性的”，Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的： 分区的分配要尽可能的均匀； 分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。我们举例来看一下StickyAssignor策略的实际效果。 假设消费组内有3个消费者：C0、C1和C2，它们都订阅了4个主题：t0、t1、t2、t3，并且每个主题有2个分区，也就是说整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下： 123消费者C0：t0p0、t1p1、t3p0消费者C1：t0p1、t2p0、t3p1消费者C2：t1p0、t2p1 这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同，但事实是否真的如此呢？再假设此时消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下： 12消费者C0：t0p0、t1p0、t2p0、t3p0消费者C2：t0p1、t1p1、t2p1、t3p1 如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为： 12消费者C0：t0p0、t1p1、t3p0、t2p0消费者C2：t1p0、t2p1、t0p1、t3p1 可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。 如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。 到目前为止所分析的都是消费者的订阅信息都是相同的情况，我们来看一下订阅信息不同的情况下的处理。 举例，同样消费组内有3个消费者：C0、C1和C2，集群中有3个主题：t0、t1和t2，这3个主题分别有1、2、3个分区，也就是说集群中有t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。消费者C0订阅了主题t0，消费者C1订阅了主题t0和t1，消费者C2订阅了主题t0、t1和t2。 如果此时采用RoundRobinAssignor策略，那么最终的分配结果如下所示（和讲述RoundRobinAssignor策略时的一样，这样不妨赘述一下）： 1234【分配结果集1】消费者C0：t0p0消费者C1：t1p0消费者C2：t1p1、t2p0、t2p1、t2p2 如果此时采用的是StickyAssignor策略，那么最终的分配结果为： 1234【分配结果集2】消费者C0：t0p0消费者C1：t1p0、t1p1消费者C2：t2p0、t2p1、t2p2 可以看到这是一个最优解（消费者C0没有订阅主题t1和t2，所以不能分配主题t1和t2中的任何分区给它，对于消费者C1也可同理推断）。假如此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为： 12消费者C1：t0p0、t1p1消费者C2：t1p0、t2p0、t2p1、t2p2 可以看到RoundRobinAssignor策略保留了消费者C1和C2中原有的3个分区的分配：t2p0、t2p1和t2p2（针对结果集1）。而如果采用的是StickyAssignor策略，那么分配结果为： 12消费者C1：t1p0、t1p1、t0p0消费者C2：t2p0、t2p1、t2p2 可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：t1p0、t1p1、t2p0、t2p1、t2p2。 从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂。 自定义分区分配策略kafka 处理支持默认提供的三种分区分配算法，还支持用户自定义分区分配算法，自定义的分配策略必须要实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口。PartitionAssignor接口的定义如下： 123456789101112131415Subscription subscription(Set&lt;String&gt; topics);String name();Map&lt;String, Assignment&gt; assign(Cluster metadata, Map&lt;String, Subscription&gt; subscriptions);void onAssignment(Assignment assignment);class Subscription &#123; private final List&lt;String&gt; topics; private final ByteBuffer userData;（省略若干方法……）&#125;class Assignment &#123; private final List&lt;TopicPartition&gt; partitions; private final ByteBuffer userData;（省略若干方法……）&#125; PartitionAssignor接口中定义了两个内部类：Subscription和Assignment。 Subscription类用来表示消费者的订阅信息，类中有两个属性：topics和userData，分别表示消费者所订阅topic列表和用户自定义信息。PartitionAssignor接口通过subscription()方法来设置消费者自身相关的Subscription信息，注意到此方法中只有一个参数topics，与Subscription类中的topics的相互呼应，但是并没有有关userData的参数体现。为了增强用户对分配结果的控制，可以在subscription()方法内部添加一些影响分配的用户自定义信息赋予userData，比如：权重、ip地址、host或者机架（rack）等等。 举例，在subscription()这个方法中提供机架信息，标识此消费者所部署的机架位置，在分区分配时可以根据分区的leader副本所在的机架位置来实施具体的分配，这样可以让消费者与所需拉取消息的broker节点处于同一机架。参考下图，消费者consumer1和broker1都部署在机架rack1上，消费者consumer2和broker2都部署在机架rack2上。如果分区的分配不是机架感知的，那么有可能与图（上部分）中的分配结果一样，consumer1消费broker2中的分区，而consumer2消费broker1中的分区；如果分区的分配是机架感知的，那么就会出现图（下部分）的分配结果，consumer1消费broker1中的分区，而consumer2消费broker2中的分区，这样相比于前一种情形而言，既可以减少消费延迟又可以减少跨机架带宽的占用。 再来说一下Assignment类，它是用来表示分配结果信息的，类中也有两个属性：partitions和userData，分别表示所分配到的分区集合和用户自定义的数据。可以通过PartitionAssignor接口中的onAssignment()方法是在每个消费者收到消费组leader分配结果时的回调函数，例如在StickyAssignor策略中就是通过这个方法保存当前的分配方案，以备在下次消费组再平衡（rebalance）时可以提供分配参考依据。 接口中的name()方法用来提供分配策略的名称，对于Kafka提供的3种分配策略而言，RangeAssignor对应的protocol_name为“range”，RoundRobinAssignor对应的protocol_name为“roundrobin”，StickyAssignor对应的protocol_name为“sticky”，所以自定义的分配策略中要注意命名的时候不要与已存在的分配策略发生冲突。这个命名用来标识分配策略的名称，在后面所描述的加入消费组以及选举消费组leader的时候会有涉及。 真正的分区分配方案的实现是在assign()方法中，方法中的参数metadata表示集群的元数据信息，而subscriptions表示消费组内各个消费者成员的订阅信息，最终方法返回各个消费者的分配信息。 Kafka中还提供了一个抽象类org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor，它可以简化PartitionAssignor接口的实现，对assign()方法进行了实现，其中会将Subscription中的userData信息去掉后，在进行分配。Kafka提供的3种分配策略都是继承自这个抽象类。如果开发人员在自定义分区分配策略时需要使用userData信息来控制分区分配的结果，那么就不能直接继承AbstractPartitionAssignor这个抽象类，而需要直接实现PartitionAssignor接口。 下面代码参考Kafka中的RangeAssignor策略来自定义一个随机的分配策略，这里笔者称之为RandomAssignor，具体代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.apache.kafka.clients.consumer;import org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor;import org.apache.kafka.common.TopicPartition;import java.util.*;public class RandomAssignor extends AbstractPartitionAssignor &#123; @Override public String name() &#123; return &quot;random&quot;; &#125; @Override public Map&lt;String, List&lt;TopicPartition&gt;&gt; assign( Map&lt;String, Integer&gt; partitionsPerTopic, Map&lt;String, Subscription&gt; subscriptions) &#123; Map&lt;String, List&lt;String&gt;&gt; consumersPerTopic = consumersPerTopic(subscriptions); Map&lt;String, List&lt;TopicPartition&gt;&gt; assignment = new HashMap&lt;&gt;(); for (String memberId : subscriptions.keySet()) &#123; assignment.put(memberId, new ArrayList&lt;&gt;()); &#125; // 针对每一个topic进行分区分配 for (Map.Entry&lt;String, List&lt;String&gt;&gt; topicEntry : consumersPerTopic.entrySet()) &#123; String topic = topicEntry.getKey(); List&lt;String&gt; consumersForTopic = topicEntry.getValue(); int consumerSize = consumersForTopic.size(); Integer numPartitionsForTopic = partitionsPerTopic.get(topic); if (numPartitionsForTopic == null) &#123; continue; &#125; // 当前topic下的所有分区 List&lt;TopicPartition&gt; partitions = AbstractPartitionAssignor.partitions(topic, numPartitionsForTopic); // 将每个分区随机分配给一个消费者 for (TopicPartition partition : partitions) &#123; int rand = new Random().nextInt(consumerSize); String randomConsumer = consumersForTopic.get(rand); assignment.get(randomConsumer).add(partition); &#125; &#125; return assignment; &#125; // 获取每个topic所对应的消费者列表，即：[topic, List[consumer]] private Map&lt;String, List&lt;String&gt;&gt; consumersPerTopic(Map&lt;String, Subscription&gt; consumerMetadata) &#123; Map&lt;String, List&lt;String&gt;&gt; res = new HashMap&lt;&gt;(); for (Map.Entry&lt;String, Subscription&gt; subscriptionEntry : consumerMetadata.entrySet()) &#123; String consumerId = subscriptionEntry.getKey(); for (String topic : subscriptionEntry.getValue().topics()) put(res, topic, consumerId); &#125; return res; &#125;&#125; 在使用时，消费者客户端需要添加相应的Properties参数，示例如下： 12properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RandomAssignor.class.getName()); 分配的实施我们了解了Kafka中消费者的分区分配策略之后是否会有这样的疑问：如果消费者客户端中配置了两个分配策略，那么以哪个为准？如果有多个消费者，彼此所配置的分配策略并不完全相同，那么以哪个为准？多个消费者之间的分区分配是需要协同的，那么这个协同的过程又是怎样？ 在kafka中有一个组协调器（GroupCoordinator）负责来协调消费组内各个消费者的分区分配，对于每一个消费组而言，在kafka服务端都会有其对应的一个组协调器。具体的协调分区分配的过程如下：1.首先各个消费者向GroupCoordinator提案各自的分配策略。如下图所示，各个消费者提案的分配策略和订阅信息都包含在JoinGroupRequest请求中。2.GroupCoordinator收集各个消费者的提案，然后执行以下两个步骤：一、选举消费组的leader；二、选举消费组的分区分配策略。 选举消费组的分区分配策略比较好理解，为什么这里还要选举消费组的leader，因为最终的分区分配策略的实施需要有一个成员来执行，而这个leader消费者正好扮演了这一个角色。在Kafka中把具体的分区分配策略的具体执行权交给了消费者客户端，这样可以提供更高的灵活性。比如需要变更分配策略，那么只需修改消费者客户端就醒来，而不必要修改并重启Kafka服务端。 怎么选举消费组的leader? 这个分两种情况分析：如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader；如果某一时刻leader消费者由于某些原因退出了消费组，那么就会重新选举一个新的leader，这个重新选举leader的过程又更为“随意”了，相关代码如下： 123//scala code.private val members = new mutable.HashMap[String, MemberMetadata]var leaderId = members.keys.head 解释一下这2行代码：在GroupCoordinator中消费者的信息是以HashMap的形式存储的，其中key为消费者的名称，而value是消费者相关的元数据信息。leaderId表示leader消费者的名称，它的取值为HashMap中的第一个键值对的key，这种选举的方式基本上和随机挑选无异。总体上来说，消费组的leader选举过程是很随意的。 怎么选举消费组的分配策略？投票决定。每个消费者都可以设置自己的分区分配策略，对于消费组而言需要从各个消费者所呈报上来的各个分配策略中选举一个彼此都“信服”的策略来进行整体上的分区分配。这个分区分配的选举并非由leader消费者来决定，而是根据消费组内的各个消费者投票来决定。这里所说的“根据组内的各个消费者投票来决定”不是指GroupCoordinator还要与各个消费者进行进一步交互来实施，而是根据各个消费者所呈报的分配策略来实施。最终所选举的分配策略基本上可以看做是被各个消费者所支持的最多的策略，具体的选举过程如下： 收集各个消费者所支持的所有分配策略，组成候选集candidates。每个消费者从候选集candidates中找出第一个自身所支持的策略，为这个策略投上一票。计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略。如果某个消费者并不支持所选举出的分配策略，那么就会报错。3.GroupCoordinator发送回执给各个消费者，并交由leader消费者执行具体的分区分配。 如上图所示，JoinGroupResponse回执中包含有GroupCoordinator中投票选举出的分配策略的信息。并且，只有leader消费者的回执中包含各个消费者的订阅信息，因为只需要leader消费者根据订阅信息来执行具体的分配，其余的消费并不需要。 4.leader消费者在整理出具体的分区分配方案后通过SyncGroupRequest请求提交给GroupCoordinator，然后GroupCoordinator为每个消费者挑选出各自的分配结果并通过SyncGroupResponse回执以告知它们。 broker端的分区分配生产者的分区分配是指为每条消息指定其所要发往的分区，消费者中的分区分配是指为消费者指定其可以消费消息的分区，而这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。分区分配是否均衡会影响到Kafka整体的负载均衡，具体还会牵涉到优先副本等概念。 在创建主题时，如果使用了replica-assignment参数，那么就按照指定的方案来进行分区副本的创建；如果没有使用replica-assignment参数，那么就需要按照内部的逻辑来计算分配方案了。使用kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。如果集群中所有的broker节点都没有配置broker.rack参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。","tags":["kafka","分区分配"],"categories":["kafka"]},{"title":"Kafka 系列(九)：Kafka 是如何实现精确一次（exactly once）语义的？","path":"/kafka/exactly_once/","content":"本文主要讲述了 Kafka 消息交付可靠性保障以及精确处理一次语义的实现，具体包括幂等生产者和事务生产者。 1. 概述所谓的消息交付可靠性保障，是指 Kafka 对 Producer 和 Consumer 要处理的消息提供什么样的承诺。常见的承诺有以下三种： 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。 至少一次（at least once）：消息不会丢失，但有可能被重复发送。 精确一次（exactly once）：消息不会丢失，也不会被重复发送。 目前，Kafka 默认提供的交付可靠性保障是第二种，即至少一次。 这样虽然不出丢失消息，但是会导致消息重复发送。 Kafka 也可以提供最多一次交付保障，只需要让 Producer 禁止重试即可。 这样一来肯定不会重复发送，但是可能会丢失消息。 无论是至少一次还是最多一次，都不如精确一次来得有吸引力。大部分用户还是希望消息只会被交付一次，这样的话，消息既不会丢失，也不会被重复处理。 Kafka 分别通过 幂等性（Idempotence）和事务（Transaction）这两种机制实现了 精确一次（exactly once）语义。 2. 幂等性（Idempotence）幂等这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。 幂等性最大的优势在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态。 在 Kafka 中，Producer 默认不是幂等性的，但我们可以创建幂等性 Producer。它其实是 0.11.0.0 版本引入的新功能。指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即 props.put(“enable.idempotence”, ture)，或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。 enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。 底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们 “丢弃” 掉。 当然，实际的实现原理并没有这么简单，但你大致可以这么理解。详细分析可参考：Kafka 系列(五)：幂等实现剖析 Kafka 为了实现幂等性，它在底层设计架构中引入了 ProducerID 和 SequenceNumber。 Producer 需要做的只有两件事： 1）初始化时像向 Broker 申请一个 ProducerID 2）为每条消息绑定一个 SequenceNumber Kafka Broker 收到消息后会以 ProducerID 为单位存储 SequenceNumber，也就是说即时 Producer 重复发送了， Broker 端也会将其过滤掉。 实现比较简单，同样的限制也比较大： 首先，它只能保证单分区上的幂等性。即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。 因为 SequenceNumber 是以 Topic + Partition 为单位单调递增的，如果一条消息被发送到了多个分区必然会分配到不同的 SequenceNumber , 导致重复问题。 其次，它只能实现单会话上的幂等性。不能实现跨会话的幂等性。当你重启 Producer 进程之后，这种幂等性保证就丧失了。 重启 Producer 后会分配一个新的 ProducerID，相当于之前保存的 SequenceNumber 就丢失了。 3. 事务（Transaction）Kafka 的事务概念类似于我们熟知的数据库提供的事务。 Kafka 自 0.11 版本开始也提供了对事务的支持，目前主要是在 read committed 隔离级别上做事情。它能保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息。 事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型 Producer 也不惧进程的重启。Producer 重启回来后，Kafka 依然保证它们发送消息的精确一次处理。 设置事务型 Producer 的方法也很简单，满足两个要求即可： 和幂等性 Producer 一样，开启 enable.idempotence = true。 设置 Producer 端参数 transactional. id。最好为其设置一个有意义的名字。 此外，你还需要在 Producer 代码中做一些调整，如这段代码所示： 123456789producer.initTransactions();try &#123; producer.beginTransaction(); producer.send(record1); producer.send(record2); producer.commitTransaction();&#125; catch (KafkaException e) &#123; producer.abortTransaction();&#125; 和普通 Producer 代码相比，事务型 Producer 的显著特点是调用了一些事务 API，如 initTransaction、beginTransaction、commitTransaction 和 abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。 这段代码能够保证 Record1 和 Record2 被当作一个事务统一提交到 Kafka，要么它们全部提交成功，要么全部写入失败。 实际上即使写入失败，Kafka 也会把它们写入到底层的日志中，也就是说 Consumer 还是会看到这些消息。因此在 Consumer 端，读取事务型 Producer 发送的消息也是需要一些变更的。修改起来也很简单，设置 isolation.level 参数的值即可。当前这个参数有两个取值： read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。 很显然，如果你用了事务型 Producer，那么对应的 Consumer 就不要使用这个值。 read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。 当然了，它也能看到非事务型 Producer 写入的所有消息。 4. 小结幂等性 Producer 和事务型 Producer 都是 Kafka 社区力图为 Kafka 实现精确一次处理语义所提供的工具，只是它们的作用范围是不同的。 幂等性 Producer 只能保证单分区、单会话上的消息幂等性； 而事务能够保证跨分区、跨会话间的幂等性。 从交付语义上来看，自然是事务型 Producer 能做的更多。天下没有免费的午餐。比起幂等性 Producer，事务型 Producer 的性能要更差，在实际使用过程中，我们需要仔细评估引入事务的开销，切不可无脑地启用事务。 最后还是建议实际使用时在 Consumer 端也要进行去重，防止重复消费，这样比较稳妥。","tags":["kafka"],"categories":["kafka"]},{"title":"Kafka 系列(八)：如何避免消息丢失?","path":"/kafka/lost_messages/","content":"本文主要从 Producer、Broker、Consumer 等 3 个方面分析了 Kafka 应该如何配置才能避免消息丢失。 1. 概述在使用 MQ 的时候最大的问题就是消息丢失，常见的丢失情况如下： 1）Producer 端丢失 2）Broker 端丢失 3）Consumer 端丢失 一条消息从生产到消费一共要经过以下 3 个流程： 1）Producer 发送到 Broker 2）Broker 保存消息 (持久化) 3）Consumer 消费消息 3 个步骤分别对应了上述的 3 种消息丢失场景。 接下来以 Kafka 为例分析该如何避免这些问题。 2. Kafka 消息持久化保障一句话概括，Kafka 只对 “已提交” 的消息（committed message）做有限度的持久化保证。 其他 MQ 也类似。 第一个核心要素是已提交的消息。 什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为 “已提交” 消息了。 那为什么是若干个 Broker 呢？这取决于你对 “已提交” 的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事情是不变的。 第二个核心要素就是有限度的持久化保证。 也就是说 Kafka 不可能保证在任何情况下都做到不丢失消息。 举个极端点的例子，如果地球都不存在了，Kafka 还能保存任何消息吗？显然不能！ 有限度其实就是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。 3. 具体场景分析3.1 Producer 端丢失Producer 端丢消息更多是因为消息根本没有提交到 Kafka。 目前 Kafka Producer 是异步发送消息的，也就是说如果你调用的是 producer.send(msg) 这个 API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。 这种发送方式有个有趣的名字，叫 “fire and forget”，翻译一下就是 “发射后不管”。如果出现消息丢失，我们是无法知晓的。这个发送方式挺不靠谱, 非常不建议使用。 导致消息没有发送成功的因素也有很多： 1）例如网络抖动，导致消息压根就没有发送到 Broker 端； 2）或者消息本身不合格导致 Broker 拒绝接收（比如消息太大了，超过了 Broker 的承受能力）等。 Kafka 不认为消息是已提交的，因此也就没有 Kafka 丢失消息这一说了。 解决方案也很简单：**Producer 永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)**。 通过回调，一旦出现消息提交失败的情况，你就可以有针对性地进行处理。 举例来说： 如果是因为那些瞬时错误，那么仅仅让 Producer 重试就可以了； 如果是消息不合格造成的，那么可以调整消息格式后再次发送。 总之，处理发送失败的责任在 Producer 端而非 Broker 端。 3.2 Broker 端丢失Broker 丢失消息是由 Kafka 自身原因造成的。Kafka 为了提高吞吐量和性能，采用异步批量的刷盘策略，也就是按照一定的消息量和间隔时间进行刷盘。 Broker 端丢失消息才真的是因为 Kafka 造成的。 Kafka 收到消息后会先存储在也缓存中 (Page Cache) 中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。 Kafka 没有提供同步刷盘的方式，也就是说单个 Broker 丢失消息是必定会出现的。 为了解决单个 broker 数据丢失问题，Kafka 通过 producer 和 broker 协同处理单个 broker 丢失参数的情况： acks=0，producer 不等待 broker 的响应，效率最高，但是消息很可能会丢。 acks=1，leader broker 收到消息后，不等待其他 follower 的响应，即返回 ack。也可以理解为 ack 数为 1。 此时，如果 follower 还没有收到 leader 同步的消息 leader 就挂了，那么消息会丢失。 acks=-1(-1 等效于 all) ，leader broker 收到消息后，挂起，等待所有 ISR 列表中的 follower 返回结果后，再返回 ack。 这种配置下，如果 Leader 刚收到消息就断电，producer 可以知道消息没有被发送成功，将会重新发送。 如果在 follower 收到数据以后，成功返回 ack，leader 断电，数据将存在于原来的 follower 中。在重新选举以后，新的 leader 会持有该部分数据。 在配置为 all 或者 -1 的时候，只要 Producer 收到 Broker 的响应就可以理解为消息已经持久化了。 虽然可能只是刚写入了 PageCache，但是刷盘也就是迟早的事，除非刚好刷盘之前多个 Broker 同时挂了，那确实是没办法了。 建议根据实际情况设置： 如果要严格保证消息不丢失，请设置为 all 或 -1； 如果允许存在丢失，建议设置为 1； 一般不建议设为 0，除非无所谓消息丢不丢失。 3.3 Consumer 端丢失Consumer 端丢失数据主要体现在 Consumer 端要消费的消息不见了。 出现该情况的唯一原因就是：Consumer 没有正确消费消息，就把位移提交了，导致 Kafka 认为该消息已经被消费了，从而导致消息丢失。 可以看出这其实也不是 Kafka 的问题，毕竟 Kafka 也不知道究竟消费没有，只能以 Consumer 提交的位移为依据。 场景 1：获取到消息后直接提交位移了，然后再处理消息。 这样在提交位移后，处理完消息前，如果程序挂掉，这部分消息就算是丢失了。 场景 2：多线程并发消费消息，且开启了自动提交，导致消费完成之前程序就自动提交了位移，如果程序挂掉也会出现消息丢失。 解决方案也很简单：确定消费完成后才提交消息，如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。 4. 最佳实践以下为一些常见的 Kafka 无消息丢失的配置： 避免 Producer 端丢失 1）不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 2）设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 避免 Broker 端丢失 3）设置 acks = all。acks 是 Producer 的一个参数，代表了你对 “已提交” 消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是 “已提交”。这是最高等级的“已提交” 定义。 4）设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 5）设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 6）设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是 “已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 7）确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 避免 Consumer 端丢失 8）确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。 5. 小结消息生命周期中的 3 个地方都可能会出现消息丢失情况： 1）Producer 端：通过回调确保消息成功发送到 Kafka 了 2）Broker 端：通过多 Broker 以及 Producer 端设置 acks=all 降低消息丢失概率 3）Consumer 端：一定要在消息处理完成后再提交位移 需要应用程序和 Kafka 一起配合才能保证消息不丢失。","tags":["kafka"],"categories":["kafka"]},{"title":"Kafka 系列(七)：kafka 对性能的优化","path":"/kafka/kafka-optimization/","content":"性能问题一般常出现在三个地方: 网络 磁盘 复杂度 在 kafka 中性能的优化主要体现在三个方面： Producer Consumer Borker kafka 作为一个分布式队列，网络和磁盘更是优化的重中之重。kafka 中的优化手段主要有以下几种： 压缩 缓存 批量 并发 算法 顺序写一般来说，完成一次磁盘IO，需要经过 寻道、旋转和数据传输 三个步骤。 影响磁盘 IO 性能的因素也就发生在上面三个步骤上，因此主要花费的时间就是： 寻道时间：Tseek 是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O 操作越快，目前磁盘的平均寻道时间一般在 3-15ms。 旋转延迟：Trotation 是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的 1/2 表示。比如：7200rpm 的磁盘平均旋转延迟大约为 60*1000/7200/2 = 4.17ms，而转速为 15000rpm 的磁盘其平均旋转延迟为 2ms。 数据传输时间：Ttransfer 是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前 IDE/ATA 能达到 133MB/s，SATA II 可达到 300MB/s 的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。 因此，如果在写磁盘的时候省去寻道、旋转可以极大地提高磁盘读写的性能。 Kafka 采用顺序写文件的方式来提高磁盘写入性能。顺序写文件，基本减少了磁盘寻道和旋转的次数。磁头再也不用在磁道上乱舞了，而是一路向前飞速前行。 Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 Partition 的末尾，在 Kafka 中 Partition 只是一个逻辑概念，Kafka 将 Partition 划分为多个 Segment，每个 Segment 对应一个物理文件，Kafka 对 segment 文件追加写，这就是顺序写文件。 为什么 Kafka 可以使用追加写的方式呢？ 简单来说，kafka 数据存储在队列中，队列是 FIFO 先进先出模型，保证了数据的有序（同一partition）。正是由于kafka 这种不可变性、有序性使得 kafka 可以使用追加写的方式写文件。 零拷贝零拷贝的核心思想是：尽量去减少数据的拷贝次数，从而减少拷贝的 CPU 开销，以及用户态和内核态的上下文切换次数，从而优化数据传输的性能。 有关零拷贝的详细介绍请参考： 零拷贝 PageCacheproducer 发送消息到 Broker 时，Broker 会使用 write() 系统调用 (对应到 Java NIO 的 FileChannel.write() API)，按偏移量写入数据，此时数据都会先写入page cache。consumer 消费消息时，Broker 使用 sendfile() 系统调用 (对应 FileChannel.transferTo() API)，以零拷贝 的方式将数据从 page cache 传输到 broker 的 Socket buffer，然后再通过网络传输。 leader 与 follower 之间的同步，与上面 consumer 消费数据的过程是同理的。 page cache中的数据会随着内核中 flusher 线程的调度以及对 sync()/fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失。另外，如果 consumer 要消费的消息不在page cache里，才会去磁盘读取，并且会顺便预读出一些相邻的块放入 page cache，以方便下一次读取。 因此如果 Kafka producer 的生产速率与 consumer 的消费速率相差不大，那么就能几乎只靠对 broker page cache 的读写完成整个生产 - 消费过程，磁盘访问非常少。 网络模型Kafka 自己实现了网络模型做 RPC。底层基于 Java NIO，采用和 Netty 一样的 Reactor 线程模型。 这部分暂时还未细究。。。 批量和压缩Kafka Producer 向 Broker 发送消息不是一条消息一条消息的发送。Producer 有两个重要的参数：batch.size和linger.ms。这两个参数就和 Producer 的批量发送有关。 在 producer 端，消息在经过拦截器、序列化器、分区器之后会缓存到消息累加器（RecordAccumulator）中，消息累加器主要用来缓存消息，以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。 Kafka 支持多种压缩算法：lz4、snappy、gzip。Kafka 2.1.0 正式支持 ZStandard —— ZStandard 是 Facebook 开源的压缩算法，旨在提供超高的压缩比 Producer、Broker 和 Consumer 使用相同的压缩算法，在 producer 向 Broker 写入数据，Consumer 向 Broker 读取数据时甚至可以不用解压缩，最终在 Consumer Poll 到消息时才解压，这样节省了大量的网络和磁盘开销。 分区并发Kafka 的 Topic 可以分成多个 Partition，每个 Paritition 类似于一个队列，保证数据有序。同一个 Consumer Group 下的不同 Consumer 并发消费 Paritition，分区实际上是调优 Kafka 并行度的最小单元，因此，可以说，每增加一个 Paritition 就增加了一个消费并发。 Kafka 具有优秀的分区分配算法——StickyAssignor，可以保证分区的分配尽量地均衡，且每一次重分配的结果尽量与上一次分配结果保持一致。这样，整个集群的分区尽量地均衡，各个 Broker 和 Consumer 的处理不至于出现太大的倾斜。 分区数越多越好？ 不是 越多的分区需要打开更多的文件句柄 在 kafka 的 broker 中，每个分区都会对照着文件系统的一个目录。在 kafka 的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。因此，随着 partition 的增多，需要的文件句柄数急剧增加，必要时需要调整操作系统允许打开的文件句柄数。 客户端 / 服务器端需要使用的内存就越多 客户端 producer 有个参数 batch.size，默认是 16KB。它会为每个分区缓存消息，一旦满了就打包将消息批量发出。看上去这是个能够提升性能的设计。不过很显然，因为这个参数是分区级别的，如果分区数越多，这部分缓存所需的内存占用也会更多。 降低高可用性 分区越多，每个 Broker 上分配的分区也就越多，当一个发生 Broker 宕机，那么恢复时间将很长。 高效的文件数据结构Kafka 消息是以 Topic 为单位进行归类，各个 Topic 之间彼此独立，互不影响。每个 Topic 又可以分为一个或多个分区。每个分区各自存在一个记录消息数据的日志文件。 Kafka 每个分区日志在物理上实际按大小被分成多个 Segment。 segment file 组成：每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，后缀 .index、 .timeindex 、.log 分别表示为 segment 索引文件、数据文件。 segment 文件命名规则：partion 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。 Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由 broker 端参数 log.index.interval.bytes指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值，对应地可以增加或缩小索引项的密度。 稀疏索引通过 mmap 的方式，将 index 文件映射到内存，这样对 index 的操作就不需要操作磁盘 IO，以加快索引的查询速度。mmap的 Java 实现对应 MappedByteBuffer 。 mmap 是一种内存映射文件的方法。即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read,write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。mmap 详情可参考 系统调用 mmap 偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。 时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。 稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。 按照二分法找到小于 offset 的 segment 的.log 和.index 用目标 offset 减去文件名中的 offset 得到消息在这个 segment 中的偏移量。 再次用二分法在 index 文件中找到对应的索引。 到 log 文件中，顺序查找，直到找到 offset 对应的消息。 参考文章： https://mp.weixin.qq.com/s/9i4lDtWqOrzJbzN1I1yAwg","tags":["kafka","性能优化"],"categories":["kafka"]},{"title":"Kafka 系列(六)：幂等实现剖析","path":"/kafka/kafka-idempotence/","content":"什么是幂等幂等 这个词原是数学领域中的概念，指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的。 下面通过几个简单的例子说明一下。 比如在乘法运算中，让数字乘以 1 就是一个幂等操作，因为不管你执行多少次这样的运算，结果都是相同的。再比如，取整函数（floor 和 ceiling）是幂等函数，那么运行 1 次 floor(3.4) 和 100 次 floor(3.4)，结果是一样的，都是 3。相反地，让一个数加 1 这个操作就不是幂等的，因为执行一次和执行多次的结果必然不同。 在计算机领域中，幂等性的含义稍微有一些不同： 在命令式编程语言（比如 C）中，若一个子程序是幂等的，那它必然不能修改系统状态。这样不管运行这个子程序多少次，与该子程序关联的那部分系统状态保持不变。 在函数式编程语言（比如 Scala 或 Haskell）中，很多纯函数（pure function）天然就是幂等的，它们不执行任何的 side effect。 幂等性有很多好处，其最大的优势在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态。如果是非幂等性操作，我们还需要担心某些操作执行多次对状态的影响，但对于幂等性操作而言，我们根本无需担心此事。 Producer 幂等性Producer 的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是 Kafka 所提供的幂等性是有条件的： kafka 中的幂等性只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）; kafka 中的幂等性不能跨多个 TopicPartition，只能保证单个 partition 内的幂等性，当涉及多个 Topic-Partition 时，这中间的状态并没有同步。 如果需要跨会话、跨多个 topic-partition 的情况，需要使用 Kafka 的事务性来实现。 Producer 幂等性使用在 Kafka 中，Producer 默认不是幂等性的，但我们可以创建幂等性 Producer。 指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即 props.put(&quot;enable.idempotence&quot;, ture)，或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。 12345678910Properties props = new Properties();props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, &quot;true&quot;);props.put(&quot;acks&quot;, &quot;all&quot;); // 当 enable.idempotence 为 true，这里默认为 allprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);KafkaProducer producer = new KafkaProducer(props);producer.send(new ProducerRecord(topic, &quot;test&quot;); Prodcuer 幂等性对外保留的接口非常简单，其底层的实现对上层应用做了很好的封装，应用层并不需要去关心具体的实现细节，对用户非常友好。 幂等性要解决的问题一般来说，消息可靠性交付保障，提供三种级别： 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。 至少一次（at least once）：消息不会丢失，但有可能被重复发送。 精确一次（exactly once）：消息不会丢失，也不会被重复发送。 kafka 默认提供的就是第二种，即至少一次。 在 kafka 中，消息已提交的含义，通常是Broker 成功接收到消息，并且 Producer 接到 Broker 的应答才会认为该消息成功发送。不过倘若消息成功“提交”，但 Broker 的应答没有成功发送回 Producer 端（比如网络出现瞬时抖动），那么 Producer 就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是 Kafka 默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送。 Kafka 也可以提供最多一次交付保障，只需要让 Producer 禁止重试即可。这样一来，消息要么写入成功，要么写入失败，但绝不会重复发送。我们通常不会希望出现消息丢失的情况，但一些场景里偶发的消息丢失其实是被允许的，相反，消息重复是绝对要避免的。此时，使用最多一次交付保障就是最恰当的。 对于大多数应用而言，数据保证不丢是可以满足其需求的，但是对于一些其他的应用场景（比如支付数据等），它们是要求精确计数的，这时候如果上游数据有重复，下游应用只能在消费数据时进行相应的去重操作，应用在去重时，最常用的手段就是根据唯一 id 键做 check 去重。 在这种场景下，因为上游生产导致的数据重复问题，会导致所有有精确计数需求的下游应用都需要做这种复杂的、重复的去重处理。试想一下：如果在发送时，系统就能保证 exactly once，这对下游将是多么大的解脱。这就是幂等性要解决的问题，主要是解决数据重复的问题，正如前面所述，数据重复问题，通用的解决方案就是加唯一 id，然后根据 id 判断数据是否重复，Producer 的幂等性也是这样实现的，这一小节就让我们看下 Kafka 的 Producer 如何保证数据的 exactly once 的。 Producer 幂等性实现原理正如前面所述，幂等性要解决的问题是：Producer 设置 at least once 时，由于异常触发重试机制导致数据重复，幂等性的目的就是为了解决这个数据重复的问题，简单来说就是： at least once + 幂等 = exactly once kafka Producer 在实现时有两个重要机制： PID（Producer ID），用来标识每个 producer client； sequence numbers，client 发送的每条消息都会带相应的 sequence number，Server 端就是根据这个值来判断数据是否重复。 PID每个 Producer 在初始化时都会被分配一个唯一的 PID，这个 PID 对应用是透明的，完全没有暴露给用户。对于一个给定的 PID，sequence number 将会从0开始自增，每个 Topic-Partition 都会有一个独立的 sequence number。Producer 在发送数据时，将会给每条 msg 标识一个 sequence number，Server 也就是通过这个来验证数据是否重复。 这里的 PID 是全局唯一的，Producer 故障后重新启动后会被分配一个新的 PID，这也是幂等性无法做到跨会话的一个原因。 PID 申请下面我们看下 ProducerId 是如何获取的。 KafkaProducer 中的 Sender 线程在执行发送逻辑之前，会先判断判断是否需要一个新的 ProducerID 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950void runOnce() &#123; // 如果开启了幂等或事务，需要多一些检查 if (transactionManager != null) &#123; try &#123; transactionManager.maybeResolveSequences(); // do not continue sending if the transaction manager is in a failed state if (transactionManager.hasFatalError()) &#123; RuntimeException lastError = transactionManager.lastError(); if (lastError != null) maybeAbortBatches(lastError); client.poll(retryBackoffMs, time.milliseconds()); return; &#125; // 判断是否需要一个新的 ProducerId transactionManager.bumpIdempotentEpochAndResetIdIfNeeded(); if (maybeSendAndPollTransactionalRequest()) &#123; return; &#125; &#125; catch (AuthenticationException e) &#123; // This is already logged as error, but propagated here to perform any clean ups. log.trace(&quot;Authentication exception while processing transactional request&quot;, e); transactionManager.authenticationFailed(e); &#125; &#125; long currentTimeMs = time.milliseconds(); long pollTimeout = sendProducerData(currentTimeMs); client.poll(pollTimeout, currentTimeMs);&#125;synchronized void bumpIdempotentEpochAndResetIdIfNeeded() &#123; if (!isTransactional()) &#123; if (epochBumpRequired) &#123; bumpIdempotentProducerEpoch(); &#125; // 当前不处于初始化状态，并且没有 ProducerId if (currentState != State.INITIALIZING &amp;&amp; !hasProducerId()) &#123; transitionTo(State.INITIALIZING); InitProducerIdRequestData requestData = new InitProducerIdRequestData() .setTransactionalId(null) .setTransactionTimeoutMs(Integer.MAX_VALUE); // 构建初始化ProducerId请求，放入请求队列中 InitProducerIdHandler handler = new InitProducerIdHandler(new InitProducerIdRequest.Builder(requestData), false); enqueueRequest(handler); &#125; &#125;&#125; 之后请求会被发送到服务端（Broker）, 服务端处理该请求的入口是 KafkaApis 中的 handleInitProducerIdRequest() 123456789101112131415161718192021222324252627282930313233343536373839404142434445def handleInitProducerIdRequest(request: RequestChannel.Request, requestLocal: RequestLocal): Unit = &#123; val initProducerIdRequest = request.body[InitProducerIdRequest] val transactionalId = initProducerIdRequest.data.transactionalId // 权限校验 if (transactionalId != null) &#123; if (!authHelper.authorize(request.context, WRITE, TRANSACTIONAL_ID, transactionalId)) &#123; requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception) return &#125; &#125; else if (!authHelper.authorize(request.context, IDEMPOTENT_WRITE, CLUSTER, CLUSTER_NAME, true, false) &amp;&amp; !authHelper.authorizeByResourceType(request.context, AclOperation.WRITE, ResourceType.TOPIC)) &#123; requestHelper.sendErrorResponseMaybeThrottle(request, Errors.CLUSTER_AUTHORIZATION_FAILED.exception) return &#125; // 此处省略部分代码 def sendResponseCallback(result: InitProducerIdResult): Unit = &#123;...&#125; val producerIdAndEpoch = (initProducerIdRequest.data.producerId, initProducerIdRequest.data.producerEpoch) match &#123; // 初始化的是否都是 -1（具体可以看 InitProducerIdRequest 的构造方法），所以进入第一个 case case (RecordBatch.NO_PRODUCER_ID, RecordBatch.NO_PRODUCER_EPOCH) =&gt; Right(None) case (RecordBatch.NO_PRODUCER_ID, _) | (_, RecordBatch.NO_PRODUCER_EPOCH) =&gt; Left(Errors.INVALID_REQUEST) case (_, _) =&gt; Right(Some(new ProducerIdAndEpoch(initProducerIdRequest.data.producerId, initProducerIdRequest.data.producerEpoch))) &#125; producerIdAndEpoch match &#123; // 初始化 ProducerId case Right(producerIdAndEpoch) =&gt; txnCoordinator.handleInitProducerId(transactionalId, initProducerIdRequest.data.transactionTimeoutMs, producerIdAndEpoch, sendResponseCallback, requestLocal) case Left(error) =&gt; requestHelper.sendErrorResponseMaybeThrottle(request, error.exception) &#125;&#125; def handleInitProducerId(transactionalId: String, transactionTimeoutMs: Int, expectedProducerIdAndEpoch: Option[ProducerIdAndEpoch], responseCallback: InitProducerIdCallback, requestLocal: RequestLocal = RequestLocal.NoCaching): Unit = &#123; if (transactionalId == null) &#123; // 最终可以发现，producerId 是由 producerIdManager 来管理的。 val producerId = producerIdManager.generateProducerId() responseCallback(InitProducerIdResult(producerId, producerEpoch = 0, Errors.NONE)) &#125; else if (transactionalId.isEmpty) &#123; ... 看代码可以发现 ProducerIdManager 是一个接口，它有两个实现类 ZkProducerIdManager RPCProducerIdManager ZkProducerIdManager 是通过 zk 来管理 producerId。 PID 端申请是向 ZooKeeper 申请，zk 中有一个 latest_producer_id_block 节点，每个 Broker 向 zk 申请一个 PID 段(默认情况下，每次申请 1000 个 PID)后，都会把自己申请的 PID 段信息写入到这个节点，这样当其他 Broker 再申请 PID 段时，会首先读写这个节点的信息，然后根据 block_end 选择一个 PID 段，最后再把信息写会到 zk 的这个节点，这个节点信息格式如下所示： 1&#123;&quot;version&quot;:1,&quot;broker&quot;:35,&quot;block_start&quot;:&quot;4000&quot;,&quot;block_end&quot;:&quot;4999&quot;&#125; ProducerIdManager 申请 PID 段的流程如下： 先从 zk 的 latest_producer_id_block 节点读取最新已经分配的 PID 段信息； 如果该节点不存在，直接从 0 开始分配，选择 0~1000 的 PID 段（ProducerIdManager 的 PidBlockSize 默认为 1000，即是每次申请的 PID 段大小）； 如果该节点存在，读取其中数据，根据 block_end 选择 这个 PID 段（如果 PID 段超过 Long 类型的最大值，这里会直接返回一个异常）； 在选择了相应的 PID 段后，将这个 PID 段信息写回到 zk 的这个节点中，如果写入成功，那么 PID 段就证明申请成功，如果写入失败（写入时会判断当前节点的 zkVersion 是否与步骤1获取的 zkVersion 相同，如果相同，那么可以成功写入，否则写入就会失败，证明这个节点被修改过），证明此时可能其他的 Broker 已经更新了这个节点（当前的 PID 段可能已经被其他 Broker 申请），那么从步骤 1 重新开始，直到写入成功。 RPCProducerIdManager 是最新版本新实现的一个功能，新版本的kafka 移除zookeeper之后，producerId 将在控制器上分配。 Sequence Numbers有了PID之后，在 PID+Partition 级别上再加上 sequence numbers 信息，就可以实现Producer的幂等性了。 ProducerBatch也提供了setProducerState() 方法（具体执行时机是在 RecordAccumulator 中的 drain 方法中），它可以给一个 batch 添加一些 meta 信息（pid、baseSequence、isTransactional），这些信息是会伴随着 ProduceRequest 发到 Server 端，Server 端也正是通过这些 meta 来做相应的判断。 发送流程客户端发送逻辑当开通幂等功能之后，producer 的发送流程如下： 客户端通过 KafkaProducer 的 send() 方法将数据添加到 RecordAccumulator 中，添加时会判断是否需要新建一个 ProducerBatch，这时这个 ProducerBatch 还是没有 PID 和 sequence number 信息的； Producer 后台发送线程 Sender，在 run() 方法中，会先根据 TransactionManager 的 maybeResolveSequences() 方法判断当前的 PID 是否需要重置，重置的原因是因为：如果有 topic-partition 的 batch 重试多次失败最后因为超时而被移除，这时 sequence number 将无法做到连续，因为 sequence number 有部分已经分配出去，这时系统依赖自身的机制无法继续进行下去（因为幂等性是要保证不丢不重的），相当于程序遇到了一个 fatal 异常，PID 会进行重置，TransactionManager 相关的缓存信息被清空（Producer 不会重启），只是保存状态信息的 TransactionManager 做了 clear+new 操作，遇到这个问题时是无法保证 exactly once 的（有数据已经发送失败了，并且超过了重试次数）； Sender 线程通过 bumpIdempotentEpochAndResetIdIfNeeded() 方法判断是否需要申请 PID，如果需要的话，会想服务端发送 InitProducerIdRequest Sender 线程通过 sendProducerData() 方法发送数据，整体流程与之前的 Producer 流程相似，不同的地方是在 RecordAccumulator 的 drain() 方法中，在加了幂等性之后，drain() 方法多了如下几步判断： 常规的判断：判断这个 topic-partition 是否可以继续发送（如果出现前面2中的情况是不允许发送的）、判断 PID 是否有效、如果这个 batch 是重试的 batch，那么需要判断这个 batch 之前是否还有 batch 没有发送完成，如果有，这里会先跳过这个 Topic-Partition 的发送，直到前面的 batch 发送完成，最坏情况下，这个 Topic-Partition 的 in-flight request 将会减少到1（这个涉及也是考虑到 server 端的一个设置，文章下面会详细分析）； 如果这个 ProducerBatch 还没有这个相应的 PID 和 sequence number 信息，会在这里进行相应的设置； 最后 Sender 线程再调用 sendProduceRequests() 方法发送 ProduceRequest 请求，后面的就跟之前正常的流程保持一致了。 服务端处理逻辑当 Broker 收到 ProduceRequest 请求之后，会通过 KafkaApis.handleProduceRequest() 做相应的处理，其处理流程如下（这里只讲述关于幂等性相关的内容）： 先进行权限校验（这里还不是太理解校验权限的目的） 如果请求是事务请求，检查是否对 TXN.id 有 Write 权限，没有的话返回 TRANSACTIONAL_ID_AUTHORIZATION_FAILED； 如果请求设置了幂等性，检查是否对 ClusterResource 有 IdempotentWrite 权限，没有的话返回 CLUSTER_AUTHORIZATION_FAILED； 验证对 topic 是否有 Write 权限以及 Topic 是否存在，否则返回 TOPIC_AUTHORIZATION_FAILED 或 UNKNOWN_TOPIC_OR_PARTITION 异常； 检查是否有 PID 信息，没有的话走正常的写入流程； UnifiedLog 对象会在 analyzeAndValidateProducerState() 方法先根据 batch 的 sequence number 信息检查这个 batch 是否重复（server 端会缓存 PID 对应这个 Topic-Partition 的最近5个 batch 信息），如果有重复，这里当做写入成功返回（不更新 LOG 对象中相应的状态信息，比如这个 replica 的 the end offset 等）； 有了 PID 信息，并且不是重复 batch 时，在更新 producer 信息时，会做以下校验： 检查该 PID 是否已经缓存中存在 如果不存在，那么判断 sequence number 是否 从0 开始，是的话，在缓存中记录 PID 的 meta（PID，epoch， sequence number），并执行写入操作，否则返回 UnknownProducerIdException（PID 在 server 端已经过期或者这个 PID 写的数据都已经过期了，但是 Client 还在接着上次的 sequence number 发送数据）； 如果该 PID 存在，先检查 PID epoch 与 server 端记录的是否相同； 如果不同并且 sequence number 不从 0 开始，那么返回 OutOfOrderSequenceException 异常； 如果不同并且 sequence number 从 0 开始，那么正常写入； 如果相同，那么根据缓存中记录的最近一次 sequence number（currentLastSeq）检查是否为连续（会区分为 0、Int.MaxValue 等情况），不连续的情况下返回 OutOfOrderSequenceException 异常。 下面与正常写入相同。 幂等性时，Broker 在处理 ProduceRequest 请求时，多了一些校验操作，这里重点看一下其中一些重要实现，先看下 analyzeAndValidateProducerState() 方法的实现，如下所示： analyzeAndValidateProducerState() 到达路径： KafkaApis.handleProduceRequest() ReplicaManager.appendRecords() -&gt; appendToLocalLog() -&gt; appendRecordsToLeader() UnifiedLog.appendAsLeader() -&gt; append() -&gt; analyzeAndValidateProducerState analyzeAndValidateProducerState()1234567891011121314151617181920212223242526272829303132333435private def analyzeAndValidateProducerState(appendOffsetMetadata: LogOffsetMetadata, records: MemoryRecords, origin: AppendOrigin):(mutable.Map[Long, ProducerAppendInfo], List[CompletedTxn], Option[BatchMetadata]) = &#123; val updatedProducers = mutable.Map.empty[Long, ProducerAppendInfo] val completedTxns = ListBuffer.empty[CompletedTxn] var relativePositionInSegment = appendOffsetMetadata.relativePositionInSegment records.batches.forEach &#123; batch =&gt; if (batch.hasProducerId) &#123; // if this is a client produce request, there will be up to 5 batches which could have been duplicated. // If we find a duplicate, we return the metadata of the appended batch to the client. if (origin == AppendOrigin.Client) &#123; val maybeLastEntry = producerStateManager.lastEntry(batch.producerId) maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt; return (updatedProducers, completedTxns.toList, Some(duplicate)) &#125; &#125; // We cache offset metadata for the start of each transaction. This allows us to // compute the last stable offset without relying on additional index lookups. val firstOffsetMetadata = if (batch.isTransactional) Some(LogOffsetMetadata(batch.baseOffset, appendOffsetMetadata.segmentBaseOffset, relativePositionInSegment)) else None val maybeCompletedTxn = updateProducers(producerStateManager, batch, updatedProducers, firstOffsetMetadata, origin) maybeCompletedTxn.foreach(completedTxns += _) &#125; relativePositionInSegment += batch.sizeInBytes &#125; (updatedProducers, completedTxns.toList, None)&#125; 如果这个 batch 有 PID 信息，会首先检查这个 batch 是否为重复的 batch 数据，其实现如下，batchMetadata 会缓存最新 5个 batch 的数据（如果超过5个，添加时会进行删除，这个也是幂等性要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5 的原因，与这个值的设置有关），根据 batchMetadata 缓存的 batch 数据来判断这个 batch 是否为重复的数据。 1234567891011121314151617181920def findDuplicateBatch(batch: RecordBatch): Option[BatchMetadata] = &#123; if (batch.producerEpoch != producerEpoch) None else batchWithSequenceRange(batch.baseSequence, batch.lastSequence)&#125;// Return the batch metadata of the cached batch having the exact sequence range, if any.def batchWithSequenceRange(firstSeq: Int, lastSeq: Int): Option[BatchMetadata] = &#123; val duplicate = batchMetadata.filter &#123; metadata =&gt; firstSeq == metadata.firstSeq &amp;&amp; lastSeq == metadata.lastSeq &#125; duplicate.headOption&#125;private def addBatchMetadata(batch: BatchMetadata): Unit = &#123; if (batchMetadata.size == ProducerStateEntry.NumBatchesToRetain) batchMetadata.dequeue() //note: 只会保留最近 5 个 batch 的记录 batchMetadata.enqueue(batch) //note: 添加到 batchMetadata 中记录，便于后续根据 seq id 判断是否重复&#125; 如果 batch 不是重复的数据，analyzeAndValidateProducerState() 会通过 updateProducers() 更新 producer 的相应记录，在更新的过程中，会做一步校验，校验方法如下所示： 123456789101112131415161718192021222324252627282930313233//note: 检查 seq numberprivate def checkSequence(producerEpoch: Short, appendFirstSeq: Int): Unit = &#123; if (producerEpoch != updatedEntry.producerEpoch) &#123; //note: epoch 不同时 if (appendFirstSeq != 0) &#123; //note: 此时要求 seq number 必须从0开始（如果不是的话，pid 可能是新建的或者 PID 在 Server 端已经过期） //note: pid 已经过期（updatedEntry.producerEpoch 不是-1，证明时原来的 pid 过期了） if (updatedEntry.producerEpoch != RecordBatch.NO_PRODUCER_EPOCH) &#123; throw new OutOfOrderSequenceException(s&quot;Invalid sequence number for new epoch: $producerEpoch &quot; + s&quot;(request epoch), $appendFirstSeq (seq. number)&quot;) &#125; else &#123; //note: pid 已经过期（updatedEntry.producerEpoch 为-1，证明 server 端 meta 新建的，PID 在 server 端已经过期，client 还在接着上次的 seq 发数据） throw new UnknownProducerIdException(s&quot;Found no record of producerId=$producerId on the broker. It is possible &quot; + s&quot;that the last message with t（）he producerId=$producerId has been removed due to hitting the retention limit.&quot;) &#125; &#125; &#125; else &#123; val currentLastSeq = if (!updatedEntry.isEmpty) updatedEntry.lastSeq else if (producerEpoch == currentEntry.producerEpoch) currentEntry.lastSeq else RecordBatch.NO_SEQUENCE if (currentLastSeq == RecordBatch.NO_SEQUENCE &amp;&amp; appendFirstSeq != 0) &#123; //note: 此时期望的 seq number 是从 0 开始,因为 currentLastSeq 是 -1,也就意味着这个 pid 还没有写入过数据 // the epoch was bumped by a control record, so we expect the sequence number to be reset throw new OutOfOrderSequenceException(s&quot;Out of order sequence number for producerId $producerId: found $appendFirstSeq &quot; + s&quot;(incoming seq. number), but expected 0&quot;) &#125; else if (!inSequence(currentLastSeq, appendFirstSeq)) &#123; //note: 判断是否连续 throw new OutOfOrderSequenceException(s&quot;Out of order sequence number for producerId $producerId: $appendFirstSeq &quot; + s&quot;(incoming seq. number), $currentLastSeq (current end sequence number)&quot;) &#125; &#125;&#125; 思考题 Producer 在设置幂等性时，为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5，如果设置大于 5（不考虑 Producer 端参数校验的报错），会带来什么后果？ Producer 在设置幂等性时，如果我们设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 大于 1，那么是否可以保证有序，如果可以，是怎么做到的？ 为什么要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于5之所以要求 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 小于等于 5 的主要原因是： Server 端的 ProducerStateManager 实例会缓存每个 PID 在 Topic-Partition 上发送的最近 5 个batch 数据（这个 5 是写死的，至于为什么是 5，可能跟经验有关，当不设置幂等性时，当这个设置为 5 时，性能相对来说较高，社区是有一个相关测试文档，忘记在哪了），如果超过 5，ProducerStateManager 就会将最旧的 batch 数据清除。 假设应用将 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 6，假设发送的请求顺序是 1、2、3、4、5、6，这时候 server 端只能缓存 2、3、4、5、6 请求对应的 batch 数据，这时候假设请求 1 发送失败，需要重试，当重试的请求发送过来后，首先先检查是否为重复的 batch，这时候检查的结果是否，之后会开始 check 其 sequence number 值，这时候只会返回一个 OutOfOrderSequenceException 异常，client 在收到这个异常后，会再次进行重试，直到超过最大重试次数或者超时，这样不但会影响 Producer 性能，还可能给 Server 带来压力 当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 配置大于1时，是否保证有序先来分析一下，在什么情况下 Producer 会出现乱序的问题？ 没有幂等性时，乱序的问题是在重试时出现的，举个例子：client 依然发送了 6 个请求 1、2、3、4、5、6（它们分别对应了一个 batch），这 6 个请求只有 2-6 成功 ack 了，1 失败了，这时候需要重试，重试时就会把 batch 1 的数据添加到待发送的数据列队中），那么下次再发送时，batch 1 的数据将会被发送，这时候数据就已经出现了乱序，因为 batch 1 的数据已经晚于了 batch 2-6。 当 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION 设置为 1 时，是可以解决这个问题的，因为同时只允许一个请求正在发送，只有当前的请求发送完成（成功 ack 后），才能继续下一条请求的发送，类似单线程处理这种模式，每次请求发送时都会等待上次的完成，效率非常差，但是可以解决乱序的问题（当然这里有序只是针对单 client 情况，多 client 并发写是无法做到的）。 系统能提供的方案，基本上就是有序性与性能之间二选一，无法做到兼容，实际上系统出现请求重试的几率是很小的（一般都是网络问题触发的），可能连 0.1% 的时间都不到，但是就是为了这 0.1% 时间都不到的情况，应用需要牺牲性能问题来解决，在大数据场景下，我们是希望有更友好的方式来解决这个问题。简单来说，就是当出现重试时，max-in-flight-request 可以动态减少到 1，在正常情况下还是按 5 （5是举例说明）来处理，这有点类似于分布式系统 CAP 理论中关于 P 的考虑，当出现问题时，可以容忍性能变差，但是其他的情况下，我们希望的是能拥有原来的性能，而不是一刀切。令人高兴的，在 Kafka 2.0.0 版本中，如果 Producer 开始了幂等性，Kafka 是可以做到这一点的，如果不开启幂等性，是无法做到的，因为它的实现是依赖了 sequence number。 当请求出现重试时，batch 会重新添加到队列中，这时候是根据 sequence number 添加到队列的合适位置（有些 batch 如果还没有 sequence number，那么就保持其相对位置不变），也就是队列中排在这个 batch 前面的 batch，其 sequence number 都比这个 batch 的 sequence number 小，其实现如下，这个方法保证了在重试时，其 batch 会被放到合适的位置： 12345678910111213/** * Re-enqueue the given record batch in the accumulator to retry */public void reenqueue(ProducerBatch batch, long now) &#123; batch.reenqueued(now); //note: 重试,更新相应的 meta Deque&lt;ProducerBatch&gt; deque = getOrCreateDeque(batch.topicPartition); synchronized (deque) &#123; if (transactionManager != null) insertInSequenceOrder(deque, batch); //note: 将 batch 添加到队列的合适位置（根据 seq num 信息） else deque.addFirst(batch); &#125;&#125; 另外 Sender 在发送请求时，会首先通过 RecordAccumulator 的 drain() 方法获取其发送的数据，在遍历 Topic-Partition 对应的 queue 中的 batch 时，如果发现 batch 已经有了 sequence number 的话，则证明这个 batch 是重试的 batch，因为没有重试的 batch 其 sequence number 还没有设置，这时候会做一个判断，会等待其 in-flight-requests 中请求发送完成，才允许再次发送这个 Topic-Partition 的数据，其判断实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243private boolean shouldStopDrainBatchesForPartition(ProducerBatch first, TopicPartition tp) &#123; ProducerIdAndEpoch producerIdAndEpoch = null; if (transactionManager != null) &#123; if (!transactionManager.isSendToPartitionAllowed(tp)) return true; producerIdAndEpoch = transactionManager.producerIdAndEpoch(); if (!producerIdAndEpoch.isValid()) // we cannot send the batch until we have refreshed the producer id return true; if (!first.hasSequence()) &#123; if (transactionManager.hasInflightBatches(tp) &amp;&amp; transactionManager.hasStaleProducerIdAndEpoch(tp)) &#123; // Don&#x27;t drain any new batches while the partition has in-flight batches with a different epoch // and/or producer ID. Otherwise, a batch with a new epoch and sequence number // 0 could be written before earlier batches complete, which would cause out of sequence errors return true; &#125; if (transactionManager.hasUnresolvedSequence(first.topicPartition)) // Don&#x27;t drain any new batches while the state of previous sequence numbers // is unknown. The previous batches would be unknown if they were aborted // on the client after being sent to the broker at least once. return true; &#125; // 获取 inFlightBatches 中第一个 batch 的 baseSequence, inFlightBatches 为 null 的话返回 RecordBatch.NO_SEQUENCE int firstInFlightSequence = transactionManager.firstInFlightSequence(first.topicPartition); if (firstInFlightSequence != RecordBatch.NO_SEQUENCE &amp;&amp; first.hasSequence() &amp;&amp; first.baseSequence() != firstInFlightSequence) //重试操作（seq number 不为0）,如果这个 batch 的 baseSequence 与 in-flight //queue 中第一个 request batch 的 baseSequence不同的话（证明它前面还有请求未成功）, //会等待下次循环再判断, 最坏的情况下会导致 in-flight request 为1（只影响这个 partition） //这种情况下,继续发送这个是没有意义的,因为幂等性时保证顺序的,只有前面的都成功,后面的再发送才有意义 //这里是 break,相当于在这次发送中直接跳过了这个 topic-partition 的发送 // If the queued batch already has an assigned sequence, then it is being retried. // In this case, we wait until the next immediate batch is ready and drain that. // We only move on when the next in line batch is complete (either successfully or due to // a fatal broker error). This effectively reduces our in flight request count to 1. return true; &#125; return false;&#125; 仅有 client 端这两个机制还不够，Server 端在处理 ProduceRequest 请求时，还会检查 batch 的 sequence number 值，它会要求这个值必须是连续的，如果不连续都会返回异常，Client 会进行相应的重试，举个栗子：假设 Client 发送的请求顺序是 1、2、3、4、5（分别对应了一个 batch），如果中间的请求 2 出现了异常，那么会导致 3、4、5 都返回异常进行重试（因为 sequence number 不连续），也就是说此时 2、3、4、5 都会进行重试操作添加到对应的 queue 中。 Producer 的 TransactionManager 实例的 TopicPartitionEntry.inflightBatchesBySequence 成员变量会维护这个 Topic-Partition 与目前正在发送的 batch 的对应关系（通过 addInFlightBatch() 方法添加 batch 记录），只有这个 batch 成功 ack 后，才会通过 removeInFlightBatch() 方法将这个 batch 从 inflightBatchesBySequence 中移除。 接着前面的例子，此时 inflightBatchesBySequence 中还有 2、3、4、5 这几个 batch（有顺序的，2 在前面），根据前面的 RecordAccumulator 的 drain() 方法可以知道只有这个 Topic-Partition 下次要发送的 batch 是 batch 2（跟 transactionManager 的这个 firstInFlightSequence() 方法获取 inFlightBatches 中第一个 batch 的 baseSequence 来判断） 时，才可以发送，否则会直接 break，跳过这个 Topic-Partition 的数据发送。这里相当于有一个等待，等待 batch 2 重新加入到 queue 中，才可以发送，不能跳过 batch 2，直接重试 batch 3、4、5，这是不允许的。 简单来说，其实现机制概括为： Server 端验证 batch 的 sequence number 值，不连续时，直接返回异常； Client 端请求重试时，batch 在 reenqueue 时会根据 sequence number 值放到合适的位置（有序保证之一）； Sender 线程发送时，在遍历 queue 中的 batch 时，会检查这个 batch 是否是重试的 batch，如果是的话，只有这个 batch 是最旧的那个需要重试的 batch，才允许发送，否则本次发送跳过这个 Topic-Partition 数据的发送等待下次发送。","tags":["kafka","幂等"],"categories":["kafka"]},{"title":"Kafka 系列(五)：如何保障数据可靠性？","path":"/kafka/kafka-reliability/","content":"Kafka 中采用了多副本的机制，这是大多数分布式系统中惯用的手法，以此来实现水平扩展、提供容灾能力、提升可用性和可靠性等。 我们对此可以引申出一系列的疑问： Kafka 多副本之间如何进行数据同步，尤其是在发生异常时候的处理机制又是什么？ 多副本间的数据一致性如何解决，基于的一致性协议又是什么？ 如何确保Kafka 的可靠性？ Kafka 中的可靠性和可用性之间的关系又如何？ 下面从副本的角度切入来看看Kafka如何保障数据一致性、数据可靠性等问题，主要包括副本剖析、日志同步机制和可靠性分析等内容。 副本剖析副本（Replica）是分布式系统中常见的概念之一，指的是分布式系统对数据和服务提供的一种冗余方式。在常见的分布式系统中，为了对外提供可用的服务，我们往往会对数据和服务进行副本处理。数据副本是指在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取该数据，这是解决分布式系统数据丢失问题最有效的手段。另一类副本是服务副本，指多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。 Kafka从0.8版本开始为分区引入了多副本机制，通过增加副本数量来提升数据容灾能力。同时，Kafka通过多副本机制实现故障自动转移，在Kafka集群中某个broker节点失效的情况下仍然保证服务可用。 下面的内容会涉及到AR、ISR、HW等基础概念，下面我们先简要回顾一下，详情请参考 &lt;Kafka中的基本概念&gt; 副本是相对于分区而言的，即副本是特定分区的副本。 一个分区中包含一个或多个副本，其中一个为leader副本，其余为follower副本，各个副本位于不同的broker节点中。只有leader副本对外提供服务，follower副本只负责数据同步。 分区中的所有副本统称为 AR，而ISR 是指与leader 副本保持同步状态的副本集合，当然leader副本本身也是这个集合中的一员。 LEO标识每个分区中最后一条消息的下一个位置，分区的每个副本都有自己的LEO，ISR中最小的LEO即为HW，俗称高水位，消费者只能拉取到HW之前的消息。 从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待ISR集合中的所有 follower 副本都同步完之后才能被认为已经提交，之后才会更新分区的 HW，进而消费者可以消费到这条消息。 失效副本正常情况下，分区的所有副本都处于ISR集合中，但是难免会有异常情况发生，从而某些副本被剥离出ISR集合中。在ISR集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区（under-replicated分区）。 可以通过 kafka-topic.sh 脚本的 under-replicated-partitions 参数来显示主题中包含失效副本的分区。 失效副本不仅是指处于功能失效状态的副本，处于同步失效状态的副本也可以看作失效副本。 怎么判定一个分区是否有副本处于同步失效的状态呢？ Kafka 从 0.9.x 版本开始就通过唯一的broker端参数 replica.lag.time.max.ms 来抉择，当ISR集合中的一个follower副本滞后leader副本的时间超过此参数指定的值时则判定为同步失败，需要将此follower副本剔除出ISR集合，replica.lag.time.max.ms 参数的默认值为10000。 具体的实现原理也很容易理解，当follower副本将leader副本LEO（LogEndOffset）之前的日志全部同步时，则认为该 follower 副本已经追赶上leader 副本，此时更新该副本的lastCaughtUpTimeMs 标识。 注意： 千万不要错误的以为，只要 follower 副本拉取 leader 副本的数据就会更新 lastCaughtUpTimeMs 。 当leader 副本中消息的流入速度大于 follower 副本的拉取速度时，就算 follower 副本一直拉取，也不会和 leader 副本保持同步。如果还将该 follower 副本放入 ISR 集合中，就有可能造成消息丢失。 Kafka 的副本管理器会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的 lastCaughtUpTimeMs 差值是否大于参数replica.lag.time.max.ms 指定的值。 什么情况会导致副本失效？ follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的Full GC。 follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如I/O开销过大。 当通过脚本工具增加了副本因子，新增加的副本因子在赶上leader之前都处于失效状态 ISR的伸缩Kafka 在启动的时候会开启两个与 ISR 相关的定时任务，名称分别为 isr-expiration 和isr-change-propagation isr-expiration 任务会周期性地检测每个分区是否需要缩减其ISR集合。 这个周期和 replica.lag.time.max.ms 参数有关，大小是这个参数值的一半，默认值为5000ms。 当检测到ISR集合中有失效副本时，就会收缩ISR集合。如果某个分区的ISR集合发生变更，则会将变更后的数据记录到 ZooKeeper 对应的 /brokers/topics/partition/state 节点中。节点中的数据示例如下： 1&#123;&quot;controller epoch&quot;: 26, &quot;leader&quot;: 0, &quot;version&quot;: 1, &quot;leader epoch&quot;: 2, &quot;isr&quot;: [0, 1]&#125; controller_epoch 表示当前Kafka控制器的epoch leader 表示当前分区的leader副本所在的broker的id编号 version表示版本号（当前版本固定为1） leader_epoch表示当前分区的leader纪元 isr表示变更后的ISR列表。 当 ISR 集合发生变更时还会将变更后的记录缓存到 isrChangeSet 中，isr-change-propagation 任务会周期性（固定值为 2500ms）地检查isrChangeSet，如果发现isrChangeSet中有ISR集合的变更记录，那么它会在ZooKeeper的/isr_change_notification路径下创建一个以 isr_change_开头的持久顺序节点（比如/isr_change_notification/isr_change_0000000000），并将isrChangeSet中的信息保存到这个节点中。 Kafka控制器为/isr_change_notification添加了一个Watcher，当这个节点中有子节点发生变化时会触发Watcher的动作，以此通知控制器更新相关元数据信息并向它管理的broker节点发送更新元数据的请求，最后删除/isr_change_notification路径下已经处理过的节点。 频繁地触发Watcher会影响Kafka控制器、ZooKeeper甚至其他broker节点的性能。为了避免这种情况，Kafka添加了限定条件，当检测到分区的ISR集合发生变化时，还需要检查以下两个条件： 上一次ISR集合发生变化距离现在已经超过5s。 上一次写入ZooKeeper的时间距离现在已经超过60s。 满足以上两个条件之一才可以将ISR集合的变化写入目标节点。 有缩减对应就会有扩充，那么Kafka又是何时扩充ISR的呢？ 随着follower副本不断与leader副本进行消息同步，follower副本的LEO也会逐渐后移，并最终追赶上leader副本，此时该follower副本就有资格进入ISR集合。 追赶上leader副本的判定准则是此副本的LEO是否不小于leader副本的HW，注意这里并不是和leader副本的LEO相比。ISR扩充之后同样会更新ZooKeeper中的/brokers/topics/partition/state节点和isrChangeSet，之后的步骤就和ISR收缩时的相同。 当ISR集合发生增减时，或者ISR集合中任一副本的LEO发生变化时，都可能会影响整个分区的HW。 例如，leader副本的LEO为9，follower1副本的LEO为7，而follower2副本的LEO为6，如果判定这3个副本都处于ISR集合中，那么这个分区的HW为6；如果follower3已经被判定为失效副本被剥离出ISR集合，那么此时分区的HW为leader副本和follower1副本中LEO的最小值，即为7。 LEO 和 HW这两个概念可以参考：&lt;Kafka中的基本概念&gt; 对于副本而言，还有两个概念：本地副本（Local Replica）和远程副本（RemoteReplica）。 本地副本是指对应的Log分配在当前的broker节点上，远程副本是指对应的Log分配在其他的broker节点上。在Kafka中，同一个分区的信息会存在多个broker节点上，并被其上的副本管理器所管理，这样在逻辑层面每个broker节点上的分区就有了多个副本，但是只有本地副本才有对应的日志。 整个消息追加的过程可以概括如下： 生产者客户端发送消息至leader副本（副本1）中。 消息被追加到leader副本的本地日志，并且会更新日志的偏移量。 follower副本（副本2和副本3）向leader副本请求同步数据。 leader副本所在的服务器读取本地日志，并更新对应拉取的follower副本的信息。 leader副本所在的服务器将拉取结果返回给follower副本。 follower副本收到leader副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。 了解了这些内容后，我们再来分析在这个过程中各个副本LEO和HW的变化情况。下面的示例，生产者一直在往leader副本中写入消息。某一时刻，leader副本的LEO增加至5，并且所有副本的HW还都为0。之后follower副本向leader副本拉取消息，在拉取的请求中会带有自身的LEO信息，这个LEO信息对应的是FetchRequest请求中的fetch_offset。leader副本返回给follower副本相应的消息，并且还带有自身的HW信息，这个HW信息对应的是FetchResponse中的high_watermark。 此时两个follower副本各自拉取到了消息，并更新各自的LEO为3和4。与此同时，follower副本还会更新自己的HW，更新HW的算法是比较当前LEO和leader副本中传送过来的HW的值，取较小值作为自己的HW值。当前两个follower副本的HW都等于0（min（0，0）=0）。 接下来follower副本再次请求拉取leader副本中的消息。 此时leader副本收到来自follower副本的FetchRequest请求，其中带有LEO的相关信息，选取其中的最小值作为新的HW，即min（15，3，4）=3。然后连同消息和HW一起返回FetchResponse给follower副本。注意leader副本的HW是一个很重要的东西，因为它直接影响了分区数据对消费者的可见性。 两个follower副本在收到新的消息之后更新LEO并且更新自己的HW为3（min（LEO，3）=3）。 在一个分区中，leader副本所在的节点会记录所有副本的LEO，而follower副本所在的节点只会记录自身的LEO，而不会记录其他副本的LEO。对HW而言，各个副本所在的节点都只记录它自身的HW。leader 副本收到 follower副本的FetchRequest请求之后，它首先会从自己的日志文件中读取数据，然后在返回给follower副本数据前先更新follower副本的LEO。 Kafka 的根目录下有 cleaner-offset-checkpoint、log-start-offset-checkpoint、recovery-point-offset-checkpoint和replication-offset-checkpoint四个检查点文件 recovery-point-offset-checkpoint 和replication-offset-checkpoint 这两个文件分别对应了 LEO和 HW。 Kafka 中会有一个定时任务负责将所有分区的 LEO 刷写到恢复点文件 recovery-point-offset-checkpoint 中，定时周期由 broker 端参数 log.flush.offset.checkpoint.interval.ms来配置，默认值为60000。 还有一个定时任务负责将所有分区的HW刷写到复制点文件replication-offset-checkpoint中，定时周期由broker端参数replica.high.watermark.checkpoint.interval.ms来配置，默认值为5000。 log-start-offset-checkpoint文件对应logStartOffset（注意不能缩写为LSO，因为在Kafka中LSO是LastStableOffset的缩写），在FetchRequest和FetchResponse中也有它的身影，它用来标识日志的起始偏移量。各个副本在变动 LEO 和 HW 的过程中，logStartOffset 也有可能随之而动。Kafka 也有一个定时任务来负责将所有分区的 logStartOffset书写到起始点文件log-start-offset-checkpoint中，定时周期由broker端参数log.flush.start.offset.checkpoint.interval.ms来配置，默认值为60000。 Leader Epoch上述过程是在正常情况下的leader副本与follower副本之间的同步过程。 如果leader副本发生切换，那么同步过程又该如何处理呢？ 在0.11.0.0版本之前，Kafka使用的是基于HW的同步机制，但这样有可能出现数据丢失或leader副本和follower副本数据不一致的问题 数据丢失下图中，Replica B 是当前的leader副本（用L标记），Replica A是follower副本。 在某一时刻，B中有2条消息 m1 和 m2，A从B中同步了这两条消息，此时A和B的LEO都为2，同时HW都为1； 之后A再向B中发送请求以拉取消息，FetchRequest请求中带上了A的LEO信息，B在收到请求之后更新了自己的HW为2； B中虽然没有更多的消息，但还是会返回FetchResponse，并在其中包含了HW信息；最后A根据FetchResponse中的HW信息更新自己的HW为2。 可以看到整个过程中两者之间的HW同步有一个间隙，在A写入消息m2之后（LEO更新为2）需要再一轮的FetchRequest/FetchResponse才能更新自身的HW为2。 下图中，如果在这个时候A宕机了，那么在A重启之后会根据之前HW位置（这个值会存入本地的复制点文件replication-offset-checkpoint）进行日志截断，这样便会将m2这条消息删除，此时A只剩下m1这一条消息，之后A再向B发送FetchRequest请求拉取消息。 此时若B 再宕机，那么 A 就会被选举为新的leader，如下图。B 恢复之后会成为follower，由于follower副本HW不能比leader副本的HW高，所以还会做一次日志截断，以此将HW调整为1。这样一来m2这条消息就丢失了（就算B不能恢复，这条消息也同样丢失）。 数据不一致对于上面的情况，也有一些解决方法，比如等待所有follower副本都更新完自身的HW之后再更新leader副本的HW，这样会增加多一轮的FetchRequest/FetchResponse延迟，自然不够妥当。 还有一种方法就是follower副本恢复之后，在收到leader副本的FetchResponse前不要截断follower副本（follower副本恢复之后会做两件事情：截断自身和向leader发送FetchRequest请求），不过这样也避免不了数据不一致的问题。 例如下图中，当前leader副本为A，follower副本为B，A中有2条消息m1和m2，并且HW和LEO都为2，B中有1条消息m1，并且HW和LEO都为1。假设A和B同时“挂掉”，然后B第一个恢复过来并成为leader 之后B写入消息m3，并将LEO和HW更新至2（假设所有场景中的min.insync.replicas参数配置为1）。此时A也恢复过来了，根据前面数据丢失场景中的介绍可知它会被赋予follower的角色，并且需要根据HW截断日志及发送FetchRequest至B，不过此时A的HW正好也为2，那么就可以不做任何调整了，如下图 如此一来A中保留了m2而B中没有，B中新增了m3而A也同步不到，这样A和B就出现了数据不一致的情形。 Leader Epoch为了解决上述两种问题，Kafka从0.11.0.0开始引入了 leader epoch 的概念，在需要截断数据的时候使用leader epoch作为参考依据而不是原本的HW。 leader epoch代表leader的纪元信息（epoch），初始值为0。每当leader变更一次，leader epoch 的值就会加1，相当于为leader增设了一个版本号。 与此同时，每个副本中还会增设一个矢量 &lt;LeaderEpoch –&gt; ，其中StartOffset表示当前Leader Epoch下写入的第一条消息的偏移量。 每个副本的Log下都有一个leader-epoch-checkpoint文件，在发生leader epoch变更时，会将对应的矢量对追加到这个文件中. 解决数据丢失问题 下图中 LE（LeaderEpoch的缩写，当前A和B中的LE都为0）。 同样 A 发生重启，之后 A 不是先忙着截断日志而是先发送 OffsetsForLeaderEpochRequest 请求给 B（OffsetsForLeaderEpochRequest 请求体结构如下图所示，其中包含 A 当前的LeaderEpoch值），B作为目前的leader在收到请求之后会返回当前的LEO（LogEndOffset），与请求对应的响应为OffsetsForLeaderEpochResponse 如果A中的LeaderEpoch（假设为LE_A）和B中的不相同，那么B此时会查找LeaderEpoch为 LE_A+1 对应的 StartOffset 并返回给 A，也就是 LE_A 对应的 LEO，所以我们可以将OffsetsForLeaderEpochRequest的请求看作用来查找follower副本当前LeaderEpoch的LEO。 如下图，A 在收到2之后发现和目前的LEO相同，也就不需要截断日志了。B发生了宕机，A成为新的leader，那么对应的LE=0也变成了LE=1，对应的消息m2此时就得到了保留，之后不管B有没有恢复，后续的消息都可以以LE1为LeaderEpoch陆续追加到A中。 解决数据不一致问题 下面我们再来看一下leader epoch如何应对数据不一致的场景。 如下图所示，当前A为leader，B为follower，A中有2条消息m1和m2，而B中有1条消息m1。假设A和B同时“挂掉”，然后B第一个恢复过来并成为新的leader。 之后B写入消息m3，并将LEO和HW更新至2。（注意此时的LeaderEpoch已经从LE0增至LE1了。） 紧接着A也恢复过来成为follower，并向B发送OffsetsForLeaderEpochRequest请求，此时A的LeaderEpoch为LE0。B根据LE0查询到对应的offset为1并返回给A，A就截断日志并删除了消息m2。 之后A发送FetchRequest至B请求来同步数据，最终A和B中都有两条消息m1和m3，HW和LEO都为2，并且LeaderEpoch都为LE1，如此便解决了数据不一致的问题。 日志同步机制在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。虽然有许多方式可以实现这些功能，但最简单高效的方式还是从集群中选出一个leader来负责处理数据写入的顺序性。只要leader还处于存活状态，那么follower只需按照leader中的写入顺序来进行同步即可。 通常情况下，只要leader不宕机我们就不需要关心follower的同步问题。 不过当leader宕机时，我们就要从follower中选举出一个新的leader。follower的同步状态可能落后leader很多，甚至还可能处于宕机状态，所以必须确保选择具有最新日志消息的follower作为新的leader。 kafka 在执行日志同步时，在Kafka中动态维护着一个ISR集合，处于ISR集合内的节点保持与leader相同的高水位（HW），只有位列其中的副本（unclean.leader.election.enable配置为false）才有资格被选为新的 leader。 写入消息时只有等到所有 ISR 集合中的副本都确认收到之后才能被认为已经提交。位于 ISR 中的任何副本节点都有资格成为leader，选举过程简单、开销低，这也是Kafka选用此模型的重要因素。Kafka中包含大量的分区，leader副本的均衡保障了整体负载的均衡，所以这一因素也极大地影响Kafka的性能指标。 日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的leader中能够包含这条消息。 这里就有一个需要权衡（tradeoff）的地方，如果leader在消息被提交前需要等待更多的follower确认，那么在它宕机之后就可以有更多的follower替代它，不过这也会造成性能的下降。 对于这种tradeoff，一种常见的做法是“少数服从多数”，“少数服从多数”的方式有一个很大的优势，系统的延迟取决于最快的几个节点，比如副本数为3，那么延迟就取决于最快的那个follower而不是最慢的那个（除了leader，只需要另一个follower确认即可）。 不过它也有一些劣势，为了保证leader选举的正常进行，它所能容忍的失败follower数比较少，如果要容忍1个follower失败，那么至少要有3个副本，如果要容忍2个follower失败，必须要有5个副本。也就是说，在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降。这也就是“少数服从多数”的这种Quorum模型常被用作共享集群配置（比如ZooKeeper），而很少用于主流的数据存储中的原因。 在采用ISR模型和（f+1）个副本数的配置下，一个Kafka分区能够容忍最大f个节点失败，相比于“少数服从多数”的方式所需的节点数大幅减少。实际上，为了能够容忍f个节点失败，“少数服从多数”的方式和ISR的方式都需要相同数量副本的确认信息才能提交消息。比如，为了容忍1个节点失败，“少数服从多数”需要3个副本和1个follower的确认信息，采用ISR的方式需要2个副本和1个follower的确认信息。在需要相同确认信息数的情况下，采用ISR的方式所需要的副本总数变少，复制带来的集群开销也就更低，“少数服从多数”的优势在于它可以绕开最慢副本的确认信息，降低提交的延迟，而对Kafka而言，这种能力可以交由客户端自己去选择。 总结kafka对可靠性的保障体现在多个方面，消息发送阶段、消息存储阶段以及消费消息阶段均有涉及。 消息发送阶段消息发送的3种模式，即发后即忘、同步和异步。 对于发后即忘的模式，不管消息有没有被成功写入，生产者都不会收到通知，那么即使消息写入失败也无从得知，因此发后即忘的模式不适合高可靠性要求的场景。 如果要提升可靠性，那么生产者可以采用同步或异步的模式，在出现异常情况时可以及时获得通知，以便可以做相应的补救措施，比如选择重试发送（可能会引起消息重复）。 有些发送异常属于可重试异常，比如 NetworkException，这个可能是由瞬时的网络故障而导致的，一般通过重试就可以解决。对于这类异常，客户端内部本身提供了重试机制来应对这种类型的异常，通过 retries 参数即可配置。默认情况下，retries参数设置为0，即不进行重试，对于高可靠性要求的场景，需要将这个值设置为大于 0 的值，与 retries 参数相关的还有一个retry.backoff.ms参数，它用来设定两次重试之间的时间间隔，以此避免无效的频繁重试。 如果配置的retries参数值大于0，则可能引起一些负面的影响。由于默认的max.in.flight.requests.per.connection参数值为5，这样可能会影响消息的顺序性。对此要么放弃客户端内部的重试功能，要么将max.in.flight.requests.per.connection参数设置为1，这样也就放弃了吞吐。 生产者客户端参数 acks 也是用来支撑可靠性的。该参数有三个可选项：0、1、-1 对于acks=1的配置，生产者将消息发送到leader副本，leader副本在成功写入本地日志之后会告知生产者已经成功提交。（如果此时ISR集合的follower副本还没来得及拉取到leader中新写入的消息，leader就宕机了，那么此次发送的消息就会丢失。） 对于ack=-1的配置，生产者将消息发送到leader副本，leader副本在成功写入本地日志之后还要等待 ISR 中的 follower 副本全部同步完成才能够告知生产者已经成功提交，即使此时leader副本宕机，消息也不会丢失 在acks=-1的情形中，它要求ISR中所有的副本都收到相关的消息之后才能够告知生产者已经成功提交。试想一下这样的情形，leader 副本的消息流入速度很快，而follower副本的同步速度很慢，在某个临界点时所有的follower副本都被剔除出了ISR集合，那么ISR中只有一个leader副本，最终acks=-1演变为acks=1的情形，如此也就加大了消息丢失的风险。 Kafka也考虑到了这种情况，并为此提供了min.insync.replicas参数（默认值为1）来作为辅助（配合acks=-1来使用），这个参数指定了ISR集合中最小的副本数，如果不满足条件就会抛出NotEnoughReplicasException或NotEnoughReplicasAfterAppendException。 在正常的配置下，需要满足副本数 &gt; min.insync.replicas参数的值。 一个典型的配置方案为：副本数配置为 3，min.insync.replicas 参数值配置为 2。注意min.insync.replicas参数在提升可靠性的时候会从侧面影响可用性。（试想如果ISR中只有一个leader副本，那么最起码还可以使用，而此时如果配置min.insync.replicas &gt; 1，则会使消息无法写入。） 与可靠性和ISR集合有关的还有一个参数—unclean.leader.election.enable。这个参数的默认值为false，如果设置为true就意味着当leader下线时候可以从非ISR集合中选举出新的 leader，这样有可能造成数据的丢失。如果这个参数设置为false，那么也会影响可用性，非ISR集合中的副本虽然没能及时同步所有的消息，但最起码还是存活的可用副本。 从0.11.0.0 版本开始，unclean.leader.election.enable 的默认值由原来的 true 改为了false，可以看出Kafka的设计者愈发地偏向于可靠性的提升。 消息存储阶段存储消息阶段需要在消息刷盘之后再给生产者响应，假设消息写入缓存中就返回响应，那么机器突然断电这消息就没了，而生产者以为已经发送成功了。 如果Broker是集群部署，有多副本机制，即消息不仅仅要写入当前Broker,还需要写入副本机中。那配置成至少写入两台机子后再给生产者响应。这样基本上就能保证存储的可靠了。一台挂了还有一台还在呢。 那假如来个地震机房机子都挂了呢？emmmmmm…大公司基本上都有异地多活。 就Kafka而言，越多的副本数越能够保证数据的可靠性，副本数可以在创建主题时配置，也可以在后期修改，不过副本数越多也会引起磁盘、网络带宽的浪费，同时会引起性能的下降。 一般而言，设置副本数为3即可满足绝大多数场景对可靠性的要求，而对可靠性要求更高的场景下，可以适当增大这个数值，比如国内部分银行在使用 Kafka 时就会设置副本数为 5。 在broker端还有两个参数log.flush.interval.messages 和 log.flush.interval.ms，用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。同步刷盘是增强一个组件可靠性的有效方式，不过这种方式极其损耗性能，最好还是采用多副本的机制来保障。 消息消费阶段消费者需要真正执行完业务逻辑之后，再发送给Broker消费成功，这才是真正的消费了。 所以只要我们在消息业务逻辑处理完成之后再给Broker响应，那么消费阶段消息就不会丢失。 在kafka中，消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。 当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset（enable.auto.commit 参数的默认值为 true）。虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取，所以需要将 enable.auto.commit 参数设置为 false 来执行手动位移提交。 在执行手动位移提交的时候也要遵循一个原则：如果消息没有被成功消费，那么就不能提交所对应的消费位移。对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失。 对于消费端，Kafka 还提供了一个可以兜底的功能，即回溯消费，通过这个功能可以让我们能够有机会对漏掉的消息相应地进行回补，进而可以进一步提高可靠性。","tags":["kafka","可靠性"],"categories":["kafka"]},{"title":"Kafka 系列(四)：Kafka 消费者","path":"/kafka/kafka-consumer/","content":"1. 传统消息模型传统消息模型一般分为消息队列模型和发布订阅模型： 1）消息队列模型的缺陷在于消息一旦被消费，就会从队列中被删除，而且只能被下游的一个 Consumer 消费。这种模型的伸缩性（scalability）很差，因为下游的多个 Consumer 都要“抢”这个共享消息队列的消息。 2）发布 / 订阅模型倒是允许消息被多个 Consumer 消费，但它的问题也是伸缩性不高，因为每个订阅者都必须要订阅主题的所有分区。这种全量订阅的方式既不灵活，也会影响消息的真实投递效果。 Kafka 的 Consumer Group 机制正好避开这两种模型的缺陷，又兼具它们的优点。 Kafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型： 如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型； 如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型。 2. Consumer GroupConsumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。 组内可以有多个消费者或消费者实例（Consumer Instance），它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。当然，每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。 Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。 在实际场景中，使用进程更为常见一些。 Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。 Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。 这个分区当然也可以被其他的 Group 消费。 理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数，这样能最大限度地实现高伸缩性。 注意：Consumer Group 中的实例是以 分区 为单位进行消费的，如果实例数大于分区数就会导致有的实例无法消费到任何消息。 假如有 6 个分区，Consumer Group 中却有 8 个实例，那么有两个实例将不会被分配任何分区，它们永远处于空闲状态。 因此，在实际使用过程中一般不推荐设置大于总分区数的 Consumer 实例。 下面的例子中，主题中共有4个分区（Partition）：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。 每一个分区只能被一个消费组中的一个消费者所消费。 假设某一时刻某消费组内只有一个消费者 C0，订阅了一个主题，这个主题包含 7 个分区：P0、P1、P2、P3、P4、P5、P6。也就是说，这个消费者C0订阅了7个分区。 此时消费组内又加入了一个新的消费者C1，按照既定的逻辑，需要将原来消费者C0的部分分区分配给消费者C1消费。消费者C0和C1各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。 紧接着消费组内又加入了一个新的消费者C2 消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。对于分区数固定的情况，一味地增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。假设一共有8个消费者，7个分区，那么最后的消费者C7由于分配不到任何分区而无法消费任何消息。 以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略，有关分区分配的更多细节可以参考 Kafka有哪几处地方有分区分配的概念？ 对于消息中间件而言，一般有两种消息投递模式： 点对点（P2P，Point-to-Point）模式 发布/订阅（Pub/Sub）模式 点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。 发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（Topic），主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。Kafka 同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合：· 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。 消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。 消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。 3. 消费者客户端一个正常的消费逻辑需要具备以下几个步骤： 配置消费者客户端参数及创建相应的消费者实例。 订阅主题。 拉取消息并消费。 提交消费位移。 关闭消费者实例。 3.1 主要参数 bootstrap.servers：用来指定连接 Kafka 集群所需的 broker 地址清单，具体内容形式为host1：port1，host2：post group.id：消费者隶属的消费组的名称，默认值为“”。如果设置为空，会抛 InvalidGroupIdException。一般而言，这个参数需要设置成具有一定的业务意义的名称。 key.deserializer 和 value.deserializer：消费者从broker端获取的消息格式都是字节数组（byte[]）类型，所以需要执行相应的反序列化操作才能还原成原有的对象格式。 client.id：用来设定KafkaConsumer对应的客户端id，默认值也为“”。如果客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1” 3.2 订阅主题kafka 提供两种方式来订阅主题： subscribe（） assign （） 一个消费者可以订阅一个或多个主题，可以使用 subscribe（）方法订阅了一个主题，对于这个方法而言，既可以以集合的形式订阅多个主题，也可以以正则表达式的形式订阅特定模式的主题。 对于消费者使用集合的方式（subscribe（Collection））来订阅主题而言，比较容易理解，订阅了什么主题就消费什么主题中的消息。如果前后两次订阅了不同的主题，那么消费者以最后一次的为准。 如果消费者采用的是正则表达式的方式（subscribe（Pattern））订阅，在之后的过程中，如果有人又创建了新的主题，并且主题的名字与正则表达式相匹配，那么这个消费者就可以消费到新添加的主题中的消息。如果应用程序需要消费多个主题，并且可以处理不同的类型，那么这种订阅方式就很有效。在Kafka 和其他系统之间进行数据复制时，这种正则表达式的方式就显得很常见。 消费者不仅可以通过KafkaConsumer.subscribe（）方法订阅主题，还可以直接订阅某些主题的特定分区，在KafkaConsumer中还提供了一个assign（）方法来实现这些功能。这个方法只接受一个参数 Collection&lt;TopicPartition&gt; partitions ，用来指定需要订阅的分区集合。 既然有订阅，那么就有取消订阅，取消订阅的方式有如下几种 consumer.unsubscribe(); consumer.subscribe(new ArrayList&lt;&gt;()); consumer.assgin(new ArrayList&lt;&gt;()); 通过 subscribe（）方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign（）方法订阅分区时，是不具备消费者自动均衡的功能的，其实这一点从assign（）方法的参数中就可以看出端倪，两种类型的subscribe（）都有ConsumerRebalanceListener类型参数的方法，而assign（）方法却没有。 再均衡监听器 再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。 不过在再均衡发生期间，消费组内的消费者是无法读取消息的。也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。 另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作，之后这个分区又被分配给了消费组内的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。一般情况下，应尽量避免不必要的再均衡的发生。 在subscribe（Collection＜String＞ topics，ConsumerRebalanceListener listener） 和 subscribe（Pattern pattern，ConsumerRebalanceListener listener）方法中可以指定再均衡监听器ConsumerRebalanceListener。再均衡监听器用来设定发生再均衡动作前后的一些准备或收尾的动作。ConsumerRebalanceListener 是一个接口，包含2 个方法， 12void onPartitionsRevoked(Collection＜TopicPartition＞partitions)void onPartitionsAssigned(Collection＜TopicPartition＞partitions) onPartitionsRevoked 方法会在再均衡开始之前和消费者停止读取消息之后被调用。可以通过这个回调方法来处理消费位移的提交，以此来避免一些不必要的重复消费现象的发生。参数partitions表示再均衡前所分配到的分区。 onPartitionsAssigned方法会在重新分配分区之后和消费者开始读取消费之前被调用。参数partitions表示再均衡后所分配到的分区。 3.3 消息消费Kafka中的消费是基于拉模式的。 消息的消费一般有两种模式：推模式和拉模式。 推模式是服务端主动将消息推送给消费者 拉模式是消费者主动向服务端发起请求来拉取消息。 Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll（）方法，而poll（）方法返回的是所订阅的主题（分区）上的一组消息。 对于poll（）方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空；如果订阅的所有分区中都没有可供消费的消息，那么poll（）方法返回为空的消息集合。 poll（）方法里还有一个超时时间参数timeout，用来控制poll（）方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞。 timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程。可以直接将timeout设置为0，这样poll（）方法会立刻返回，而不管是否已经拉取到了消息。如果应用线程唯一的工作就是从Kafka中拉取并消费消息，则可以将这个参数设置为最大值Long.MAX_VALUE。 poll () 方法的返回值为 ConsumerRecords （每条消息为ConsumerRecord）。在 ConsumerRecords 类中还提供了几个方法来方便开发人员对消息集进行处理：count（）方法用来计算出消息集中的消息个数，返回类型是int；isEmpty（）方法用来判断消息集是否为空，返回类型是boolean；empty（）方法用来获取一个空的消息集，返回类型是ConsumerRecord＜K，V＞。 3.4 位移提交对于Kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。对于消费者而言，它也有一个offset的概念，消费者使用offset来表示消费到分区中某个消息所在的位置。 在每次调用poll（）方法时，它返回的是还没有被消费过的消息集（当然这个前提是消息已经存储在Kafka 中了，并且暂不考虑异常情况的发生），要做到这一点，就需要记录上一次消费时的消费位移。并且这个消费位移必须做持久化保存，而不是单单保存在内存中，否则消费者重启之后就无法知晓之前的消费位移。再考虑一种情况，当有新的消费者加入时，那么必然会有再均衡的动作，对于同一分区而言，它可能在再均衡动作之后分配给新的消费者，如果不持久化保存消费位移，那么这个新的消费者也无法知晓之前的消费位移。 在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题__consumer_offsets中。这里把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。 如下图，x表示某一次拉取操作中此分区消息的最大偏移量，假设当前消费者已经消费了 x 位置的消息，那么我们就可以说消费者的消费位移为 x，图中也用了lastConsumedOffset这个单词来标识它。 不过需要非常明确的是，当前消费者需要提交的消费位移并不是 x，而是 x+1。 对应于图中的position，它表示下一条需要拉取的消息的位置。 在消费者中还有一个committed offset的概念，它表示已经提交过的消费位移。 KafkaConsumer 类提供了 position（TopicPartition）和 committed（TopicPartition）两个方法来分别获取上面所说的position和committed offset的值。 12public long position(TopicPartition partition)public OffsetAndMetadata committed(TopicPartition partition) 下面来做个小实验，验证下lastConsumedOffset、committed offset和position之间的关系。 123456789101112131415161718192021222324TopicPartition tp = new TopicPartition(topic, 0);consumer.assign(Arrays.asList(tp));long lastConsumedOffset = -1; // 当前消费到的位移while(true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000); if (records.isEmpty()) &#123; break; &#125; List&lt;consumerRecord&lt;string, string&gt;&gt; partitionRecords = records.records(tp); lastConsumedoffset = partitionRecords.get(partitionRecords.size() - 1).offset(); consumer.commitsync(); //同步提交消费位移 System.out.println(comsumed offset is&quot;+ lastconsumedoffset): offsetAndMetadata offsetAndMetadata = consumer.committed(tp); System.out.println(&quot;commited offset is &quot; + offsetAndMetadata.offset()); long posititon = consumer.position(tp); System.out.println(&quot;the offset of the next record is &quot; + posititon);&#125;Output:consumed offset is 377commited offset is 378the offset of the next record is 378 可以看出，消费者消费到此分区消息的最大偏移量为377，对应的消费位移lastConsumedOffset也就是377。在消费完之后就执行同步提交，但是最终结果显示所提交的位移committed offset为 378，并且下一次所要拉取的消息的起始偏移量 position 也为 378。 对于位移提交的具体时机的把握也很有讲究，有可能会造成重复消费和消息丢失的现象。 当前一次poll（）操作所拉取的消息集为[x+2，x+7]，x+2代表上一次提交的消费位移，说明已经完成了x+1之前（包括x+1在内）的所有消息的消费，x+5表示当前正在处理的位置。如果拉取到消息之后就进行了位移提交，即提交了x+8，那么当前消费x+5的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从x+8开始的。也就是说，x+5至x+7之间的消息并未能被消费，如此便发生了消息丢失的现象。 再考虑另外一种情形，位移提交的动作是在消费完所有拉取到的消息之后才执行的，那么当消费x+5的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从x+2开始的。也就是说，x+2至x+4之间的消息又重新消费了一遍，故而又发生了重复消费的现象。 在 Kafka 中默认的消费位移的提交方式是自动提交，这个由消费者客户端参数enable.auto.commit 配置，默认值为 true。当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数auto.commit.interval.ms配置，默认值为5秒，此参数生效的前提是enable.auto.commit参数为true。 在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。 自动提交消费位移的方式非常简便，它免去了复杂的位移提交逻辑，让编码更简洁。但随之而来的是重复消费和消息丢失的问题。假设刚刚提交完一次消费位移，然后拉取一批消息进行消费，在下一次自动提交消费位移之前，消费者崩溃了，那么又得从上一次位移提交的地方重新开始消费，这样便发生了重复消费的现象（对于再均衡的情况同样适用）。我们可以通过减小位移提交的时间间隔来减小重复消息的窗口大小，但这样并不能避免重复消费的发送，而且也会使位移提交更加频繁。 在Kafka中还提供了手动位移提交的方式，这样可以使得开发人员对消费位移的管理控制更加灵活。很多时候并不是说拉取到消息就算消费完成，而是需要将消息写入数据库、写入本地缓存，或者是更加复杂的业务处理。在这些场景下，所有的业务处理完成才能认为消息被成功消费，手动的提交方式可以让开发人员根据程序的逻辑在合适的地方进行位移提交。开启手动提交功能的前提是消费者客户端参数enable.auto.commit配置为false。 手动提交可以细分为同步提交和异步提交，对应于 KafkaConsumer 中的commitSync（）和commitAsync（）两种类型的方法。 3.5 指定位移消费在 Kafka 中每当消费者查找不到所记录的消费位移时，就会根据消费者客户端参数auto.offset.reset的配置来决定从何处开始进行消费，这个参数的默认值为“latest”，表示从分区末尾开始消费消息 如果将auto.offset.reset参数配置为“earliest”，那么消费者会从起始处，也就是0开始消费。 auto.offset.reset参数还有一个可配置的值—“none”，配置为此值就意味着出现查到不到消费位移的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出NoOffsetForPartitionException异常 如果能够找到消费位移，那么配置为“none”不会出现任何异常。如果配置的不是“latest”、“earliest”和“none”，则会报出ConfigException异常 seek() 方法： 提供的auto.offset.reset 参数也只能在找不到消费位移或位移越界的情况下粗粒度地从开头或末尾开始消费。有些时候，我们需要一种更细粒度的掌控，可以让我们从特定的位移处开始拉取消息，而 KafkaConsumer 中的 seek（）方法正好提供了这个功能，让我们得以追前消费或回溯消费。 1public void seek(TopicPartition partition, long offset); seek（）方法中的参数partition表示分区，而offset参数用来指定从分区的哪个位置开始消费。seek（）方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 poll（）方法的调用过程中实现的。也就是说，在执行seek（）方法之前需要先执行一次poll（）方法，等到分配到分区之后才可以重置消费位置。 3.6 关闭消费KafkaConsumer 提供了对消费速度进行控制的方法，在有些应用场景下我们可能需要暂停某些分区的消费而先消费其他分区，当达到一定条件时再恢复这些分区的消费。KafkaConsumer中使用pause（）和resume（）方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。 KafkaConsumer还提供了一个无参的paused（）方法来返回被暂停的分区集合。 3.7 消费者拦截器消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。 与生产者拦截器对应的，消费者拦截器需要自定义实现org.apache.kafka.clients.consumer.ConsumerInterceptor接口。ConsumerInterceptor接口包含3个方法： 123public ConsumerRecords＜K,V＞ onConsume(ConsumerRecords＜K,V＞records);public void onCommit(Map＜TopicPartition,OffsetAndMetadata＞offsets);public void close(). KafkaConsumer会在poll（）方法返回之前调用拦截器的onConsume（）方法来对消息进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息（可能会减少poll（）方法返回的消息的个数）。如果 onConsume（）方法中抛出异常，那么会被捕获并记录到日志中，但是异常不会再向上传递。 KafkaConsumer会在提交完消费位移之后调用拦截器的onCommit（）方法，可以使用这个方法来记录跟踪所提交的位移信息，比如当消费者使用commitSync的无参方法时，我们不知道提交的消费位移的具体细节，而使用拦截器的onCommit（）方法却可以做到这一点。 在消费者中也有拦截链的概念，和生产者的拦截链一样，也是按照interceptor.classes参数配置的拦截器的顺序来一一执行的（配置的时候，各个拦截器之间使用逗号隔开）。同样也要提防“副作用”的发生。如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。 4. 多线程实现KafkaProducer是线程安全的，然而KafkaConsumer却是非线程安全的。KafkaConsumer中定义了一个 acquire（）方法，用来检测当前是否只有一个线程在操作，若有其他线程正在操作则会抛出ConcurrentModifcationException异常 KafkaConsumer中的每个公用方法在执行所要执行的动作之前都会调用这个acquire（）方法，只有wakeup（）方法是个例外 12345678910private final AtomicLong currentThread = new AtomicLong(NO_CURRENT_THREAD); // kafkaConsumer 中的成员变量private void acquire() &#123; long threadId = Thread.currentThread().getId(); if (threadId != currentThread.get() &amp;&amp; !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId))&#123; throw new ConcurrentModificationException(&quot;KafkaConsumer is not safe for multi-threaded access&quot;); &#125; refcount.incrementAndGet();&#125; acquire（）方法和我们通常所说的锁（synchronized、Lock等）不同，它不会造成阻塞等待，我们可以将其看作一个轻量级锁，它仅通过线程操作计数标记的方式来检测线程是否发生了并发操作，以此保证只有一个线程在操作。acquire（）方法和release（）方法成对出现，表示相应的加锁和解锁操作。 12345private void release()&#123; if (refcount.decrementAndGet() == 0) &#123; currentThread.set(NO_CURRENT_THREAD); &#125;&#125; acquire（）方法和release（）方法都是私有方法，因此在实际应用中不需要我们显式地调用，但了解其内部的机理之后可以促使我们正确、有效地编写相应的程序逻辑。 KafkaConsumer 非线程安全并不意味着我们在消费消息的时候只能以单线程的方式执行。 如果生产者发送消息的速度大于消费者处理消息的速度，那么就会有越来越多的消息得不到及时的消费，造成了一定的延迟。除此之外，由于Kafka 中消息保留机制的作用，有些消息有可能在被消费之前就被清理了，从而造成消息的丢失。我们可以通过多线程的方式来实现消息消费，多线程的目的就是为了提高整体的消费能力。 多线程的实现方式大致有如下三种方式： 4.1 线程封闭第一种也是最常见的方式：线程封闭，即为每个线程实例化一个KafkaConsumer对象 一个线程对应一个KafkaConsumer实例，我们可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数。 内部类KafkaConsumerThread代表消费线程，其内部包裹着一个独立的KafkaConsumer实例。通过外部类的main（）方法来启动多个消费线程，消费线程的数量由consumerThreadNum变量指定。一般一个主题的分区数事先可以知晓，可以将consumerThreadNum设置成不大于分区数的值，如果不知道主题的分区数，那么也可以通过KafkaConsumer类的partitionsFor（）方法来间接获取，进而再设置合理的consumerThreadNum值。 上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别，它的优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP连接，如果分区数和consumerThreadNum的值都很大，那么会造成不小的系统开销。 4.2 指定分区消费第一种方案中，由于消费者与分区数的关系，当消费线程的个数大于分区数时，就有部分消费线程一直处于空闲的状态。 第二种方案是多个消费线程同时消费同一个分区，这个通过 assign（）、seek（）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少，并不推荐。 一般而言，分区是消费线程的最小划分单位。 4.3 改造消息处理模块在第一种方案的具体实现的第①行，如果这里对消息的处理非常迅速，那么 poll（）拉取的频次也会更高，进而整体消费的性能也会提升；相反，如果在这里对消息的处理缓慢，比如进行一个事务性操作，或者等待一个RPC的同步响应，那么poll（）拉取的频次也会随之下降，进而造成整体消费性能的下降。一般而言，poll（）拉取消息的速度是相当快的，而整体消费的瓶颈也正是在处理消息这一块，如果我们通过一定的方式来改进这一部分，那么我们就能带动整体消费性能的提升。 第三种方案，可以尝试将处理消息模块改成多线程的实现方式，来提升性能。 第三种实现方式相比第一种实现方式而言，除了横向扩展的能力，还可以减少TCP连接对系统资源的消耗，不过缺点就是对于消息的顺序处理就比较困难了。","tags":["kafka","consumer"],"categories":["kafka"]},{"title":"Kafka 系列(三)：Producer 源码篇","path":"/kafka/kafka-producer-source-code/","content":"Kafka 系列文章列表Kafka 版本：2021-11 trunk 分支（当前最新版本3.0.0） 在 Kafka 中，客户端由 Java 语言实现，服务端由 Scala 语言来实现的，在使用 Kafka 时，客户端是用户最先接触到部分，因此，kafka系列文章的源码分析也会从客户端端开始，今天讲的是 Producer 端发送模型的实现。 在看这篇源码分析之前，不了解发送端原理的同学，可以先看下上篇博文Kafka Producer 原理篇 Producer 的使用在分析 Producer 发送模型之前，先看一下用户是如何使用 Producer 向 Kafka 写数据的，下面是一个关于 Producer 最简单的应用示例。 12345678910111213141516171819202122232425262728import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.Producer;import java.util.Properties;public class ProducerDemo &#123; private static String topicName; private static int msgNum; private static int key; public static void main(String[] args) &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); topicName = &quot;test&quot;; msgNum = 10; // 发送的消息数 Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for (int i = 0; i &lt; msgNum; i++) &#123; String msg = i + &quot; Kafka Producer Demo.&quot;; producer.send(new ProducerRecord&lt;String, String&gt;(topicName, msg)); &#125; producer.close(); &#125;&#125; 从上面的代码可以看出 Kafka 为用户提供了非常简单的 API，在使用时，只需要如下两步： 初始化 KafkaProducer 实例； 调用 send 接口发送数据。 本文主要是围绕着 Producer 在内部是如何实现 send 接口而展开的。 发送流程下面通过对 send 源码分析来一步步剖析 Producer 数据的发送流程。 send()用户是直接使用 producer.send() 发送的数据，先看一下 send() 接口的实现 12345678910111213// 异步发送一条记录到 topic，等同于 send(record, null)@Overridepublic Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record) &#123; return send(record, null);&#125;// 异步发送一条记录到主题，并在确认发送后调用提供的回调。@Overridepublic Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; // 在发送消息之前，先经过拦截器处理（），这个方法不会抛出异常 ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors.onSend(record); return doSend(interceptedRecord, callback);&#125; 数据发送的最终实现还是调用了 Producer 的 doSend() 接口。 doSend()doSend() 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112// 异步发送记录到主题private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; TopicPartition tp = null; try &#123; // 1. 检查 producer 是否被关闭 throwIfProducerClosed(); // 2. 确认数据要发送到的 topic 的 metadata 是可用的 long nowMs = time.milliseconds(); ClusterAndWaitTime clusterAndWaitTime; try &#123; clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs); &#125; catch (KafkaException e) &#123; if (metadata.isClosed()) throw new KafkaException(&quot;Producer closed while send in progress&quot;, e); throw e; &#125; nowMs += clusterAndWaitTime.waitedOnMetadataMs; long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs); Cluster cluster = clusterAndWaitTime.cluster; // 3. 序列化 record 的 key 和 value byte[] serializedKey; try &#123; serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key()); &#125; catch (ClassCastException cce) &#123; throw new SerializationException(&quot;Can&#x27;t convert key of class &quot; + record.key().getClass().getName() + &quot; to class &quot; + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() + &quot; specified in key.serializer&quot;, cce); &#125; byte[] serializedValue; try &#123; serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value()); &#125; catch (ClassCastException cce) &#123; throw new SerializationException(&quot;Can&#x27;t convert value of class &quot; + record.value().getClass().getName() + &quot; to class &quot; + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() + &quot; specified in value.serializer&quot;, cce); &#125; // 4. 获取该 record 的 partition 的值（可以指定,也可以根据算法计算） int partition = partition(record, serializedKey, serializedValue, cluster); tp = new TopicPartition(record.topic(), partition); setReadOnly(record.headers()); Header[] headers = record.headers().toArray(); int serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(), compressionType, serializedKey, serializedValue, headers); ensureValidRecordSize(serializedSize); long timestamp = record.timestamp() == null ? nowMs : record.timestamp(); if (log.isTraceEnabled()) &#123; log.trace(&quot;Attempting to append record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;&quot;, record, callback, record.topic(), partition); &#125; // producer callback will make sure to call both &#x27;callback&#x27; and interceptor callback Callback interceptCallback = new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); if (transactionManager != null &amp;&amp; transactionManager.isTransactional()) &#123; transactionManager.failIfNotReadyForSend(); &#125; // 5. 向 accumulator 中追加数据 RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs, true, nowMs); // 6. 如果最近一个 ProducerBatch 满了，重新创建一个 ProducerBatch 进行追加 if (result.abortForNewBatch) &#123; int prevPartition = partition; partitioner.onNewBatch(record.topic(), cluster, prevPartition); partition = partition(record, serializedKey, serializedValue, cluster); tp = new TopicPartition(record.topic(), partition); if (log.isTraceEnabled()) &#123; log.trace(&quot;Retrying append due to new batch creation for topic &#123;&#125; partition &#123;&#125;. The old partition was &#123;&#125;&quot;, record.topic(), partition, prevPartition); &#125; // producer callback will make sure to call both &#x27;callback&#x27; and interceptor callback interceptCallback = new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs, false, nowMs); &#125; if (transactionManager != null &amp;&amp; transactionManager.isTransactional()) transactionManager.maybeAddPartitionToTransaction(tp); // 7. 如果 batch 已经满了,唤醒 sender 线程发送数据 if (result.batchIsFull || result.newBatchCreated) &#123; log.trace(&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;, record.topic(), partition); this.sender.wakeup(); &#125; return result.future; // handling exceptions and record the errors; // for API exceptions return them in the future, // for other exceptions throw directly &#125; catch (ApiException e) &#123; log.debug(&quot;Exception occurred during message send:&quot;, e); if (callback != null) callback.onCompletion(null, e); this.errors.record(); this.interceptors.onSendError(record, tp, e); return new FutureFailure(e); &#125; catch (InterruptedException e) &#123; this.errors.record(); this.interceptors.onSendError(record, tp, e); throw new InterruptException(e); &#125; catch (KafkaException e) &#123; this.errors.record(); this.interceptors.onSendError(record, tp, e); throw e; &#125; catch (Exception e) &#123; // we notify interceptor about all exceptions, since onSend is called before anything else in this method this.interceptors.onSendError(record, tp, e); throw e; &#125;&#125; 在 dosend() 方法的实现上，一条 Record 数据的发送，可以分为以下几步： 确认数据要发送到的 topic 的 metadata 是可用的（如果该 partition 的 leader 存在则是可用的），如果没有 topic 的 metadata 信息，就需要获取相应的 metadata 序列化 record 的 key 和 value； 确定 record 要发送到的 partition（可以指定，也可以根据算法计算）； 向 accumulator 中追加 record 数据，数据会先进行缓存； 如果追加完数据后，对应的 RecordBatch 已经达到了 batch.size 的大小（或者batch 的剩余空间不足以添加下一条 Record），则唤醒 sender 线程发送数据。 下面会对这几部分的具体实现进行详细分析。 发送流程详解获取 topic 的 metadata 信息在数据发送前，需要先确定 topic 是可用的。这部分具体实现在 KafkaProducer 中的 waitOnMetadata() 。 序列化 key 和 valueProducer 端对 record 的 key 和 value 值进行序列化操作，在 Consumer 端再进行相应的反序列化。 kafka 提供了一部分通用的序列化实现（所有默认提供的序列化实现均在 org.apache.kafka.common.serialization），当然我们也是可以自定义序列化的具体实现。 确定分区关于 partition 值的计算，分为三种情况： 指明 partition 的情况下，直接将指明的值直接作为 partiton 值； 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值； 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。 具体实现如下： 12345678// 为给定的记录计算分区。如果记录有分区直接返回，否则调用配置的分区算法来计算分区。private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) &#123; Integer partition = record.partition(); return partition != null ? partition : partitioner.partition( record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);&#125; Producer 默认使用的 partitioner 是 org.apache.kafka.clients.producer.internals.DefaultPartitioner，DefaultPartitioner 默认采用的是 sticky partitioning （黏性分区分配）。 12345678public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster, int numPartitions) &#123; if (keyBytes == null) &#123; return stickyPartitionCache.partition(topic, cluster); &#125; // hash the keyBytes to choose a partition return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;&#125; 关于 sticky partitioning 的具体实现，可以查看专题文章。 用户也可以自定义 partition 的策略。 向 accumulator 追加数据Producer 会先将 record 写入到 buffer 中，当达到一个 batch.size 的大小时，再唤起 sender 线程去发送 RecordBatch，这里先详细分析一下 Producer 是如何向 buffer 中写入数据的。 Producer 是通过 RecordAccumulator 实例追加数据，其中一个比较重要的变量就是 ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches ，每个 TopicPartition 都会对应一个 Deque&lt;RecordBatch&gt; ，当添加数据时，会向其 TopicPartition 对应的 queue 中尾部最后一个 RecordBatch 中添加 record，而发送数据时，则会先从 queue 头部的 RecordBatch 开始发送。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// org.apache.kafka.clients.producer.internals.RecordAccumulator// 向累加器中添加一条记录，返回追加结果public RecordAppendResult append(TopicPartition tp, long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long maxTimeToBlock, boolean abortOnNewBatch, long nowMs) throws InterruptedException &#123; // We keep track of the number of appending thread to make sure we do not miss batches in // abortIncompleteBatches(). appendsInProgress.incrementAndGet(); ByteBuffer buffer = null; if (headers == null) headers = Record.EMPTY_HEADERS; try &#123; // check if we have an in-progress batch // 每个 topicPartition 对应一个 queue Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp); // 在对一个 queue 进行操作时,会保证线程安全 synchronized (dq) &#123; if (closed) throw new KafkaException(&quot;Producer closed while send in progress&quot;); // 向队列中最后一个 batch 中追加 RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq, nowMs); if (appendResult != null) return appendResult; &#125; // 没有一个正在进行的记录批次，尝试分配一个新的批次 if (abortOnNewBatch) &#123; // Return a result that will cause another call to append. return new RecordAppendResult(null, false, false, true); &#125; // 为 topic-partition 创建一个新的 RecordBatch, 需要初始化相应的 RecordBatch，要为其分配的大小是: max（batch.size, 加上头文件的本条消息的大小） byte maxUsableMagic = apiVersions.maxUsableProduceMagic(); int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers)); log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125; with remaining timeout &#123;&#125;ms&quot;, size, tp.topic(), tp.partition(), maxTimeToBlock); // 为新的 RecordBatch 分配 buffer buffer = free.allocate(size, maxTimeToBlock); // Update the current time in case the buffer allocation blocked above. nowMs = time.milliseconds(); synchronized (dq) &#123; // Need to check if producer is closed again after grabbing the dequeue lock. if (closed) throw new KafkaException(&quot;Producer closed while send in progress&quot;); RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq, nowMs); if (appendResult != null) &#123; // Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#x27;t happen often... return appendResult; &#125; // 给 topic-partition 创建一个 RecordBatch MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic); ProducerBatch batch = new ProducerBatch(tp, recordsBuilder, nowMs); // 向新的 RecordBatch 中追加数据 FutureRecordMetadata future = Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers, callback, nowMs)); // 将 RecordBatch 添加到对应的 queue 中 dq.addLast(batch); // 向未 ack 的 batch 集合添加这个 batch incomplete.add(batch); // Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch buffer = null; // 如果 dp.size()&gt;1 就证明这个 queue 有一个 batch 是可以发送了 return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true, false); &#125; &#125; finally &#123; if (buffer != null) free.deallocate(buffer); appendsInProgress.decrementAndGet(); &#125;&#125; 获取该 TopicPartition 对应的 queue，没有的话会创建一个空的 queue； 向 queue 中追加数据，先获取 queue 中最新加入的那个 RecordBatch，如果不存在或者存在但剩余空余不足以添加本条 record 则新创建一个，成功写入的话直接返回结果，写入成功； 创建一个新的 RecordBatch，初始化内存大小根据 Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers)) 来确定（防止单条 record 过大的情况）； 向新建的 RecordBatch 写入 record，并将 RecordBatch 添加到 queue 中，返回结果，写入成功。 发送 RecordBatch当 record 写入成功后，如果发现 RecordBatch 已满足发送的条件（通常是 queue 中有多个 batch，那么最先添加的那些 batch 肯定是可以发送了），那么就会唤醒 sender 线程，发送 RecordBatch。 sender 线程对 RecordBatch 的处理是在 sendProducerData() 方法中进行的，该方法具体实现如下： sendProducerData() 源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private long sendProducerData(long now) &#123; Cluster cluster = metadata.fetch(); // 获取那些已经可以发送的 RecordBatch 对应的 nodes RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now); // 如果有 topic-partition 的 leader 是未知的,就强制 metadata 更新 if (!result.unknownLeaderTopics.isEmpty()) &#123; // The set of topics with unknown leader contains topics with leader election pending as well as // topics which may have expired. Add the topic again to metadata to ensure it is included // and request metadata update, since there are messages to send to the topic. for (String topic : result.unknownLeaderTopics) this.metadata.add(topic, now); log.debug(&quot;Requesting metadata update due to unknown leader topics from the batched records: &#123;&#125;&quot;, result.unknownLeaderTopics); this.metadata.requestUpdate(); &#125; // 如果与node 没有连接（如果可以连接,同时初始化该连接）,就证明该 node 暂时不能发送数据,暂时移除该 node Iterator&lt;Node&gt; iter = result.readyNodes.iterator(); long notReadyTimeout = Long.MAX_VALUE; while (iter.hasNext()) &#123; Node node = iter.next(); if (!this.client.ready(node, now)) &#123; iter.remove(); notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now)); &#125; &#125; // 返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id）,并将 RecordBatch 从对应的 queue 中移除 Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now); addToInflightBatches(batches); if (guaranteeMessageOrder) &#123; // Mute all the partitions drained for (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123; for (ProducerBatch batch : batchList) this.accumulator.mutePartition(batch.topicPartition); &#125; &#125; // 移除超时的 RecordBatch accumulator.resetNextBatchExpiryTime(); List&lt;ProducerBatch&gt; expiredInflightBatches = getExpiredInflightBatches(now); List&lt;ProducerBatch&gt; expiredBatches = this.accumulator.expiredBatches(now); expiredBatches.addAll(expiredInflightBatches); // 这一块暂时还没太搞懂，不过不影响理解发送的流程 if (!expiredBatches.isEmpty()) log.trace(&quot;Expired &#123;&#125; batches in accumulator&quot;, expiredBatches.size()); for (ProducerBatch expiredBatch : expiredBatches) &#123; String errorMessage = &quot;Expiring &quot; + expiredBatch.recordCount + &quot; record(s) for &quot; + expiredBatch.topicPartition + &quot;:&quot; + (now - expiredBatch.createdMs) + &quot; ms has passed since batch creation&quot;; failBatch(expiredBatch, new TimeoutException(errorMessage), false); if (transactionManager != null &amp;&amp; expiredBatch.inRetry()) &#123; // This ensures that no new batches are drained until the current in flight batches are fully resolved. transactionManager.markSequenceUnresolved(expiredBatch); &#125; &#125; sensors.updateProduceRequestMetrics(batches); // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately // loop and try sending more data. Otherwise, the timeout will be the smaller value between next batch expiry // time, and the delay time for checking data availability. Note that the nodes may have data that isn&#x27;t yet // sendable due to lingering, backing off, etc. This specifically does not include nodes with sendable data // that aren&#x27;t ready to send since they would cause busy looping. long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout); pollTimeout = Math.min(pollTimeout, this.accumulator.nextExpiryTimeMs() - now); pollTimeout = Math.max(pollTimeout, 0); if (!result.readyNodes.isEmpty()) &#123; log.trace(&quot;Nodes with data ready to send: &#123;&#125;&quot;, result.readyNodes); // if some partitions are already ready to be sent, the select time would be 0; // otherwise if some partition already has some data accumulated but not ready yet, // the select time will be the time difference between now and its linger expiry time; // otherwise the select time will be the time difference between now and the metadata expiry time; pollTimeout = 0; &#125; sendProduceRequests(batches, now); return pollTimeout;&#125; 这段代码前面有很多是其他的逻辑处理，如：移除暂时不可用的 node、处理超时的 RecordBatch，真正进行发送发送 RecordBatch 的是 sendProduceRequests(batches, now) 这个方法。里面的实现逻辑主要就是将 batches 中 leader 为同一个 node 的所有 RecordBatch 放在一个请求中进行发送。 以上就是 kafka producer 客户端发送的整个流程，如有问题，欢迎在评论区交流。","tags":["kafka","producer"],"categories":["kafka"]},{"title":"Kafka 系列(二)：Producer 原理篇","path":"/kafka/kafka-producer/","content":"Kafka 系列文章列表Kafka 版本：2021-11 trunk 分支（当前最新版本3.0.0） 一个正常的生产者逻辑需要具备以下几个步骤： 配置生产者客户端参数以及创建相应的生产者实例 构建待发送的消息 发送消息 关闭生产者实例 序列化器生产者在发送消息时，需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给kafka，同样的消费者需要用反序列化器（Deserializer）把从Kafka中收到的字节数组转换成相应的对象。 生产者使用的序列化器和消费者使用的反序列化器需要一一对应。 kafka 客户端提供了多种序列化器，同时也支持自定义实现序列化器（可以选择使用如 Avro、JSON、Thrift、ProtoBuf、Protostuff等通用的序列化工具来实现）。 分区器消息在通过 send() 方法发往 broke 的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一些列作用之后才能被真正的发往kafka。拦截器一般不是必须的，而序列化器是必需的。 消息经过序列化器之后就需要确定他发往的分区，如果消息 ProducerRecord 中指定了具体的 partition 字段，那么就不需要分区器的作用，因为partition 就代表了要发往的分区号。 如果消息没有指定分区号，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值。分区器的作用就是为消息分配分区。 kafka 中提供的默认分区器的计算逻辑是： 如果 key 不为 null，则对 key 进行 哈希 （采用 MurmurHash2 算法），最终根据到的哈希值计算分区号，拥有相同key的消息会被发送到同一个分区 如果 key 为 null，消息将会以轮训的方式发往主题内的各个可用分区 在不改变主题分区的数量下，key 和分区之间的映射关系可以保持不变，一旦主题的分区数量发生变化（增加分区），那么映射关系就很难保证了。 除了 kafka 默认提供的分区器外，还可以使用自定义的分区器，只需要同 DefaultPartitioner 一样实现 Partitioner 接口即可。 实现自定义分区器之后，需要通过配置参数显示指定自定义分区器。 拦截器kafka 一共有两种拦截器：生产者拦截器和消费者拦截器。 生产者拦截器既可以在 消息发送前 做一些准备工作，比如按照某个规则过滤不符合条件的消息、修改消息的内容等，也可以在 发送回调逻辑前 做一些定制化的需求，比如统计类的工作。 实现方式：实现 ProducerInterceptor 接口，该接口提供如下三个方法 onSend onAcknowledgement close KafkaProducer 再将消息序列化和计算分区之前会调用生产者拦截器的 onSend() 方法来对消息进行相应的定制化操作。（一般来说最好不要修改 ProducerRecord 的 topic key partition 等信息，不然有可能影响分区的计算以及broker端日志的压缩功能） KafkaProducer 会在消息被应答之前和消息发送失败时调用生产者拦截器的 onAcknowledgement() 方法，优先于用户设定的 Callback 之前执行。这个方法运行在 Producer 的 IO 线程中，所以逻辑越简单越好，否则会影响消息发送的速度。 close() 方法主要用于在关闭拦截器时，执行一些资源的清理工作。 这三个方法中抛出的异常会被捕获并记录到日志中，并不会向上传递。 整体架构kafka 中同个生产者客户端由两个线程协调运行，分别为：主线程和 Sender 线程（发送线程）。 在主线程中由 KafkaProducer 创建消息，然后通过 可能的 拦截器、序列化器、分区器的作用之后，缓存到消息累加器 RecordAccumulator 中。Sender 线程负责从消息累加器中获取消息并将其发送到 kafka 中。 消息累加器 主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。消息累加器缓存的大小可以通过配置 buffer.memory 指定（默认为 33554432 B – 32MB）。如果发送速度超过了发送到服务器的速度，则会导致生产者空间不足，这时候 send() 方法调用要么被阻塞，要么抛出异常，这取决于 max.block.ms 的配置，默认为 60000 – 60s。 主线程中发送过来的消息都会被追加到 RecordAccumulator 的某个双端队列（Deque）中，在 RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch ，即 Deque&lt;ProducerBatch&gt; 。消息写入缓存时，追加到双端队列的尾部； Sender 读取消息时，从双端队列的头部读取。注意ProducerBatch不是ProducerRecord，ProducerBatch中可以包含一至多个ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而ProducerBatch是指一个消息批次，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑。与此同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，也可以减少网络请求的次数以提升整体的吞吐量。如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory参数适当调大以增加整体的吞吐量。 消息在网络上都是以字节（Byte）的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在Kafka生产者客户端中，通过java.io.ByteBuffer实现消息内存的创建和释放。不过频繁的创建和释放是比较耗费资源的，在RecordAccumulator的内部还有一个BufferPool，它主要用来实现ByteBuffer的复用，以实现缓存的高效利用。不过BufferPool只针对特定大小的ByteBuffer进行管理，而其他大小的ByteBuffer不会缓存进BufferPool中，这个特定的大小由batch.size参数来指定，默认值为16384B，即16KB。我们可以适当地调大batch.size参数以便多缓存一些消息。 ProducerBatch的大小和batch.size参数也有着密切的关系。当一条消息（ProducerRecord）流入RecordAccumulator时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建），查看 ProducerBatch 中是否还可以写入这个ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过batch.size参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。 Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本 &lt;分区，Deque&lt;ProducerBatch&gt;&gt; 的保存形式转变成 &lt;Node，List&lt;ProducerBatch&gt;&gt; 的形式，其中Node表示Kafka集群的broker节点。对于网络连接来说，生产者客户端是与具体的broker节点建立的连接，也就是向具体的broker 节点发送消息，而并不关心消息属于哪一个分区；而对于 KafkaProducer的应用逻辑而言，我们只关注向哪个分区中发送哪些消息，所以在这里需要做一个应用逻辑层面到网络I/O层面的转换。 在转换成 &lt;Node，List&lt;ProducerBatch&gt;&gt; 的形式之后，Sender 还会进一步封装成 &lt;Node，Request&gt; 的形式，这样就可以将Request请求发往各个Node了，这里的Request是指Kafka的各种协议请求，对于消息发送而言就是指具体的ProduceRequest 请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式为 Map&lt;NodeId，Deque&lt;Request&gt;&gt; ，它的主要作用是缓存了已经发出去但还没有收到响应的请求（NodeId 是一个String 类型，表示节点的 id 编号）。与此同时，InFlightRequests还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与Node之间的连接）最多缓存的请求数。这个配置参数为max.in.flight.requests.per.connection，默认值为 5，即每个连接最多只能缓存 5个未响应的请求，超过该数值之后就不能再向这个连接发送更多的请求了，除非有缓存的请求收到了响应（Response）。通过比较 Deque&lt;Request&gt; 的size与这个参数的大小来判断对应的Node中是否已经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node 节点负载较大或网络连接有问题，再继续向其发送请求会增大请求超时的可能。 leastLoadedNode InFlightRequests还可以获得leastLoadedNode，即所有Node中负载最小的那一个。这里的负载最小是通过每个Node在InFlightRequests中还未确认的请求决定的，未确认的请求越多则认为负载越大。 图中展示了三个节点Node0、Node1和Node2，很明显Node1的负载最小。也就是说，Node1为当前的leastLoadedNode。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。leastLoadedNode的概念可以用于多个应用场合，比如元数据请求、消费者组播协议的交互。 当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过metadata.max.age.ms 时间没有更新元数据都会引起元数据的更新操作。客户端参数metadata.max.age.ms的默认值为300000，即5分钟。元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作是由Sender线程发起的，在创建完MetadataRequest之后同样会存入InFlightRequests，之后的步骤就和发送消息时的类似。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里的数据同步通过synchronized和final关键字来保障。","tags":["kafka","producer"],"categories":["kafka"]},{"title":"Kafka 系列(一)：基本概念","path":"/kafka/kafka-concept/","content":"本文主要介绍一下kafka中的基本概念，主要包括：Producer、Consumer、topic、partition、offset、broker、ISR、AR、HW、LEO等。 Consumer &amp; Producer一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干Consumer，以及一个ZooKeeper集群。其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息。 Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中。 Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理。 Broker：服务代理节点。对于Kafka而言，Broker可以简单地看作一个独立的Kafka服务节点或Kafka服务实例。大多数情况下也可以将Broker看作一台Kafka服务器，前提是这台服务器上只部署了一个Kafka实例。一个或多个Broker组成了一个Kafka集群。 消费者（Consumer）负责订阅Kafka中的主题（Topic），并且从订阅的主题上拉取消息。与其他一些消息中间件不同的是：在Kafka的消费理念中还有一层消费组（Consumer Group）的概念，每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。 例如，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。 有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。 按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。 换言之，每一个分区只能被一个消费组中的一个消费者所消费。 消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。 对于分区数固定的情况，一味地增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。 以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。 对于消息中间件而言，一般有两种消息投递模式： 点对点（P2P，Point-to-Point）模式 发布/订阅（Pub/Sub）模式 点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。 发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（Topic），主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。 主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。Kafka 同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合： 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。 Topic &amp; Partition在Kafka中还有两个特别重要的概念 主题（Topic） 分区（Partition） Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题并进行消费。 主题是一个逻辑上的概念，它还可以细分为多个分区，一个分区只属于单个主题，很多时候也会把分区称为主题分区（Topic-Partition）。 同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，也就是说，Kafka保证的是分区有序而不是主题有序。 Kafka中的分区可以分布在不同的服务器（broker）上，也就是说，一个主题可以横跨多个broker，以此来提供比单个broker更强大的性能。 每一条消息被发送到broker之前，会根据分区规则选择存储到哪个具体的分区。如果分区规则设定得合理，所有的消息都可以均匀地分配到不同的分区中。 如果一个主题只对应一个文件，那么这个文件所在的机器 I/O 将会成为这个主题的性能瓶颈，而分区解决了这个问题。在创建主题的时候可以通过指定的参数来设置分区的个数，当然也可以在主题创建完成之后去修改分区的数量，通过增加分区的数量可以实现水平扩展。 Kafka 为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。 副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当Kafka集群中某个broker失效时仍然能保证服务可用。 Kafka 消费端也具备一定的容灾能力。Consumer 使用拉（Pull）模式从服务端拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。 AR &amp; ISR分区中的所有副本统称为AR（Assigned Replicas）。所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。 消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。 与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），由此可见，AR=ISR+OSR。在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步，即AR=ISR，OSR集合为空。 leader副本负责维护和跟踪ISR集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从ISR集合中剔除。如果OSR集合中有follower副本“追上”了leader副本，那么leader副本会把它从OSR集合转移至ISR集合。 默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader，而在OSR集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。 HW &amp; LEOHW 、 LEO 和上面提到的 ISR有着紧密的关系。 HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最后一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。 LEO （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1. 分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。 LW是Low Watermark的缩写，俗称“低水位”，代表AR集合中最小的logStartOffset值。副本的拉取请求（FetchRequest，它有可能触发新建日志分段而旧的被清理，进而导致logStartOffset的增加）和删除消息请求（DeleteRecordRequest）都有可能促使LW的增长。 下面具体分析一下 ISR 集合和 HW、LEO的关系。 假设某分区的 ISR 集合中有 3 个副本，即一个 leader 副本和 2 个 follower 副本，此时分区的 LEO 和 HW 都分别为 3 。消息3和消息4从生产者出发之后先被存入leader副本。 在消息被写入leader副本之后，follower副本会发送拉取请求来拉取消息3和消息4进行消息同步。 在同步过程中不同的副本同步的效率不尽相同，在某一时刻follower1完全跟上了leader副本而follower2只同步了消息3，如此leader副本的LEO为5，follower1的LEO为5，follower2的LEO 为4，那么当前分区的HW取最小值4，此时消费者可以消费到offset0至3之间的消息。 当所有副本都成功写入消息3和消息4之后，整个分区的HW和LEO都变为5，因此消费者可以消费到offset为4的消息了。 由此可见kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。 事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认已成功提交，这种复制方式极大的影响了性能。而在异步复制的方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就会被认为已经成功提交。在这种情况下，如果follower副本都还没有复制完而落后于leader副本，然后leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效的权衡了数据可靠性和性能之间的关系。","tags":["kafka"],"categories":["kafka"]},{"title":"分布式ID","path":"/framework/unique-id/","content":"概述唯一id是我们在设计阶段常常遇到的问题。 在复杂的分布式系统中，几乎都需要对大量的数据和消息进行唯一标识。在设计初期，我们需要考虑日后数据量的级别，如果可能会对数据进行分库分表，那么就需要有一个全局唯一id来标识一条数据或记录。 生成唯一id的策略有多种，但是每种策略都有它的适用场景、优点以及局限性。 唯一ID的特点全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。 趋势递增：最好趋势递增，这个要求就得看具体业务场景了，一般不严格要求。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、排序等特殊需求。 高可用：100%的可用性是骗人的，但是也要无限接近于100%的可用性 高可用性：同时除了对ID号码自身的要求，业务还对ID号生成系统的可用性要求极高，想象一下，如果ID生成系统瘫痪，这就会带来一场灾难。所以不能有单点故障； 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则； 分片支持：可以控制ShardingId。比如某一个用户的文章要放在同一个分片内，这样查询效率高，修改也容易； 长度适中。 常见方案数据库自增ID基于数据库的auto_increment自增ID完全可以充当分布式ID，具体实现：需要一个单独的MySQL实例用来生成ID，建表结构如下： 123456CREATE DATABASE `SEQ_ID`;CREATE TABLE SEQID.SEQUENCE_ID ( id bigint(20) unsigned NOT NULL auto_increment, value char(10) NOT NULL default &#x27;&#x27;, PRIMARY KEY (id),) ENGINE=MyISAM; 当我们需要一个ID的时候，向表中插入一条记录返回主键ID，但这种方式有一个比较致命的缺点，访问量激增时MySQL本身就是系统的瓶颈，用它来实现分布式服务风险比较大. 1insert into SEQUENCE_ID(value) VALUES (&#x27;values&#x27;); 优点 使用简单。 利用现有数据库系统的功能实现，成本小，代码简单，性能可以接受。 ID号单调递增。数值类型查询速度快。 缺点 强依赖DB。不同数据库语法和实现不同，数据库迁移的时候、多数据库版本支持的时候、或分表分库的时候需要处理，会比较麻烦。当DB异常时整个系统不可用，属于致命问题。 单点故障。在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。 数据一致性问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。 难于扩展。在性能达不到要求的情况下，比较难于扩展。ID发号性能瓶颈限制在单台MySQL的读写性能。 优化实现 针对主库单点， 如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。 1234567-- Mysql 1set @@auto_increment_offset = 1; -- 起始值set @@auto_increment_increment = 2; -- 步长--Mysql 2set @@auto_increment_offset = 2; -- 起始值set @@auto_increment_increment = 2; -- 步长 这样两个MySQL实例的自增ID分别就是： Mysql 1 : 1、3、5、7、9 Mysql 2 : 2、4、6、8、10 这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。 使用集群之后性能依旧扛不住高并发时，就需要进行扩容。这时会比较麻烦。 水平扩展的数据库集群，有利于解决数据库单点压力的问题，同时为了ID生成特性，将自增步长按照机器数量来设置。 增加第三台MySQL实例需要人工修改一、二两台MySQL实例的起始值和步长，把第三台机器的ID起始生成位置设定在比现有最大自增ID的位置远一些，但必须在一、二两台MySQL实例ID还没有增长到第三台MySQL实例的起始ID值的时候，否则自增ID就要出现重复了，必要时可能还需要停机修改。 优点 解决DB单点问题 缺点 不利于后续扩容，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。 🔥 数据库号段模式号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下： 12345678CREATE TABLE id_generator ( id int(10) NOT NULL, max_id bigint(20) NOT NULL COMMENT &#x27;当前最大id&#x27;, step int(20) NOT NULL COMMENT &#x27;号段的布长&#x27;, biz_type int(20) NOT NULL COMMENT &#x27;业务类型&#x27;, version int(20) NOT NULL COMMENT &#x27;版本号&#x27;, PRIMARY KEY (`id`)) biz_type ：代表不同业务类型 max_id ：当前最大的可用id step ：代表号段的长度 version ：是一个乐观锁，每次都更新version，保证并发时数据的正确性 id biz_type max_id step version 1 101 1000 2000 0 等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，新的号段范围是(max_id ,max_id +step]。 1update id_generator set max_id = #&#123;max_id+step&#125;, version = version + 1 where version = # &#123;version&#125; and biz_type = XXX 由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。 UUIDUUID (Universally Unique Identifier) 的目的，是让分布式系统中的所有元素，都能有唯一的辨识资讯，而不需要透过中央控制端来做辨识资讯的指定。如此一来，每个人都可以建立不与其它人冲突的 UUID。在这样的情况下，就不需考虑数据库建立时的名称重复问题。 UUID的标准形式: 16字节128位，通常以36长度的字符串表示. 示例：550e8400-e29b-41d4-a716-446655440000，到目前为止业界一共有5种方式生成UUID。 在Java中我们可以直接使用下面的API生成UUID: 1UUID uuid = UUID.randomUUID(); String s = UUID.randomUUID().toString(); 优点 非常简单，本地生成，代码方便，API调用方便。 性能非高。生成的id性能非常好，没有网络消耗，基本不会有性能问题。 全球唯一。在数据库迁移、系统数据合并、或者数据库变更的情况下，可以 从容应对。 缺点 存储成本高。UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。如果是海量数据库，就需要考虑存储量的问题。 信息不安全。基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。 不适用作为主键，ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用。UUID往往是使用字符串存储，查询的效率比较低。 UUID是无序的。不是单调递增的，而现阶段主流的数据库主键索引都是选用的B+树索引，对于无序长度过长的主键插入效率比较低。 传输数据量大。 不可读。 优化方案 为了解决UUID不可读， 可以使用UUID to Int64的方法 。 为了解决UUID无序的问题，NHibernate在其主键生成方式中提供了Comb算法（combined guid/timestamp）。保留GUID的10个字节，用另6个字节表示GUID生成的时间（DateTime）。 像用作订单号UUID这样的字符串没有丝毫的意义，看不出和订单相关的有用信息；而对于数据库来说用作业务主键ID，它不仅是太长还是字符串，存储性能差查询也很耗时，所以不推荐用作分布式ID。 Redis生成ID当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。 1234127.0.0.1:6379&gt; set seq_id 1 // 初始化自增ID为1OK127.0.0.1:6379&gt; incr seq_id // 增加1，并返回递增后的数值(integer) 2 可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5。各个Redis生成的ID为： 12345A：1,6,11,16,21B：2,7,12,17,22C：3,8,13,18,23D：4,9,14,19,24E：5,10,15,20,25 这个负载到哪台机器上需要提前设定好，未来很难做修改。但是3-5台服务器基本能够满足，都可以获得不同的ID。步长和初始值一定需要事先设定好。使用Redis集群也可以防止单点故障的问题。 比较适合使用Redis来生成日切流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生成一个Key，使用INCR进行累加。 用redis实现需要注意一点，要考虑到redis持久化的问题。 优点 不依赖于数据库，灵活方便，且性能优于数据库。。 数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点 如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。。 需要编码和配置的工作量比较大。 Redis单点故障，影响序列服务的可用性。 zookeeper生成IDzookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。 很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。 Twitter的snowflake算法snowflake(雪花算法)是Twitter开源的分布式ID生成算法，结果是一个long型的ID。这种方案把64-bit分别划分成多段，分开来标示机器、时间、序列号等。 Snowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。 第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。 时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年 工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。 序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID 具体实现的代码可以参看如下： twitter-archive/snowflake Twitter的雪花算法SnowFlakehttps://github.com/twitter-archive/snowflake beyondfengyu/SnowFlake Twitter的雪花算法SnowFlake，使用Java语言实现。https://github.com/beyondfengyu/SnowFlake snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。 优点 稳定性高，不依赖于数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 灵活方便，可以根据自身业务特性分配bit位。 单机上ID单调自增，毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 缺点 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 ID可能不是全局递增。在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全局递增的情况。 百度 uid-generatoruid-generator是基于Snowflake算法实现的，与原始的snowflake算法不同在于，uid-generator支持自定义时间戳、工作机器ID和 序列号 等各部分的位数，而且uid-generator中采用用户自定义workId的生成策略。 uid-generator需要与数据库配合使用，需要新增一个WORKER_NODE表。当应用启动时会向数据库表中去插入一条数据，插入成功后返回的自增ID就是该机器的workId数据由host，port组成。 对于uid-generator ID组成结构： workId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，而且同一应用每次重启就会消费一个workId。 uid-generator 百度 uid-generatorhttps://github.com/baidu/uid-generator 美团 LeafLeaf由美团开发，Leaf同时支持号段模式和snowflake算法模式，可以切换使用。 号段模式先导入源码 https://github.com/Meituan-Dianping/Leaf，再建一张表 leaf_alloc 12345678910DROP TABLE IF EXISTS `leaf_alloc`;CREATE TABLE `leaf_alloc` ( `biz_tag` varchar(128) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;业务key&#x27;, `max_id` bigint(20) NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;当前已经分配了的最大id&#x27;, `step` int(11) NOT NULL COMMENT &#x27;初始步长，也是动态调整的最小步长&#x27;, `description` varchar(256) DEFAULT NULL COMMENT &#x27;业务key的描述&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;数据库维护的更新时间&#x27;, PRIMARY KEY (`biz_tag`)) ENGINE=InnoDB; 然后在项目中开启号段模式，配置对应的数据库信息，并关闭 snowflake 模式 123456789leaf.name=com.sankuai.leaf.opensource.testleaf.segment.enable=trueleaf.jdbc.url=jdbc:mysql://localhost:3306/leaf_test?useUnicode=true&amp;characterEncoding=utf8&amp;characterSetResults=utf8leaf.jdbc.username=rootleaf.jdbc.password=rootleaf.snowflake.enable=false#leaf.snowflake.zk.address=#leaf.snowflake.port= 启动leaf-server 模块的 LeafServerApplication项目就跑起来了 号段模式获取分布式自增ID的测试url ：http：//localhost：8080/api/segment/get/leaf-segment-test 监控号段模式：http://localhost:8080/cache snowflake模式Leaf的snowflake模式依赖于ZooKeeper，不同于原始snowflake算法也主要是在workId的生成上，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。 123leaf.snowflake.enable=trueleaf.snowflake.zk.address=127.0.0.1leaf.snowflake.port=2181 snowflake模式获取分布式自增ID的测试url：http://localhost:8080/api/snowflake/get/test 滴滴 TinyidTinyid由滴滴开发，Github地址：https://github.com/didi/tinyid。 Tinyid是基于号段模式原理实现的与Leaf如出一辙，每个服务获取一个号段（1000,2000]、（2000,3000]、（3000,4000] Tinyid提供http和tinyid-client两种方式接入 Http 方式接入先导入 Tinyid 源码 https://github.com/didi/tinyid.git，再建一张表 tiny_id_info 123456789101112131415161718192021222324CREATE TABLE `tiny_id_info` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增主键&#x27;, `biz_type` varchar(63) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;业务类型，唯一&#x27;, `begin_id` bigint(20) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;开始id，仅记录初始值，无其他含义。初始化时begin_id和max_id应相同&#x27;, `max_id` bigint(20) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;当前最大id&#x27;, `step` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;步长&#x27;, `delta` int(11) NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;每次id增量&#x27;, `remainder` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;余数&#x27;, `create_time` timestamp NOT NULL DEFAULT &#x27;2010-01-01 00:00:00&#x27; COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT &#x27;2010-01-01 00:00:00&#x27; COMMENT &#x27;更新时间&#x27;, `version` bigint(20) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;版本号&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `uniq_biz_type` (`biz_type`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT &#x27;id信息表&#x27;;CREATE TABLE `tiny_id_token` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增id&#x27;, `token` varchar(255) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;token&#x27;, `biz_type` varchar(63) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;此token可访问的业务类型标识&#x27;, `remark` varchar(255) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;备注&#x27;, `create_time` timestamp NOT NULL DEFAULT &#x27;2010-01-01 00:00:00&#x27; COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT &#x27;2010-01-01 00:00:00&#x27; COMMENT &#x27;更新时间&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT &#x27;token信息表&#x27;; 配置数据库 12345datasource.tinyid.names=primarydatasource.tinyid.primary.driver-class-name=com.mysql.jdbc.Driverdatasource.tinyid.primary.url=jdbc:mysql://ip:port/databaseName?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8datasource.tinyid.primary.username=rootdatasource.tinyid.primary.password=123456 测试 获取分布式自增ID: http://localhost:9999/tinyid/id/nextIdSimple?bizType=test&amp;token=0f673adf80504e2eaa552f5d791b644c&#39; 批量获取分布式自增ID: http://localhost:9999/tinyid/id/nextIdSimple?bizType=test&amp;token=0f673adf80504e2eaa552f5d791b644c&amp;batchSize=10&#39; Java客户端方式接入引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.xiaoju.uemc.tinyid&lt;/groupId&gt; &lt;artifactId&gt;tinyid-client&lt;/artifactId&gt; &lt;version&gt;$&#123;tinyid.version&#125;&lt;/version&gt;&lt;/dependency&gt; 配置文件 12tinyid.server =localhost:9999tinyid.token =0f673adf80504e2eaa552f5d791b644c 12345// 获取单个分布式自增IDLong id = TinyId.nextId(&quot;test&quot;);// 按需批量分布式自增IDList&lt;Long&gt; ids = TinyId.nextId(&quot;test&quot;, 10); test 是具体业务类型","tags":["分布式ID","全局唯一ID"],"categories":["分布式"]},{"title":"RTO & RPO","path":"/design/rtorpo/","content":"RTO &amp; RPO在故障恢复方面，目前业界公认有三个目标值得努力。 恢复时间：企业能忍受多长时间没有 IT，处于停业状态。 网络多长时间能够恢复 业务层面的恢复 整个恢复过程中，最关键的衡量指标有两个：一个是 RTO，另一个是 RPO。 所谓 RTO，Recovery Time Objective，是指故障发生后，从 IT 系统宕机导致业务停顿之时开始，到 IT 系统恢复至可以支持各部门运作、恢复运营之时，此两点之间的时间段称为 RTO。 所谓 RPO，Recovery Point Objective，是指对系统和应用数据而言，要实现能够恢复至可以支持各部门业务运作，系统及生产数据应恢复到怎样的更新程度。这种更新程度可以是上一周的备份数据，也可以是上一次交易的实时数据。 选择标准对故障恢复而言，RTO 与 RPO 哪个衡量指标更合适呢？ 在考虑采用哪个指标之前，IT 人首先要弄清楚一个基本概念，企业的容灾系统预防的是什么灾害，是多少年一遇的，能忍受多少损失，需要算出一个大概的成本，当然不一定很精确。其次，无论企业容灾系统是采用冷备、热备、温备、还是磁盘备份，几分钟恢复业务和几天恢复业务效果是完全不一样的。企业需要明确对恢复时间的容忍底限是多少。 再从灾备本身的意义来讲，无论采用哪种衡量指标，最终目的是要能够很好地检验灾备系统的实用性能，否则就失去建立灾备的意义了。而灾备最核心的作用就是确保灾难发生后业务能够连续运行，交易中的数据完整保存，丢失越少越好。因此业务层面的恢复，企业要有一个底限。参考世界范围内一系列灾难恢复经验，国家之间的差别非常大。比如在美国，政府是第一位的，警察局对数据的恢复要求特别高。而在中国，无论什么性质，银行始终是排在第一位的。 综合平衡作为银行，除开展自身业务之外，更多数据来自上下级银行间的财务汇兑与结算。 站在管理者的位置上，一旦灾难发生，最重要的是在尽可能短的时间内排除障碍，恢复业务，保证系统做到连续运行。因此，从这个角度出发，银行容许系统停滞的时间应当越短越好。选择 RTO 刚好合适。 但是，RTO 对成本要求太高，与回报似乎不成正比。企业资金不可能无限制地投入到一个灾备系统中。对于银行证券这样的联机交易事故处理非常紧密的金融机构而言，可能每一笔、每一单、每一分钱都很重要，所以都需要恢复。RPO 显然更为合适。 许多时候进行选择并不意味着非此即彼，这与现实婚姻中一夫一妻的限制还是有差别的。RTO 和 RPO 对银行来讲都很重要。RTO 越短、RPO 越新，银行面临的损失就越小，但这也意味着系统开发成本将会急剧上升。许多时候，最佳的容灾解决方案却不一定是效益最好的。反之亦是。如何去平衡这中间的关系，不仅是门学问，更像是艺术。 根据国际经验，在选择“你”还是“她”的时候，企业应当考虑灾难发生后会在多大层面上冲击业务，这涉及到企业形象，商业机密，信誉评级，品牌竞争力等等方面，各个企业的情况不同，要根据自己的情况选择合适的“对象”。灾难恢复的目的是业务连续进行，因此无论采用 RTO 还是 RPO，都要朝着这个核心靠拢。","tags":["RTO","RPO"],"categories":["系统设计"]},{"title":"幂等性","path":"/design/idempotent/","content":"什么是幂等性幂等性最早是数学里面的一个概念，后来被用于计算机领域，用于表示任意多次请求均与一次请求执行的结果相同，也就是说对于一个接口而言，无论调用了多少次，最终得到的结果都是一样的。比如以下代码： 123456789101112131415161718public class IdempotentExample &#123; // 变量 private static int count = 0; /** * 非幂等性方法 */ public static void addCount() &#123; count++; &#125; /** * 幂等性方法 */ public static void printCount() &#123; System.out.println(count); &#125;&#125; 对于变量 count 来说，如果重复调用 addCount() 方法的话，会一直累加 count 的值，因为 addCount() 方法就是非幂等性方法；而 printCount() 方法只是用来打印控制台信息的。因此，它无论调用多少次结果都是一样的，所以它是幂等性方法。 幂等性注意事项幂等性的实现与判断需要消耗一定的资源，因此不应该给每个接口都增加幂等性判断，要根据实际的业务情况和操作类型来进行区分。 例如，我们在进行查询操作和删除操作时就无须进行幂等性判断。查询操作查一次和查多次的结果都是一致的，因此我们无须进行幂等性判断。删除操作也是一样，删除一次和删除多次都是把相关的数据进行删除（这里的删除指的是条件删除而不是删除所有数据），因此也无须进行幂等性判断。 幂等性的关键步骤实现幂等性的关键步骤分为以下三个： 每个请求操作必须有唯一的 ID，而这个 ID 就是用来表示此业务是否被执行过的关键凭证，例如，订单支付业务的请求，就要使用订单的 ID 作为幂等性验证的 Key； 每次执行业务之前必须要先判断此业务是否已经被处理过； 第一次业务处理完成之后，要把此业务处理的状态进行保存，比如存储到 Redis 中或者是数据库中，这样才能防止业务被重复处理。 知道了幂等性的概念，那如何保证幂等性呢？ 如何保证接口的幂等性？幂等性的实现方案通常分为以下几类： 前端拦截 使用数据库实现幂等性 使用 JVM 锁实现幂等性 使用分布式锁实现幂等性 下面我们分别来看它们的具体实现过程。 前端拦截前端拦截是指通过 Web 站点的页面进行请求拦截，比如在用户点击完“提交”按钮后，我们可以把按钮设置为不可用或者隐藏状态，避免用户重复点击。 但前端拦截有一个致命的问题，如果是懂行的程序员或者黑客可以直接绕过页面的 JS 执行，直接模拟请求后端的接口，这样的话，我们前端的这些拦截就不能生效了。因此除了前端拦截一部分正常的误操作之外，后端的验证必不可少。 数据库实现数据库实现幂等性的方案有三个： 通过悲观锁来实现幂等性 通过唯一索引来实现幂等性 通过乐观锁来实现幂等性 悲观锁 使用悲观锁实现幂等性，一般是配合事务一起来实现，在没有使用悲观锁时，我们通常的执行过程是这样的，首先来判断数据的状态，执行 SQL 如下： 1select status from table_name where id=&#x27;xxx&#x27;; 然后再进行添加操作： 1insert into table_name (id) values (&#x27;xxx&#x27;); 最后再进行状态的修改： 1update table_name set status=&#x27;xxx&#x27;; 但这种情况因为是非原子操作，所以在高并发环境下可能会造成一个业务被执行两次的问题，当一个程序在执行中时，而另一个程序也开始状态判断的操作。因为第一个程序还未来得及更改状态，所以第二个程序也能执行成功，这就导致一个业务被执行了两次。 在这种情况下我们就可以使用悲观锁来避免问题的产生，实现 SQL 如下所示： 12345begin; # 1.开始事务select * from table_name where id=&#x27;xxx&#x27; for update; # 2.查询状态insert into table_name (id) values (&#x27;xxx&#x27;); # 3.添加操作update table_name set status=&#x27;xxx&#x27;; # 4.更改操作commit; # 5.提交事务 在实现的过程中需要注意以下两个问题： 如果使用的是 MySQL 数据库，必须选用 innodb 存储引擎，因为 innodb 支持事务； id 字段一定要是主键或者是唯一索引，不然会锁表，影响其他业务执行。 唯一索引 我们可以创建一个唯一索引的表来实现幂等性，在每次执行业务之前，先执行插入操作，因为唯一字段就是业务的 ID，因此如果重复插入的话会触发唯一约束而导致插入失败。在这种情况下（插入失败）我们就可以判定它为重复提交的请求。 唯一索引表的创建示例如下： 123456CREATE TABLE `table_name` ( `id` int NOT NULL AUTO_INCREMENT, `orderid` varchar(32) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;唯一id&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `uq_orderid` (`orderid`) COMMENT &#x27;唯一约束&#x27;) ENGINE=InnoDB; 乐观锁 乐观锁是指在执行数据操作时（更改或添加）进行加锁操作，其他时间不加锁，因此相比于整个执行过程都加锁的悲观锁来说，它的执行效率要高很多。 乐观锁可以通过版本号来实现，例如以下 SQL： 1update table_name set version=version+1 where version=0; JVM 锁实现JVM 锁实现是指通过 JVM 提供的内置锁如 Lock 或者是 synchronized 来实现幂等性。使用 JVM 锁来实现幂等性的一般流程为：首先通过 Lock 对代码段进行加锁操作，然后再判断此订单是否已经被处理过，如果未处理则开启事务执行订单处理，处理完成之后提交事务并释放锁，执行流程如下图所示： JVM 锁存在的最大问题在于，它只能应用于单机环境，因为 Lock 本身为单机锁，所以它就不适应于分布式多机环境。 分布式锁实现分布式锁实现幂等性的逻辑是，在每次执行方法之前先判断是否可以获取到分布式锁，如果可以，则表示为第一次执行方法，否则直接舍弃请求即可，执行流程如下图所示： 需要注意的是分布式锁的 key 必须为业务的唯一标识，我们通常使用 Redis 或者 ZooKeeper 来实现分布式锁；如果使用 Redis 的话，则用 set 命令来创建和获取分布式锁，执行示例如下： 12127.0.0.1:6379&gt; set lock true ex 30 nxOK # 创建锁成功 其中，ex 是用来设置超时时间的；而 nx 是 not exists 的意思，用来判断键是否存在。如果返回的结果为“OK”，则表示创建锁成功，否则表示重复请求，应该舍弃。","tags":["幂等性","系统设计"],"categories":["系统设计"]},{"title":"RPC vs REST","path":"/framework/rpc-rest/","content":"RPCRPC 是指远程服务调用（Remote Procedure Call） 也就是说两台服务器 A 和B。一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数 / 方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。 最终解决的问题：让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。 RPC 要解决的三个基本问题： 如何表示数据：这里数据包括了传递给方法的参数，以及方法执行后的返回值。 进程内的方法调用，使用自定义的数据类型，就很容易解决数据表示问题，远程方法调用则完全可能面临交互双方各自使用不同程序语言的情况； 即使只支持一种程序语言的 RPC 协议，在不同硬件指令集、不同操作系统下，同样的数据类型也完全可能有不一样表现细节，譬如数据宽度、字节序的差异等等。 有效的做法是交互双方约定一种序列化和反序列化协议，将所涉及的数据转换为某种事先约定好的中立数据流格式来进行传输。 每种 RPC 协议都应该要有对应的序列化协议 如何传输数据：准确地说，是指如何通过网络，在两个服务的 Endpoint 之间相互操作、交换数据。 这里“交换数据”通常指的是应用层协议，实际传输一般是基于标准的 TCP、UDP 等标准的传输层协议来完成的。 两个服务交互不是只扔个序列化数据流来表示参数和结果就行的，许多在此之外信息，譬如异常、超时、安全、认证、授权、事务，等等，都可能产生双方需要交换信息的需求。 如果要求足够简单，双方都是 HTTP Endpoint，直接使用 HTTP 协议也是可以的 如何确定方法：这在本地方法调用中并不是太大的问题，编译器或者解释器会根据语言规范，将调用的方法签名转换为进程空间中子过程入口位置的指针。 不过一旦要考虑不同语言，事情又立刻麻烦起来，每门语言的方法签名都可能有所差别，所以“如何表示同一个方法”，“如何找到对应的方法”还是得弄个跨语言的统一的标准才行。 为什么用 RPC，不用 HTTPRPC 是一种设计，就是为了解决不同服务之间的调用问题，完整的 RPC 实现一般会包含有 传输协议 和 序列化协议 这两个。 而 HTTP 是一种传输协议，RPC 框架完全可以使用 HTTP 作为传输协议，也可以直接使用 TCP，使用不同的协议一般也是为了适应不同的场景。 使用 TCP 和使用 HTTP 各有优势： 传输效率： TCP，通常自定义上层协议，可以让请求报文体积更小 HTTP：如果是基于HTTP 1.1 的协议，请求中会包含很多无用的内容 性能消耗，主要在于序列化和反序列化的耗时 TCP，可以基于各种序列化框架进行，效率比较高 HTTP，大部分是通过 json 来实现的，字节大小和序列化耗时都要更消耗性能 跨平台： TCP：通常要求客户端和服务器为统一平台 HTTP：可以在各种异构系统上运行 RESTREST 无论是在思想上、概念上，还是使用范围上，与 RPC 都不尽相同，充其量只能算是有一些相似，应用会有一部分重合之处，但本质上并不是同一类型的东西。 REST 与 RPC 在思想上差异的核心是抽象的目标不一样，即面向资源的编程思想与面向过程的编程思想两者之间的区别。 概念上的不同是指 REST 并不是一种远程服务调用协议(它不是一种协议, 更像是一种设计风格)。协议都带有一定的规范性和强制性，最起码也该有个规约文档，譬如 JSON-RPC，它哪怕再简单，也要有个《JSON-RPC Specification》来规定协议的格式细节、异常、响应码等信息，但是 REST 并没有定义这些内容，尽管有一些指导原则，但实际上并不受任何强制的约束。 REST，即“表征状态转移”的缩写。 下面通过一个具体事例来理解什么是“表征”以及 REST 中其他关键概念： 资源（Resource）：譬如你现在正在阅读一篇名为《REST 设计风格》的文章，这篇文章的内容本身称之为“资源”。无论你是购买的书籍、是在浏览器看的网页、是打印出来看的文稿、是在电脑屏幕上阅读抑或是手机上浏览，尽管呈现的样子各不相同，但其中的信息是不变的，你所阅读的仍是同一份“资源”。 表征（Representation）：当你通过电脑浏览器阅读此文章时，浏览器向服务端发出请求“我需要这个资源的 HTML 格式”，服务端向浏览器返回的这个 HTML 就被称之为“表征”，你可能通过其他方式拿到本文的 PDF、Markdown、RSS 等其他形式的版本，它们也同样是一个资源的多种表征。 状态（State）：当你读完了这篇文章，想看后面是什么内容时，你向服务器发出请求“给我下一篇文章”。但是“下一篇”是个相对概念，必须依赖“当前你正在阅读的文章是哪一篇”才能正确回应，这类在特定语境中才能产生的上下文信息即被称为“状态”。我们所说的有状态（Stateful）抑或是无状态（Stateless），都是只相对于服务端来说的，服务器要完成“取下一篇”的请求，要么自己记住用户的状态：这个用户现在阅读的是哪一篇文章，这称为有状态；要么客户端来记住状态，在请求的时候明确告诉服务器：我正在阅读某某文章，现在要读它的下一篇，这称为无状态。 转移（Transfer）：无论状态是由服务端还是客户端来提供的，“取下一篇文章”这个行为逻辑必然只能由服务端来提供，因为只有服务端拥有该资源及其表征形式。服务器通过某种方式，把“用户当前阅读的文章”转变成“下一篇文章”，这就被称为“表征状态转移”。 RESTful 的系统一套理想的、完全满足 REST 风格的系统应该满足以下六大原则。 服务端与客户端分离（Client-Server） 无状态（Stateless） 无状态是 REST 的一条核心原则。 REST 希望服务器不要去负责维护状态，每一次从客户端发送的请求中，应包括所有的必要的上下文信息，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。 客户端承担状态维护职责以后，会产生一些新的问题，譬如身份认证、授权等可信问题。 但必须承认的现状是，目前大多数的系统都达不到这个要求，往往越复杂、越大型的系统越是如此。服务端无状态可以在分布式计算中获得非常高价值的好处，但大型系统的上下文状态数量完全可能膨胀到让客户端在每次请求时提供变得不切实际的程度，在服务端的内存、会话、数据库或者缓存等地方持有一定的状态成为一种是事实上存在，并将长期存在、被广泛使用的主流的方案。 可缓存（Cacheability） 无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性。 “降低网络性”的通俗解释是某个功能如果使用有状态的设计只需要一次（或少量）请求就能完成，使用无状态的设计则可能会需要多次请求，或者在请求中带有额外冗余的信息。 为了缓解这个矛盾，REST 希望软件系统能够如同万维网一样，允许客户端和中间的通讯传递者（譬如代理）将部分服务端的应答缓存起来。 当然，为了缓存能够正确地运作，服务端的应答中必须明确地或者间接地表明本身是否可以进行缓存、可以缓存多长时间，以避免客户端在将来进行请求的时候得到过时的数据。 运作良好的缓存机制可以减少客户端、服务器之间的交互，甚至有些场景中可以完全避免交互，这就进一步提了高性能。 分层系统（Layered System） 这里所指的并不是表示层、服务层、持久层这种意义上的分层。而是指客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器。 中间服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。 该原则的典型的应用是内容分发网络（Content Distribution Network，CDN）。如果你是通过网站浏览到这篇文章的话，你所发出的请求一般并不是直接访问位于 GitHub Pages 的源服务器，而是访问了位于国内的 CDN 服务器，但作为用户，你完全不需要感知到这一点。 统一接口（Uniform Interface） 这是 REST 的另一条核心原则。REST 希望开发者面向资源编程，希望软件系统设计的重点放在抽象系统该有哪些资源上，而不是抽象系统该有哪些行为（服务）上。 这条原则你可以类比计算机中对文件管理的操作来理解，管理文件可能会进行创建、修改、删除、移动等操作，这些操作数量是可数的，而且对所有文件都是固定的、统一的。如果面向资源来设计系统，同样会具有类似的操作特征，由于 REST 并没有设计新的协议，所以这些操作都借用了 HTTP 协议中固有的操作命令来完成。 按需代码 REST 的优势REST 的基本思想是面向资源来抽象问题，它与此前流行的编程思想——面向过程的编程在抽象主体上有本质的差别。 在 REST 提出以前，人们设计分布式系统服务的唯一方案就只有 RPC，RPC 是将本地的方法调用思路迁移到远程方法调用上，开发者是围绕着“远程方法”去设计两个系统间交互的。 这样做的坏处不仅是“如何在异构系统间表示一个方法”、“如何获得接口能够提供的方法清单”都成了需要专门协议去解决的问题（RPC 的三大基本问题之一），更在于服务的每个方法都是完全独立的，服务使用者必须逐个学习才能正确地使用它们。 REST 提出以资源为主体进行服务设计的风格，能为它带来不少好处，譬如： 降低的服务接口的学习成本。统一接口（Uniform Interface）是 REST 的重要标志，将对资源的标准操作都映射到了标准的 HTTP 方法上去，这些方法对于每个资源的用法都是一致的，语义都是类似的，不需要刻意去学习，更不需要有什么 Interface Description Language 之类的协议存在。 资源天然具有集合与层次结构。以方法为中心抽象的接口，由于方法是动词，逻辑上决定了每个接口都是互相独立的；但以资源为中心抽象的接口，由于资源是名词，天然就可以产生集合与层次结构。 REST 绑定于 HTTP 协议。面向资源编程不是必须构筑在 HTTP 之上，但 REST 是，这是缺点，也是优点。 因为 HTTP 本来就是面向资源而设计的网络协议，纯粹只用 HTTP（而不是 SOAP over HTTP 那样在再构筑协议）带来的好处是 RPC 中的 Wire Protocol 问题就无需再多考虑了，REST 将复用 HTTP 协议中已经定义的概念和相关基础支持来解决问题。HTTP 协议已经有效运作了三十年，其相关的技术基础设施已是千锤百炼，无比成熟。而坏处自然是，当你想去考虑那些 HTTP 不提供的特性时，便会彻底地束手无策。 REST 的不足 面向资源的编程思想只适合做 CRUD，面向过程、面向对象编程才能处理真正复杂的业务逻辑 REST 与 HTTP 完全绑定，不适合应用于要求高性能传输的场景中 REST 没有传输可靠性支持 REST 缺乏对资源进行“部分”和“批量”的处理能力 RMM 成熟度模型《RESTful Web APIs》和《RESTful Web Services》的作者 Leonard Richardson 曾提出过一个衡量“服务有多么 REST”的 Richardson 成熟度模型（Richardson Maturity Model），便于那些原本不使用 REST 的系统，能够逐步地导入 REST。Richardson 将服务接口“REST 的程度”从低到高，分为 0 至 3 级： The Swamp of Plain Old XML：完全不 REST。另外，关于 Plain Old XML 这说法，SOAP 表示感觉有被冒犯到。 Resources：开始引入资源的概念。 HTTP Verbs：引入统一接口，映射到 HTTP 协议的方法上。 Hypermedia Controls：超媒体控制在本文里面的说法是“超文本驱动”，在 Fielding 论文里的说法是“Hypertext As The Engine Of Application State，HATEOAS”，其实都是指同一件事情。","tags":["RPC","REST"],"categories":["RPC","REST"]},{"title":"常见限流算法","path":"/design/limiting/","content":"限流工程上的限流是什么呢？ 限制的是 「流」，在不同场景下「流」的定义不同，可以是每秒请求数、每秒事务处理数、网络流量等等。 通常我们说的限流指代的是 限制到达系统的并发请求数，使得系统能够正常的处理 部分 用户的请求，来保证系统的稳定性。 限流不可避免的会造成用户的请求变慢或者被拒的情况，从而会影响用户体验。因此限流是需要在用户体验和系统稳定性之间做平衡的，即我们常说的 trade off。 限流也称流控（流量控制）。 为什么需要限流限流是为了保证系统的稳定性。 限流的本质是因为后端处理能力有限，需要截掉超过处理能力之外的请求，亦或是为了均衡客户端对服务端资源的公平调用，防止一些客户端饿死。 常见的限流算法计数限流、滑动窗口限流、漏桶限流、令牌桶限流。 计数限流计数限流是指限制某一个接口或者某一行为单位时间内的响应次数。设置一个计数器，对某一时间段内的请求进行计数，当请求超过设置的阈值之后则触发饱和策略（可以选择拒绝/阻塞请求）。 1234567boolean tryAcquire() &#123; if (counter &lt; threshold) &#123; counter ++; return true; &#125; return false;&#125; 优点：简单粗暴，单机在 Java 中可用 Atomic 等原子类、分布式就 Redis incr。 缺点： 对突增流量处理不优化，有可能被绕过限流策略 假设系统每秒允许 100 个请求，假设第一个时间窗口是 0-1s，在第 0.55s 处一下次涌入 100 个请求，过了 1 秒的时间窗口后计数清零，此时在 1.05 s 的时候又一下次涌入100个请求。 虽然窗口内的计数没超过阈值，但是全局来看在 0.55s-1.05s 这 0.1 秒内涌入了 200 个请求，这其实对于阈值是 100/s 的系统来说是无法接受的。 滑动窗口限流滑动窗口限流解决了上面的问题，可以保证在任意时间窗口内都不会超过阈值。 滑动窗口除了需要引入计数器之外还需要记录时间窗口内每个请求到达的时间点，因此对内存的占用会比较多。 规则如下，假设时间窗口为 1 秒 记录每次请求的时间 统计每次请求的时间 至 往前推1秒这个时间窗口内请求数，并且 1 秒前的数据可以删除。 统计的请求数小于阈值就记录这个请求的时间，并允许通过，反之拒绝。 1234567891011boolean tryAcquire() &#123; // 获取当前时间 long now = currentTimeMuillis(); // 根据当前时间获取窗口内的计数 long counter = getCounterInTimeWindow(now); if (counter &lt; threshold) &#123; // 小于阈值 addToTimeWindow(now); return true; &#125; return false;&#125; 滑动窗口虽然解决了计数算法的临界值问题，但是对突增流量问题依旧不友好。 漏桶算法漏桶（Leaky Bucket）算法是限流方面比较经典的算法，该算法最早应用于网络拥塞控制方面。 理解该算法可以联想一个具体的漏桶模型，不管进水量有多大，漏桶始终以恒定的速率往外排水，如果桶被装满则后来涌入的水会漫出去。 对应接口限流来说，用户的请求可以看做是这里的水，不管用户的请求量有多大多不均衡，能够被处理的请求速率是恒定的，而且能够被接受的请求数也是有上限的，超出上限的请求会被拒绝，典型的我们可以采用队列作为这里的漏桶实现。 123456789101112131415boolean tryAcquire() &#123; // 获取当前时间 long now currentTimeMillis(); // （当前时间 - 上次注水时间）*流出速率 = 流出的水量 long consumeWater = (now - lastInjectTime) * rate; // 之前桶内的水量 - 这段时间流出的水量 long leftWater = max(0, leftWater - consumeWater); if (leftWater + 1 &lt;= capacity) &#123; lastInjectTime = now; leftWater ++; return true; &#125; else &#123; return false; &#125;&#125; 由上面的解释我们应该能够感觉到漏桶算法非常适用于秒杀系统的限流，漏桶在这种应用场景下可以起到一定的削峰填谷的作用，并且漏桶的设计从根本上能够应对集中访问的问题，同时具备平滑策略，但是始终恒定的处理速率有时候并不一定是好事情，对于突发的请求洪峰，在保证服务安全的前提下，应该尽最大努力去响应，这个时候漏桶算法显得有些呆滞。 令牌桶算法令牌桶（Token Bucket）算法可以看作是漏桶算法的逆过程。该算法要求系统以一定的速率发放访问令牌，用户的请求必须在持有合法令牌的前提下才能够被响应，我们可以按照权重设置一类请求被响应所需持有的令牌数，只有当桶中的令牌数目满足当前请求所需时才授予令牌，对于其他情况则拒绝该请求。 可以看出令牌桶在应对突发流量的时候，桶内假如有 100 个令牌，那么这 100 个令牌可以马上被取走，而不像漏桶那样匀速的消费。所以在应对突发流量的时候令牌桶表现的更佳。 虽然漏桶和令牌桶对比时间窗口对流量的限流效果更佳，流量更加得平滑，但是也有各自的缺点。 拿令牌桶来说，假设没预热，在刚上线时候桶里没令牌，这是就会存在误杀问题（系统明明没有负载）。 再比如说请求的访问其实是随机的，假设令牌桶每20ms放入一个令牌，桶内初始没令牌，这请求就刚好在第一个20ms内有两个请求，再过20ms里面没请求，其实从40ms来看只有2个请求，应该都放行的，而有一个请求就直接被拒了。这就有可能造成很多请求的误杀，但是如果看监控曲线的话，好像流量很平滑，峰值也控制的很好。 再拿漏桶来说，漏桶中请求是暂时存在桶内的。这其实不符合互联网业务低延迟的要求。 所以漏桶和令牌桶其实比较适合阻塞式限流场景，即没令牌我就等着，这就不会误杀了，而漏桶本就是等着。比较适合后台任务类的限流。而基于时间窗口的限流比较适合对时间敏感的场景，请求过不了您就快点儿告诉我，等的花儿都谢了。 限流的难点__限流的难点在于配置__，如何让限流在不误伤的前提下尽量发挥硬件的最大性能是一个富有经验的问题，而压测是一个基础且行之有效的途径。 限流组件 Google Guava - RateLimiter（基于令牌桶实现，并扩展了算法，支持预热功能） Alibaba - Sentinel （基于漏桶算法，匀速排队限流策略）","tags":["限流算法","系统设计"],"categories":["系统设计"]},{"title":"【转】如何设计一个可扩展的限流算法","path":"/design/how-to-design-extensible-limiting-algorithm/","content":"限流（Rate Limiting，即速率限制）通过限制每个用户调用API的频率来防止API被过度使用，这可以防止他们因疏忽或恶意导致的API滥用。在没有速率限制的情况下，每个用户可以随心所欲地请求，这可能会导致“峰值”请求，从而导致其他用户得不到响应。在启用速率限制之后，它们的请求将被限制为每秒固定的数量。 在示例图表中，你可以看到速率限制如何在一段时间内阻塞请求。API最初每分钟接收4个请求，用绿色表示。当12:02启用速率限制时，以红色显示的其他请求将被拒绝。 速率限制对于公共API是非常重要的，因为你想要为每个消费者（API调用者）维护良好的服务质量，即使有些用户获取了超出其公平配额的服务。计算密集型的端点特别需要速率限制——特别是通过自动伸缩或AWS Lambda和OpenWhisk等按计算付费服务来提供服务时。你还可能希望对提供敏感数据的API进行评级，因为如果攻击者在某些不可预见的事件中获得访问权限，这可能会限制暴露的数据。 实际上有许多不同的方法来实现速率限制，我们将探讨不同速率限制算法的优缺点。我们还将探讨跨集群扩展时出现的问题。最后，我们将向你展示一个如何使用Kong快速设置速率限制的示例，Kong是最流行的开源API网关。 速度限制算法有各种各样的速率限制算法，每一种都有自己的优点和缺点。让我们回顾一下，这样你就可以根据自己的需要选择最好的限流算法。 漏桶算法漏桶算法（Leaky Bucket，与令牌桶密切相关）是这样一种算法，它提供了一种简单、直观的方法来通过队列限制速率，你可以将队列看作一个存储请求的桶。当一个请求被注册时，它被附加到队列的末尾。每隔一段时间处理队列上的第一项。这也称为先进先出（FIFO）队列。如果队列已满，则丢弃（或泄漏）其他请求。 这种算法的优点是它可以平滑请求的爆发，并以近似平均的速度处理它们。它也很容易在单个服务器或负载均衡器上实现，并且在有限的队列大小下对于每个用户都是内存有效的。 然而，突发的访问量会用旧的请求填满队列，并使最近的请求无法被处理。它也不能保证在固定的时间内处理请求。此外，如果为了容错或增加吞吐量而负载平衡服务器，则必须使用策略来协调和强制它们之间的限制。稍后我们将讨论分布式环境的挑战。 固定窗口算法在固定窗口（Fixed Window）算法中，使用n秒的窗口大小（通常使用对人类友好的值，如60秒或3600秒）来跟踪速率。每个传入的请求都会增加窗口的计数器。如果计数器超过阈值，则丢弃请求。窗口通常由当前时间戳的层定义，因此12:00:03的窗口长度为60秒，应该在12:00:00的窗口中。 这种算法的优点是，它可以确保处理更多最近的请求，而不会被旧的请求饿死。然而，发生在窗口边界附近的单个流量突发会导致处理请求的速度增加一倍，因为它允许在短时间内同时处理当前窗口和下一个窗口的请求。另外，如果许多消费者等待一个重置窗口，例如在一个小时的顶部，那么他们可能同时扰乱你的API。 滑动日志算法滑动日志（Sliding Log）速率限制涉及到跟踪每个使用者请求的时间戳日志。这些日志通常存储在按时间排序的散列集或表中。时间戳超过阈值的日志将被丢弃。当新请求出现时，我们计算日志的总和来确定请求率。如果请求将超过阈值速率，则保留该请求。 该算法的优点是不受固定窗口边界条件的限制，速率限制将严格执行。此外，因为滑动日志是针对每个消费者进行跟踪的，所以不会出现对固定窗口造成挑战的踩踏效应。但是，为每个请求存储无限数量的日志可能非常昂贵。它的计算成本也很高，因为每个请求都需要计算使用者先前请求的总和，这些请求可能跨越一个服务器集群。因此，它不能很好地处理大规模的流量突发或拒绝服务攻击。 滑动窗口这是一种将固定窗口算法的低处理成本与改进的滑动日志边界条件相结合的混合方法。与固定窗口算法一样，我们跟踪每个固定窗口的计数器。接下来，我们根据当前的时间戳计算前一个窗口请求率的加权值，以平滑突发的流量。例如，如果当前窗口通过了25%，那么我们将前一个窗口的计数加权为75%。跟踪每个键所需的相对较少的数据点允许我们在大型集群中扩展和分布。 我们推荐使用滑动窗口方法，因为它可以灵活地调整速率限制，并且具有良好的性能。速率窗口是它向API消费者提供速率限制数据的一种直观方式。它还避免了漏桶的饥饿问题和固定窗口实现的突发问题。 分布式系统中的速率限制同步策略如果希望在使用多个节点的集群时实施全局速率限制，则必须设置策略来实施该限制。如果每个节点都要跟踪自己的速率限制，那么当请求被发送到不同节点时，使用者可能会超过全局速率限制。实际上，节点的数量越大，用户越有可能超过全局限制。 执行此限制的最简单方法是在负载均衡器中设置粘性会话，以便每个使用者都被精确地发送到一个节点。缺点包括缺乏容错性和节点过载时的缩放问题。 允许更灵活的负载平衡规则的更好解决方案是使用集中的数据存储，如Redis或Cassandra。这将存储每个窗口和消费者的计数。这种方法的两个主要问题是增加了向数据存储发出请求的延迟，以及竞争条件（我们将在下面讨论）。 竞态条件集中式数据存储的最大问题之一是高并发请求模式中的竞争条件。当你使用一种简单的“get-then-set”方法时，就会发生这种情况，在这种方法中，你检索当前速率限制计数器，增加它的值，然后将其推回到数据存储中。这个模型的问题是，在执行一个完整的读递增存储周期时，可能会出现额外的请求，每个请求都试图用无效的（较低的）计数器值存储递增计数器。这允许使用者发送非常高的请求率来绕过速率限制控制。 避免这个问题的一种方法是在有问题的密钥周围放置一个“锁”，防止任何其他进程访问或写入计数器。这将很快成为一个主要的性能瓶颈，而且伸缩性不好，特别是在使用诸如Redis之类的远程服务器作为备份数据存储时。 更好的方法是使用“先设置后获取”的心态，依赖于原子操作符，它们以一种非常高性能的方式实现锁，允许你快速增加和检查计数器值，而不让原子操作成为障碍。 性能优化使用集中式数据存储的另一个缺点是，在检查速率限制计数器时增加了延迟。不幸的是，即使是检查像Redis这样的快速数据存储，也会导致每个请求增加毫秒的延迟。 为了以最小的延迟确定这些速率限制，有必要在内存中进行本地检查。这可以通过放松速率检查条件和使用最终一致的模型来实现。例如，每个节点可以创建一个数据同步周期，该周期将与中央数据存储同步。每个节点定期将每个使用者的计数器增量和它看到的窗口推送到数据存储，数据存储将自动更新这些值。然后，节点可以检索更新后的值来更新其内存版本。集群内节点之间的这种收敛→发散→再收敛的循环最终是一致的。 节点聚合的周期速率应该是可配置的。当流量分布在群集中的多个节点上时（例如，当坐在一个轮询调度平衡器后面时），较短的同步间隔将导致较少的数据点分散，而较长的同步间隔将对数据存储施加较小的读/写压力，更少的开销在每个节点上获取新的同步值。 使用Kong快速设置速率限制Kong是一个开源的API网关，它使构建具有速率限制的可伸缩服务变得非常容易。它被全球超过300,000个活动实例使用。它可以完美地从单个的Kong节点扩展到大规模的、跨越全球的Kong集群。 Kong位于API前面，是上游API的主要入口。在处理请求和响应时，Kong将执行你决定添加到API中的任何插件。 Kong的速率限制插件是高度可配置的。它提供了为每个API和消费者定义多个速率限制窗口和速率的灵活性。它支持本地内存、Redis、Postgres和Cassandra备份数据存储。它还提供了各种数据同步选项，包括同步和最终一致的模型。 你可以在其中一台开发机器上快速安装Kong来测试它。我最喜欢的入门方式是使用AWS云形成模板，因为只需几次单击就可以获得预先配置好的开发机器。只需选择一个HVM选项，并将实例大小设置为使用t2.micro，这些对于测试都是负担得起的。然后ssh到新实例上的命令行进行下一步。 在Kong上添加API下一步是使用Kong的admin API在Kong上添加一个API。我们将使用httpbin作为示例，它是一个针对API的免费测试服务。get URL将把我的请求数据镜像成JSON。我们还假设Kong在本地系统上的默认端口上运行。 12345curl -i -X POST \\--url http://localhost:8001/apis/ \\--data &#x27;name=test&#x27; \\--data &#x27;uris=/test&#x27; \\--data &#x27;upstream_url=http://httpbin.org/get&#x27; 现在 Kong 意识到每个发送到 “/test” 的请求都应该代理到 httpbin。我们可以向它的代理端口上的 Kong 发出以下请求来测试它： 12345678910111213curl http://localhost:8000/test&#123; &quot;args&quot;: &#123;&#125;, &quot;headers&quot;: &#123; &quot;Accept&quot;: &quot;*/*&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;curl/7.51.0&quot;, &quot;X-Forwarded-Host&quot;: &quot;localhost&quot; &#125;, &quot;origin&quot;: &quot;localhost, 52.89.171.202&quot;, &quot;url&quot;: &quot;http://localhost/get&quot;&#125; 它还是好的！Kong 已经接收了请求并将其代理到 httpbin，httpbin 已将我的请求头和我的原始 IP 地址进行了镜像。 添加基本的速率限制让我们继续，通过使用社区版的限速插件 [1] 添加限速功能来保护它不受过多请求的影响，每个消费者每分钟只能发出 5 个请求： 123curl -i -X POST http://localhost:8001/apis/test/plugins/ \\-d &quot;name=rate-limiting&quot; \\-d &quot;config.minute=5&quot; 如果我们现在发出超过 5 个请求，Kong 会回复以下错误信息： 1234curl http://localhost:8000/test&#123; &quot;message&quot;:&quot;API rate limit exceeded&quot;&#125; 看上去不错！我们在 Kong 上添加了一个 API，并且仅在两个 HTTP 请求中向 Kong 的 admin API 添加了速率限制。 它默认使用固定的窗口来限制 IP 地址的速率，并使用默认的数据存储在集群中的所有节点之间进行同步。有关其他选项，包括每个用户的速率限制或使用其他数据存储（如 Redis），请参阅文档 [1]。 企业版 Kong，更好的性能企业版 [2] 的速率限制增加了对滑动窗口算法的支持，以更好地控制和性能。滑动窗口可以防止你的 API 在窗口边界附近重载，如上面的部分所述。对于低延迟，它使用计数器的内存表，可以使用异步或同步更新跨集群进行同步。这提供了本地阈值的延迟，并且可以跨整个集群扩展。 第一步是安装企业版的 Kong。然后，可以配置速率限制、以秒为单位的窗口大小和同步计数器值的频率。它真的很容易使用，你可以得到这个强大的控制与一个简单的 API 调用： 12345curl -i -X POST http://localhost:8001/apis/test/plugins \\-d &quot;name=rate-limiting&quot; \\-d &quot;config.limit=5&quot; \\-d &quot;config.window_size=60&quot; \\-d &quot;config.sync_rate=10&quot; 企业还增加了对 Redis Sentinel 的支持，这使得 Redis 高可用性和更强的容错能力。你可以阅读更多的企业速率限制插件文档。","tags":["限流算法"],"categories":["系统设计"]},{"title":"线程池详解","path":"/concurrent/thread_pool/","content":"什么是线程池线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。 线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。 这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。 使用线程池可以带来一系列好处： 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。 提高响应速度：任务到达时，无需等待线程创建即可立即执行。 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。 线程池解决了什么问题线程池解决的核心是：资源管理问题 在并发环境下，系统无法确定在任意时刻，有多少任务需要执行，有多少资源需要投入。这种不确定性将带来以下若干问题： 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。 对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。 系统无法合理管理内部的资源分布，会降低系统的稳定性。 为解决资源分配这个问题，线程池采用了“池化”（Pooling）思想。池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。“池化”思想不仅仅能应用在计算机领域，在金融、设备、人员管理、工作管理等领域也有相关的应用。 在计算机领域中的表现为：统一管理IT资源，包括服务器、存储、和网络资源等等。通过共享资源，使用户在低投入中获益。除去线程池，还有其他比较典型的几种使用策略包括： 1. 内存池(Memory Pooling)：预先申请内存，提升申请内存速度，减少内存碎片。 2. 连接池(Connection Pooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。 3. 实例池(Object Pooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。 使用线程池的风险虽然线程池是构建多线程应用程序的强大机制，但使用它并不是没有风险的。用线程池构建的应用程序容易遭受任何其它多线程应用程序容易遭受的所有并发风险，诸如同步错误和死锁，它还容易遭受特定于线程池的少数其它风险，诸如与池有关的死锁、资源不足和线程泄漏。 死锁任何多线程应用程序都有死锁风险。当一组进程或线程中的每一个都在等待一个只有该组中另一个进程才能引起的事件时，我们就说这组进程或线程 死锁 了。 死锁的最简单情形是：线程 A 持有对象 X 的独占锁，并且在等待对象 Y 的锁，而线程 B 持有对象 Y 的独占锁，却在等待对象 X 的锁。除非有某种方法来打破对锁的等待（Java 锁定不支持这种方法），否则死锁的线程将永远等下去。 虽然任何多线程程序中都有死锁的风险，但线程池却引入了另一种死锁可能，在那种情况下，所有池线程都在执行已阻塞的等待队列中另一任务的执行结果的任务，但这一任务却因为没有未被占用的线程而不能运行。当线程池被用来实现涉及许多交互对象的模拟，被模拟的对象可以相互发送查询，这些查询接下来作为排队的任务执行，查询对象又同步等待着响应时，会发生这种情况。 资源不足线程池的一个优点在于：相对于其它替代调度机制而言，它们通常执行得很好。但只有恰当地调整了线程池大小时才是这样的。线程消耗包括内存和其它系统资源在内的大量资源。除了 Thread 对象所需的内存之外，每个线程都需要两个可能很大的执行调用堆栈。除此以外，JVM 可能会为每个 Java 线程创建一个本机线程，这些本机线程将消耗额外的系统资源。最后，虽然线程之间切换的调度开销很小，但如果有很多线程，环境切换也可能严重地影响程序的性能。 如果线程池太大，那么被那些线程消耗的资源可能严重地影响系统性能。在线程之间进行切换将会浪费时间，而且使用超出比您实际需要的线程可能会引起资源匮乏问题，因为池线程正在消耗一些资源，而这些资源可能会被其它任务更有效地利用。除了线程自身所使用的资源以外，服务请求时所做的工作可能需要其它资源，例如 JDBC 连接、套接字或文件。这些也都是有限资源，有太多的并发请求也可能引起失效，例如不能分配 JDBC 连接。 并发错误线程池和其它排队机制依靠使用 wait() 和 notify() 方法，这两个方法都难于使用。如果编码不正确，那么可能丢失通知，导致线程保持空闲状态，尽管队列中有工作要处理。使用这些方法时，必须格外小心；即便是专家也可能在它们上面出错。而最好使用现有的、已经知道能工作的实现，例如在下面的 无须编写您自己的池中讨论的 util.concurrent 包。 线程泄漏各种类型的线程池中一个严重的风险是线程泄漏，当从池中除去一个线程以执行一项任务，而在任务完成后该线程却没有返回池时，会发生这种情况。发生线程泄漏的一种情形出现在任务抛出一个 RuntimeException 或一个 Error 时。如果池类没有捕捉到它们，那么线程只会退出而线程池的大小将会永久减少一个。当这种情况发生的次数足够多时，线程池最终就为空，而且系统将停止，因为没有可用的线程来处理任务。 有些任务可能会永远等待某些资源或来自用户的输入，而这些资源又不能保证变得可用，用户可能也已经回家了，诸如此类的任务会永久停止，而这些停止的任务也会引起和线程泄漏同样的问题。如果某个线程被这样一个任务永久地消耗着，那么它实际上就被从池除去了。对于这样的任务，应该要么只给予它们自己的线程，要么只让它们等待有限的时间。 请求过载仅仅是请求就压垮了服务器，这种情况是可能的。在这种情形下，我们可能不想将每个到来的请求都排队到我们的工作队列，因为排在队列中等待执行的任务可能会消耗太多的系统资源并引起资源缺乏。在这种情形下决定如何做取决于您自己；在某些情况下，您可以简单地抛弃请求，依靠更高级别的协议稍后重试请求，您也可以用一个指出服务器暂时很忙的响应来拒绝请求。 如何创建线程池构造方法1234567891011121314151617181920212223242526272829303132333435363738public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)&#123;&#125; ExecutorsExecutor 框架的工具类 Executors 提供了几种默认的线程池。（方法内部实际上都是调用了ThreadPoolExecutor 的构造方法） FixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 《阿里巴巴 Java 开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 除了避免 OOM 的原因之外，不推荐使用 Executors 提供的两种快捷的线程池的原因还有： 实际使用中需要根据自己机器的性能、业务场景来手动配置线程池的参数比如核心线程数、使用的任务队列、饱和策略等等。 我们应该显示地给我们的线程池命名，这样有助于我们定位问题。 ThreadPoolExecutor 参数解析123456789101112131415161718192021222324 /** * 用给定的初始参数创建一个新的ThreadPoolExecutor。 */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 参数解析 corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 饱和策略如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 举个例子： Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。 核心设计 &amp; 实现以下分析基于 JDK 1.8 Java中的线程池核心实现类是ThreadPoolExecutor，首先来看一下ThreadPoolExecutor的UML类图，了解下ThreadPoolExecutor的继承关系。 ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。 ExecutorService接口增加了一些能力： 扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法； 提供了管控线程池的方法，比如停止线程池的运行。 AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 ThreadPoolExecutor是如何运行? 如何同时维护线程和执行任务的呢？其运行机制如下图所示： 线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转： 直接申请线程执行该任务； 缓冲到队列中等待线程执行； 拒绝该任务。 线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。 接下来，我们会按照以下三个部分去详细讲解线程池运行机制： 线程池如何维护自身状态。 线程池如何管理任务。 线程池如何管理线程。 生命周期管理线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示： 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); ctl这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。 用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。 通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。 关于内部封装的获取生命周期状态、获取线程池线程数量的计算方法如以下代码所示： 123456//计算当前运行状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; //计算当前线程数量private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;//通过状态和线程数生成ctl private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ThreadPoolExecutor的运行状态有5种，分别为： 其生命周期转换如下入所示： 任务管理任务调度 任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。 首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下： 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务。 如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。 如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。 如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 其执行流程如下图所示： 任务缓冲 任务缓冲模块是线程池能够管理任务的核心部分。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 下图中展示了线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素： 使用不同的队列可以实现不一样的任务存取策略。在这里，我们可以再介绍下阻塞队列的成员： 任务申请 由上文的任务分配部分可知，任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。 线程需要从任务缓存模块中不断地取任务执行，帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块之间的通信。这部分策略由getTask方法实现，其执行流程如下图所示： getTask这部分进行了多次判断，为的是控制线程的数量，使其符合线程池的状态。如果线程池现在不应该持有那么多线程，则会返回null值。工作线程Worker会不断接收新任务去执行，而当工作线程Worker接收不到任务的时候，就会开始被回收。 任务拒绝 任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。 拒绝策略是一个接口，其设计如下： 123public interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 用户可以通过实现这个接口去定制拒绝策略，也可以选择JDK提供的四种已有拒绝策略，其特点如下： 线程管理Worker线程 线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。我们来看一下它的部分代码： 1234private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; final Thread thread;//Worker持有的线程 Runnable firstTask;//初始化的任务，可以为null&#125; Worker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。 Worker执行任务的模型如下图所示： 线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。 Worker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。 lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 如果正在执行任务，则不应该中断线程。 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。 在线程回收过程中就使用到了这种特性，回收过程如下图所示： Worker线程增加 增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，其执行流程如下图所示： Worker线程回收 线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。 1234567try &#123; while (task != null || (task = getTask()) != null) &#123; //执行任务 &#125;&#125; finally &#123; processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己&#125; 线程回收的工作是在processWorkerExit方法完成的。 事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。 Worker线程执行任务 在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的执行过程如下： 1.while循环不断地通过getTask()方法获取任务。 2.getTask()方法从阻塞队列中取任务。 3.如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 4.执行任务。 5.如果getTask结果为null则跳出循环，执行processWorkerExit()方法，销毁线程。 执行流程如下图所示： 经典问题execute() 和 submit()的区别 execute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否。 submit() 方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 线程池的替代方案业务使用线程池是为了获取并发性，对于获取并发性，是否可以有什么其他的方案呢替代？ 如何确定线程池大小类比于实现世界中的人类通过合作做某件事情，我们可以肯定的一点是线程池大小设置过大或者过小都会有问题，合适的才是最好。 如果我们设置的线程池数量太小的话，如果同一时间有大量任务/请求需要处理，可能会导致大量的请求/任务在任务队列中排队等待执行，甚至会出现任务队列满了之后任务/请求无法处理的情况，或者大量任务堆积在任务队列导致 OOM。这样很明显是有问题的！ CPU 根本没有得到充分利用。 但是，如果我们设置线程数量太大，大量线程可能会同时在争取 CPU 资源，这样会导致大量的上下文切换，从而增加线程的执行时间，影响了整体执行效率。 经典回答 有一个简单并且适用面比较广的公式： CPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。 I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。 如何判断是 CPU 密集任务还是 IO 密集任务？ CPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。单凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。 惊艳回答 线程池参数动态化。 具体实现请参考：https://copyfuture.com/blogs-details/20201209214330534lcv0q96xiv8nvv9 线程池被创建后里面有线程吗？如何预热？线程池被创建后如果没有任务过来，里面是不会有线程的。如果需要预热的话可以调用下面的两个方法： 全部启动 prestartAllCoreThreads 仅启动一个 prestartCoreThread 核心线程数会被回收吗？核心线程数默认是不会被回收的，如果需要回收核心线程数，需要调用下面的方法： allowCoreThreadTimeOut（默认为false） ScheduledThreadPoolExecutorScheduledThreadPoolExecutor 主要用来在给定的延迟后运行任务，或者定期执行任务。 这个在实际项目中基本不会被用到，因为有其他方案选择比如quartz。 ScheduledThreadPoolExecutor 使用的任务队列 DelayQueue 封装了一个 PriorityQueue，PriorityQueue 会对队列中的任务进行排序，执行所需时间短的放在前面先被执行(ScheduledFutureTask 的 time 变量小的先执行)，如果执行所需时间相同则先提交的任务将被先执行(ScheduledFutureTask 的 squenceNumber 变量小的先执行)。 ScheduledThreadPoolExecutor 和 Timer 的比较： Timer 对系统时钟的变化敏感，ScheduledThreadPoolExecutor不是； Timer 只有一个执行线程，因此长时间运行的任务可以延迟其他任务。 ScheduledThreadPoolExecutor 可以配置任意数量的线程。 此外，如果你想（通过提供 ThreadFactory），你可以完全控制创建的线程; 在TimerTask 中抛出的运行时异常会杀死一个线程，从而导致 Timer 死机:-( …即计划任务将不再运行。ScheduledThreadExecutor 不仅捕获运行时异常，还允许您在需要时处理它们（通过重写 afterExecute 方法ThreadPoolExecutor）。抛出异常的任务将被取消，但其他任务将继续运行。 综上，在 JDK1.5 之后，你没有理由再使用 Timer 进行任务调度了。 备注： Quartz 是一个由 java 编写的任务调度库，由 OpenSymphony 组织开源出来。在实际项目开发中使用 Quartz 的还是居多，比较推荐使用 Quartz。因为 Quartz 理论上能够同时对上万个任务进行调度，拥有丰富的功能特性，包括任务调度、任务持久化、可集群化、插件等等。 ScheduledThreadPoolExecutor 的执行主要分为两大部分： 当调用 ScheduledThreadPoolExecutor 的 scheduleAtFixedRate() 方法或者 scheduleWithFixedDelay() 方法时，会向 ScheduledThreadPoolExecutor 的 DelayQueue 添加一个实现了 RunnableScheduledFuture 接口的 ScheduledFutureTask 。 线程池中的线程从 DelayQueue 中获取 ScheduledFutureTask，然后执行任务。 ScheduledThreadPoolExecutor 为了实现周期性的执行任务，对 ThreadPoolExecutor做了如下修改： 使用 DelayQueue 作为任务队列； 获取任务的方不同 执行周期任务后，增加了额外的处理 ScheduledThreadPoolExecutor 执行周期任务的步骤 线程 1 从 DelayQueue 中获取已到期的 ScheduledFutureTask（DelayQueue.take()）。到期任务是指 ScheduledFutureTask的 time 大于等于当前系统的时间； 线程 1 执行这个 ScheduledFutureTask； 线程 1 修改 ScheduledFutureTask 的 time 变量为下次将要被执行的时间； 线程 1 把这个修改 time 之后的 ScheduledFutureTask 放回 DelayQueue 中（DelayQueue.add())。","tags":["线程池","ThreadPool"],"categories":["并发","线程池"]},{"title":"Actor Model","path":"/concurrent/actor/","content":"Actors模型(Actor model)首先是由Carl Hewitt在1973定义， 由Erlang OTP (Open Telecom Platform) 推广，其消息传递更加符合面向对象的原始意图。 Actors属于并发组件模型 ，通过组件方式定义并发编程范式的高级阶段，避免使用者直接接触多线程并发或线程池等基础概念。 在 Actor 模型中，一切都是 actor，actor 通过消息传递的方式与外界通信。消息传递是异步的。每个actor都有一个邮箱（Mailbox），该邮箱接收并缓存其他actor发过来的消息，actor一次只能同步处理一个消息，处理消息过程中，除了可以接收消息，不能做任何其他操作。 使用 Actor 模型需要遵循以下几个基本原则： 所有计算都是在 actor 内执行的 actor 之间只能通过消息进行通信交流 为了响应消息，actor 可以进行如下操作 更改状态或行为 发消息给其他 actor 创建有限数量的子 actor 特性解读所有计算都在一个 actor 中进行 actor 是最基本的计算单元，在使用 Actor 模型构建系统时，一切都是actor。无论是计算斐波那契序列还是维护系统中用户的状态，都可以在一个或多个 actor 中进行。 Actor 模型中的 actor 不仅有状态，还有行为，和OOP有点像。不同的是OOP将对象（类实例）作为基本的计算单元。 Actor 模型中另一个对高并发应用有帮助的是隔离actor状态的思想。actor 的状态永远不会直接暴露在外面，也无法直接被其他 actor 查看或修改，除非通过消息机制间接地进行。这种机制同样适用于 actor 的行为。actor内部的方法同样也不会直接暴露给其他 actor 。事实上，在 actor 内部，状态和行为可以被视为相同的因素。 actor 之间只能通过消息进行通信 在 Actor 模型中，所有的通信都是基于消息机制进行的，这也是 actor 之间进行通信的方法。 每个 actor 在创建的时候都会获得一个地址，该地址是与该 actor 通信的入口。不能通过这个地址直接访问该 actor，但是可以通过这个地址发消息给它。 发送给 actor 的消息是不可变的数据。这些消息会被发送到目标 actor 提供的地址并被存在邮箱（Mailbox）中。Actor 模型提供了最多投递一次的消息机制，这意味着有可能发生投递失败的情况，如果想要保证每次都投递成功，需要使用其他工具来辅助。 akka 实现了最少投递一次的机制，更进一步提供了更加强大的顺序保证机制，可以确保正在通信的 actor 之间的消息都是按照顺序被送达的。也就是说，一个actor 发给另一个 actor多个消息的时候，可以确保消息被送达的顺序和发送顺序是一致的。 消息被投递到邮箱（Mailbox）之后，actor 可以接受并处理这些消息，但是每次只能处理一条消息。所以actor 可以很自由的修改自己的内部状态，而不用担心是否会有其他线程也在操作该状态。 actor 可以创建子 actor 在 actor 模型中，一切都是 actor ，而且 actor 之间只能通过消息机制进行通信，但是 actor 还需要知道其他 actor 的存在。 当 actor 接收到消息之后，可以进行的操作之一是创建有限数量的子 actor。之后父节点就会知道它的所有子节点的存在，并可以访问子节点的地址。 除了通过创建子节点来获取其他 actor 的方法，一个 actor 还可以把地址信息通过消息机制发送给其他 actor。这样父节点便可以把他知道的所有actor 的地址信息通知给子 actor。 actor 的这种层级结构意味着，除根节点外的所有节点都将拥有一个父节点，同时任何节点都可以拥有一个或多个子节点。这样从根节点开始遍历整棵树的actor集合被称为一个 actor 系统。 actor系统中的每个 actor 总是可以通过其他地址被唯一标识。地址命名不需要遵循任何特定的规范，只要地址唯一即可。 akka 使用层级结构的模式来命名，就像目录结构一样。或者可以使用随机生成的唯一键。 优势更加面向对象 Actor类似面向对象编程（OOP）中的对象，每个Actor实例封装了自己相关的状态，并且和其他Actor处于物理隔离状态。 举个游戏玩家的例子，每个玩家在Actor系统中是Player 这个Actor的一个实例，每个player都有自己的属性，比如Id，昵称，攻击力等，体现到代码级别其实和我们OO的代码并无多大区别，在系统内存级别也是出现了多个OO的实例 1234class PlayerActor &#123; public int Id &#123; get; set; &#125; public string Name &#123; get; set; &#125; &#125; 无锁 Actor 模型内部的状态由它自己维护，即它内部数据只能由它自己修改(通过消息传递来进行状态修改)，所以使用Actors模型进行并发编程可以很好地避免这些问题。 异步 每个Actor都有一个专用的MailBox来接收消息，这也是Actor实现异步的基础。当一个Actor实例向另外一个Actor发消息的时候，并非直接调用Actor的方法，而是把消息传递到对应的MailBox里，就好像邮递员，并不是把邮件直接送到收信人手里，而是放进每家的邮箱，这样邮递员就可以快速的进行下一项工作。所以在Actor系统里，Actor发送一条消息是非常快的。 这样的设计主要优势就是解耦了Actor，数万个Actor并发的运行，每个actor都以自己的步调运行，且发送消息，接收消息都不会被阻塞。 隔离 每个Actor的实例都维护着自己的状态，与其他Actor实例处于物理隔离状态，并非像 多线程+锁 模式那样基于共享数据。 天生分布式 每个Actor实例的位置透明，无论Actor地址是在本地还是在远程机器上对于代码来说都是一样的。每个Actor的实例非常小，最多几百字节，所以单机几十万的Actor的实例很轻松。由于位置透明性，所以Actor系统可以随意的横向扩展来应对并发，对于调用者来说，调用的Actor的位置就在本地，当然这也得益于Actor系统强大的路由系统。 容错 传统的编程方式都是在将来可能出现异常的地方去捕获异常来保证系统的稳定性，这就是所谓的防御式编程。但是防御式编程也有自己的缺点，类似于现实，防御的一方永远不能100%的防御住所有将来可能出现代码缺陷的地方。比如在java代码中很多地方充斥着判断变量是否为nil，这些就属于防御式编码最典型的案例。 但是Actor模型的程序并不进行防御式编程，而是遵循“任其崩溃”的哲学，让Actor的管理者们来处理这些崩溃问题。比如一个Actor崩溃之后，管理者可以选择创建新的实例或者记录日志。每个Actor的崩溃或者异常信息都可以反馈到管理者那里，这就保证了Actor系统在管理每个Actor实例的灵活性。 劣势由于同一类型的Actor对象是分散在多个宿主之中，所以取多个Actor的集合是个软肋。比如在电商系统中，商品作为一类Actor，查询一个商品的列表在多数情况下经过以下过程：首先根据查询条件筛选出一系列商品id，根据商品id分别取商品Actor列表（很可能会产生一个商品搜索的服务，无论是用es或者其他搜索引擎）。如果量非常大的话，有产生网络风暴的危险（虽然几率非常小）。在实时性要求不是太高的情况下，其实也可以独立出来商品Actor的列表，利用MQ接收商品信息修改的信号来处理数据一致性的问题。 在很多情况下基于Actor模型的分布式系统，缓存很有可能是进程内缓存，也就是说每个Actor其实都在进程内保存了自己的状态信息，业内通常把这种服务成为有状态服务。但是每个Actor又有自己的生命周期，会产生问题吗？还是拿商品作为例子， 如果环境是非Actor并发模型，商品的缓存可以利用LRU策略来淘汰非活跃的商品缓存，来保证内存不会使用过量，如果是基于Actor模型的进程内缓存呢，每个actor其实就是缓存本身，就不那么容易利用LRU策略来保证内存使用量了，因为Actor的活跃状态对于你来说是未知的。 分布式事物问题，其实这是所有分布式模型都面临的问题，非由于Actor而存在。还是以商品Actor为例，添加一个商品的时候，商品Actor和统计商品的Actor（很多情况下确实被设计为两类Actor服务）需要保证事物的完整性，数据的一致性。在很多的情况下可以牺牲实时一致性用最终一致性来保证。 每个Actor的mailBox有可能会出现堆积或者满的情况，当这种情况发生，新消息的处理方式是被抛弃还是等待呢，所以当设计一个Actor系统的时候mailBox的设计需要注意。 升华一下 通过以上介绍，既然Actor对于位置是透明的，任何Actor对于其他Actor就好像在本地一样。基于这个特性我们可以做很多事情了，以前传统的分布式系统，A服务器如果想和B服务器通信，要么RPC的调用（http调用不太常用），要么通过MQ系统。但是在Actor系统中，服务器之间的通信都变的很优雅了，虽然本质上也属于RPC调用，但是对于编码者来说就好像在调用本地函数一样。其实现在比较时兴的是Streaming方式。 由于Actor系统的执行模型是单线程，并且异步，所以凡是有资源竞争的类似功能都非常适合Actor模型，比如秒杀活动。 基于以上的介绍，Actor模型在设计层面天生就支持了负载均衡，而且对于水平扩容支持的非常好。当然Actor的分布式系统也是需要服务注册中心的。 虽然Actor是单线程执行模型，并不意味着每个Actor都需要占用一个线程，其实Actor上执行的任务就像Golang的goroutine一样，完全可以是一个轻量级的东西，而且一个宿主上所有的Actor可以共享一个线程池，这就保证了在使用最少线程资源的情况下，最大量化业务代码。","tags":["Actor 模型","并发模型"],"categories":["并发"]},{"title":"Token、Cookie、Session傻傻分不清楚？","path":"/network/token_cookie_session/","content":"Cookiecookie 是一个非常具体的东西，指的就是浏览器里面能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。 cookie由服务器生成，发送给浏览器，浏览器把cookie以 kv 形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。 由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的cookie数量是有限的。 Sessionsession 从字面上讲，就是会话。这个就类似于你和一个人交谈，你怎么知道当前和你交谈的是张三而不是李四呢？对方肯定有某种特征（长相等）表明他就是张三。 session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识”，服务器就知道这个请求来自于谁了。至于客户端怎么保存这个“身份标识”，可以有很多种方式，对于浏览器客户端，大家都默认采用 cookie 的方式。 服务器使用session把用户的信息临时保存在了服务器上，用户离开网站后session会被销毁。这种用户信息存储方式相对cookie来说更安全，可是session有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。 TokenToken的引入：Token是在客户端频繁向服务端请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示，在这样的背景下，Token便应运而生。 Token的定义：Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。 最简单的token组成:uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign(签名，由token的前几位+盐以哈希算法压缩成一定长的十六进制字符串，可以防止恶意第三方拼接token请求服务器)。 Token的目的：Token的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。 区别cookie 和 session 的区别 cookie数据存放在客户端上，session数据放在服务器上。 cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗, 考虑到安全应当使用session。 session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能。考虑到减轻服务器性能方面，应当使用COOKIE。 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 session 和 token 的区别Session 是一种HTTP存储机制，目的是为无状态的HTTP提供的持久机制。所谓Session 认证只是简单的把User 信息存储到Session 里。Session只提供一种简单的认证，只要有 Session ID，即认为有此 User的全部权利。是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方App。 Token ，如果指的是OAuth Token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对App 。其目的是让 某App有权利访问 某用户 的信息。这里的 Token是唯一的。不可以转移到其它 App上，也不可以转到其它 用户 上。 所以简单来说，如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token 。如果永远只是自己的网站，自己的 App，用什么就无所谓了。 只要关闭浏览器 ，session就消失了？对session来说，除非程序通知服务器删除一个session，否则服务器会一直保留，程序一般都是在用户做log off的时候发个指令去删除session。 然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分session机制都使用会话cookie来保存session id，而关闭浏览器后这个session id就消失了，再次连接服务器时也就无法找到原来的session。如果服务器设置的cookie被保存在硬盘上，或者使用某种手段改写浏览器发出的HTTP请求头，把原来的session id发送给服务器，则再次打开浏览器仍然能够打开原来的session. 恰恰是由于关闭浏览器不会导致session被删除，迫使服务器为session设置了一个失效时间，当距离客户端上一次使用session的时间超过这个失效时间时，服务器就可以以为客户端已经停止了活动，才会把session删除以节省存储空间。","tags":["网络"],"categories":["网络"]},{"title":"从输入 URL 到页面展示到底发生了什么？","path":"/network/what_happen_after_enter_url/","content":"首先打开 Google Chrome ，然后在 URL 地址栏中输入了 maps.google.com 然后 …… 查找DNSDNS(Domain Name System) 是一个分布式的数据库，它用于维护网址 URL 到其 IP 地址的映射关系。在互联网中，IP 地址是计算机所能够理解的一种地址，而 DNS 的这种别名地址是我们人类能够理解和记忆的地址，DNS 就负责把人类记忆的地址映射成计算机能够理解的地址，每个 URL 都有唯一的 IP 地址进行对应。 举个例子，google 的官网是 www.google.com ，而 google 的 ip 地址是 216.58.200.228 ，这两个地址你在 URL 上输入哪个都能访问，但是 IP 地址不好记忆，而 google.com 简单明了。 浏览器在这个阶段会检查四个地方是否存在缓存。 浏览器缓存，这个缓存就是 DNS 记录。 浏览器会为你访问过的网站在固定期限内维护 DNS 记录。因此，它是第一个运行 DNS 查询的地方。 浏览器首先会检查这个网址在浏览器中是否有一条对应的 DNS 记录，用来找到目标网址的 IP 地址。 Windows 中可以使用 chrome://net-internals/#dns 找到对应的 IP 地址Mac 中可以使用 nslookup 命令来查找 操作系统缓存。 如果 DNS 记录不在浏览器缓存中，那么浏览器将对操作系统发起系统调用，Windows 下就是 getHostName。 在 Linux 和大部分 UNIX 系统上，除非安装了 nscd，否则操作系统可能没有 DNS 缓存。nscd 是 Linux 系统上的一种名称服务缓存程序。 路由器缓存 如果 DNS 记录不在自己电脑上的话，浏览器就会和与之相连的路由器共同维护 DNS 记录。 ISP 缓存 如果与之相连的路由器也没有 DNS 记录的话，浏览器就会检查 ISP 中是否有缓存。ISP 缓存就是你本地通信服务商的缓存，因为 ISP 维护着自己的 DNS 服务器，它缓存 DNS 记录的本质也是为了降低请求时间，达到快速响应的效果。一旦你访问过某些网站，你的 ISP 可能就会缓存这些页面，以便下次快速访问。 所以，上面涉及到 DNS 缓存的查询过程如下。 如果上面四个步骤中都不存在 DNS 记录，那么就表示不存在 DNS 缓存，这个时候就需要发起 DNS 查询，以查找目标网址（本示例中是 maps.google.com）的 IP 地址。 发起 DNS 查询如上所述，如果想要使我的计算机和 maps.google.com 建立连接并进行通信的话，我需要知道 maps.google.com 的 IP 地址，由于 DNS 的设计原因，本地 DNS 可能无法给我提供正确的 IP 地址，那么它就需要在互联网上搜索多个 DNS 服务器，来找到网站的正确 IP 地址。 这里有个疑问，为什么我需要搜索多个 DNS 服务器的来找到网站的 IP 地址呢？一台服务器不行吗？ 因为 DNS 是分布式域名服务器，每台服务器只维护一部分 IP 地址到网络地址的映射，没有任何一台服务器能够维持全部的映射关系。 在 DNS 的早期设计中只有一台 DNS 服务器。这台服务器会包含所有的 DNS 映射。这是一种集中式的设计，这种设计并不适用于当今的互联网，因为互联网有着数量巨大并且持续增长的主机，这种集中式的设计会存在以下几个问题 单点故障(a single point of failure)，如果 DNS 服务器崩溃，那么整个网络随之瘫痪。 通信容量(traaffic volume)，单个 DNS 服务器不得不处理所有的 DNS 查询，这种查询级别可能是上百万上千万级，一台服务器很难满足。 远距离集中式数据库(distant centralized database)，单个 DNS 服务器不可能 邻近 所有的用户，假设在美国的 DNS 服务器不可能临近让澳大利亚的查询使用，其中查询请求势必会经过低速和拥堵的链路，造成严重的时延。 维护(maintenance)，维护成本巨大，而且还需要频繁更新。 所以在当今网络情况下 DNS 不可能集中式设计，因为它完全没有可扩展能力，所以采用分布式设计，这种设计的特点如下 分布式、层次数据库 首先分布式设计首先解决的问题就是 DNS 服务器的扩展性问题，因此 DNS 使用了大量的 DNS 服务器，它们的组织模式一般是层次方式，并且分布在全世界范围内。没有一台 DNS 服务器能够拥有因特网上所有主机的映射。相反，这些映射分布在所有的 DNS 服务器上。 大致来说有三种 DNS 服务器： 根 DNS 服务器、 顶级域(Top-Level Domain, TLD) DNS 服务器 权威 DNS 服务器 。 这些服务器的层次模型如下图所示 根 DNS 服务器 ，有 400 多个根域名服务器遍及全世界，这些根域名服务器由 13 个不同的组织管理。根域名服务器的清单和组织机构可以在 https://root-servers.org/ 中找到，根域名服务器提供 TLD 服务器的 IP 地址。 顶级域 DNS 服务器，对于每个顶级域名比如 com、org、net、edu 和 gov 和所有的国家级域名 uk、fr、ca 和 jp 都有 TLD 服务器或服务器集群。所有的顶级域列表参见 https://tld-list.com/ 。TDL 服务器提供了权威 DNS 服务器的 IP 地址。 权威 DNS 服务器，在因特网上具有公共可访问的主机，如 Web 服务器和邮件服务器，这些主机的组织机构必须提供可供访问的 DNS 记录，这些记录将这些主机的名字映射为 IP 地址。一个组织机构的权威 DNS 服务器收藏了这些 DNS 记录。 在了解了 DNS 服务器的设计理念之后，我们回到 DNS 查找的步骤上来，DNS 的查询方式主要分为三种 通过组合使用这些查询，优化的 DNS 解析过程可缩短传输距离。在理想情况下，可以使用缓存的记录数据，从而使 DNS 域名服务器能够直接使用非递归查询。 递归查询：一般发生在 Client 请求 DNS Server。Client 发出一个域名解析的请求，DNS Server 必须返回对应的 IP 地址，或者返回找不到的错误。 迭代查询：一般发生在 DNS Server 之间，当 Client 发出域名解析的请求后，DNS Server 需要给予最佳答案，这个最佳答案可能是”距离最近”的顶级域名服务器，也能是权威域名服务器。无论如何，Client 需要对返回结果再次发起请求，知道获得最终结果。 非递归查询：一般发生在 Client 和 DNS Server 之间，指的是，请求的 DNS Server 已经知道答案，直接返回。这里可能有两种情况，一种是 DNS Server 本机缓存了对应的 IP，或者是缓存了对应的域名的权威服务器。第二种情况只需要再发一次请求，即可拿到结果返回。 详情可参考：https://juejin.cn/post/6844903900982558734#heading-9 上面负责开始 DNS 查找的介质就是 DNS 解析器，它一般是 ISP 维护的 DNS 服务器，它的主要职责就是通过向网络中其他 DNS 服务器询问正确的 IP 地址。 所以对于 maps.google.com 这个域名来说，如果 ISP 维护的服务器没有 DNS 缓存记录，它就会向 DNS 根服务器地址发起查询，根名称服务器会将其重定向到 .com 顶级域名服务器。 .com 顶级域名服务器会将其重定向到google.com 权威服务器。google.com 名称服务器将在其 DNS 记录中找到 maps.google.com 匹配的 IP 地址，并将其返回给您的 DNS 解析器，然后将其发送回你的浏览器。 ARP 请求ARP 协议的全称是 Address Resolution Protocol(地址解析协议)，它是一个通过用于实现从 IP 地址到 MAC 地址的映射，即询问目标 IP 对应的 MAC 地址 的一种协议。 ARP 就是一种解决地址问题的协议，它以 IP 地址为线索，定位下一个应该接收数据分包的主机 MAC 地址。如果目标主机不在同一个链路上，那么会查找下一跳路由器的 MAC 地址。 关于为什么有了 IP 地址，还要有 MAC 地址概述可以参看知乎这个回答 https://www.zhihu.com/question/21546408 如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP 查询 如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询 ARP 的大致工作流程如下 假设 A 和 B 位于同一链路，不需要经过路由器的转换，主机 A 向主机 B 发送一个 IP 分组，主机 A 的地址是 192.168.1.2 ，主机 B 的地址是 192.168.1.3，它们都不知道对方的 MAC 地址是啥，主机 C 和 主机 D 是同一链路的其他主机。 主机 A 想要获取主机 B 的 MAC 地址，通过主机 A 会通过广播 的方式向以太网上的所有主机发送一个 ARP 请求包，这个 ARP 请求包中包含了主机 A 想要知道的主机 B 的 IP 地址的 MAC 地址。 主机 A 发送的 ARP 请求包会被同一链路上的所有主机/路由器接收并进行解析。每个主机/路由器都会检查 ARP 请求包中的信息，如果 ARP 请求包中的目标 IP 地址 和自己的相同，就会将自己主机的 MAC 地址写入响应包返回主机 A 由此，可以通过 ARP 从 IP 地址获取 MAC 地址，实现同一链路内的通信。 ARP 维护每个主机和路由器上的 ARP 缓存(或表)。这个缓存维护着每个 IP 到 MAC 地址的映射关系。通过把第一次 ARP 获取到的 MAC 地址作为 IP 对 MAC 的映射关系到一个 ARP 缓存表中，下一次再向这个地址发送数据报时就不再需要重新发送 ARP 请求了，而是直接使用这个缓存表中的 MAC 地址进行数据报的发送。每发送一次 ARP 请求，缓存表中对应的映射关系都会被清除。 通过 ARP 缓存，降低了网络流量的使用，在一定程度上防止了 ARP 的大量广播。 一般来说，发送过一次 ARP 请求后，再次发送相同请求的几率比较大，因此使用 ARP 缓存能够减少 ARP 包的发送，除此之外，不仅仅 ARP 请求的发送方能够缓存 ARP 接收方的 MAC 地址，接收方也能够缓存 ARP 请求方的 IP 和 MAC 地址，如下所示 不过，MAC 地址的缓存有一定期限，超过这个期限后，缓存的内容会被清除。 所以，浏览器会首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC。 如果缓存没有命中： 查看路由表，看看目标 IP 地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。 查询选择的网络接口的 MAC 地址 我们发送一个数据链路层的 ARP 请求： 封装 TCP 数据包浏览器得到目标服务器的 IP 地址后，根据 URL 中的端口可以知道端口号 （http 协议默认端口号是 80， https 默认端口号是 443），会准备 TCP 数据包。数据包的封装会经过下面的层层处理，数据到达目标主机后，目标主机会解析数据包，完整的请求和解析过程如下。 在经过上述 DNS 和 ARP 查找流程后，浏览器就会收到一个目标服务器的 IP 和 MAC地址，然后浏览器将会和目标服务器建立连接来传输信息。这里可以使用很多种 Internet 协议，但是 HTTP 协议建立连接所使用的运输层协议是 TCP 协议。所以这一步骤是浏览器与目标服务器建立 TCP 连接的过程。 TCP 的连接建立需要经过 TCP/IP 的三次握手，三次握手的过程其实就是浏览器和服务器交换 SYN 同步和 ACK 确认消息的过程。 假设图中左端是客户端主机，右端是服务端主机，一开始，两端都处于CLOSED（关闭）状态。 浏览器发送 HTTP 请求到 web 服务器一旦 TCP 连接建立完成后，就开始直接传输数据办正事了！此时浏览器会发送 GET 请求，要求目标服务器提供 maps.google.com 的网页，如果你填写的是表单，则发起的是 POST 请求，在 HTTP 中，GET 请求和 POST 请求是最常见的两种请求，基本上占据了所有 HTTP 请求的九成以上。 除了请求类型外，HTTP 请求还包含很多很多信息，最常见的有 Host、Connection 、User-agent、Accept-language 等 服务器处理请求并发回一个响应这个服务器包含一个 Web 服务器，也就是 Apache 服务器，服务器会从浏览器接收请求并将其传递给请求处理程序并生成响应。 服务器发送回一个 HTTP 响应服务器响应包含你请求的网页以及状态代码，压缩类型（Content-Encoding），如何缓存页面（Cache-Control），要设置的 cookie，隐私信息等。 浏览器显示 HTML 的相关内容浏览器会分阶段显示 HTML 内容。 首先，它将渲染裸露的 HTML 骨架。 然后它将检查 HTML 标记并发送 GET 请求以获取网页上的其他元素，例如图像，CSS 样式表，JavaScript 文件等。这些静态文件由浏览器缓存，因此你再次访问该页面时，不用重新再请求一次。最后，您会看到 maps.google.com 显示的内容出现在你的浏览器中。","tags":["网络"],"categories":["网络"]},{"title":"动态代理","path":"/java/dynamic-proxy/","content":"代理模式代理模式是一种比较好理解的设计模式。 简单来说就是：我们使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的能力，实现功能的增强。 生活中的代购、租房中介、售票黄牛、婚介、经纪人、快递、事务代理、非侵入式日志监听等，都是代理 模式的实际体现。 使用代理模式主要有两个目的： 一是保护目标对象 二是增强目标对象功能（比如说在目标对象的某个方法执行前后增加一些自定义的操作） 代理模式一般包含三种角色： 抽象角色（Subject）：抽象角色的主要职责是声明真实类与代理类的共同接口方法，该类可以是接口也可以是抽象类 真实角色（RealSubject）：该角色也被称为被代理类，该类定义了代理所表示的真实对象，是负责执行系统真正的逻辑业务对象 代理角色（Proxy）：也被称为代理类，其内部持有 Real Subject 的引用，因此具备完全的对 RealSubject 的代理权。客户端调用代理对象的方法，同时也调用被代理对象的方法，但是会在代理对象前后增加一些处理代码。 一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知。代理模式属于结构型模式，分为静态代理和动态代理。 静态代理静态代理是代理类在编译期间就创建好的，不是编译器生成的代理类，而是手动创建的类。在编译时就已经将接口，被代理类，代理类等确定下来。软件设计中所指的代理一般是指静态代理，也就是在代码中显式指定的代理。 下面我们通过一个简单的案例，来了解下静态代理。 Cat.java123456789/** * 静态代理类接口, 委托类和代理类都需要实现的接口规范。 * 定义了一个猫科动物的两个行为接口，吃东西，奔跑。 * 作为代理类 和委托类之间的约束接口 */public interface Cat &#123; public String eatFood(String foodName); public boolean running();&#125; Lion.java1234567891011121314151617181920212223242526272829303132/** * 狮子 实现了猫科动物接口Cat， 并实现了具体的行为。作为委托类实现 */public class Lion implements Cat &#123; private String name; private int runningSpeed; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getRunningSpeed() &#123; return runningSpeed; &#125; public void setRunningSpeed(int runningSpeed) &#123; this.runningSpeed = runningSpeed; &#125; public Lion() &#123; &#125; @Override public String eatFood(String foodName) &#123; String eat = this.name + &quot; Lion eat food. foodName = &quot; + foodName; System.out.println(eat); return eat; &#125; @Override public boolean running() &#123; System.out.println(this.name + &quot; Lion is running . Speed :&quot; + this.runningSpeed); return false; &#125;&#125; 代理类角色(FeederProxy) FeederProxy.java12345678910111213141516171819202122232425262728/** * 饲养员 实现Cat接口，作为静态代理类实现。代理狮子的行为。 * 代理类中可以新增一些其他行为，在实践中主要做的是参数校验的功能。 */public class FeederProxy implements Cat &#123; private Cat cat; public FeederProxy()&#123;&#125; public FeederProxy(Cat cat) &#123; if (cat instanceof Cat) &#123; this.cat = cat; &#125; &#125; public void setCat(Cat cat) &#123; if (cat instanceof Cat) &#123; this.cat = cat; &#125; &#125; @Override public String eatFood(String foodName) &#123; System.out.println(&quot;proxy Lion exec eatFood &quot;); return cat.eatFood(foodName); &#125; @Override public boolean running() &#123; System.out.println(&quot;proxy Lion exec running.&quot;); return cat.running(); &#125;&#125; 静态代理类测试 staticProxyTest.java12345678910111213141516/** * 静态代理类测试 */public class staticProxyTest &#123; public static void main(String[] args) &#123; Lion lion = new Lion(); lion.setName(&quot;狮子 小王&quot;); lion.setRunningSpeed(100); /** * new 静态代理类，静态代理类在编译前已经创建好了，和动态代理的最大区别点 */ Cat proxy = new FeederProxy(lion); System.out.println(Thread.currentThread().getName()+&quot; -- &quot; + proxy.eatFood(&quot;水牛&quot;)); proxy.running(); &#125;&#125; 静态代理很好的诠释了代理设计模式，代理模式最主要的就是有一个公共接口（Cat），一个委托类（Lion），一个代理类（FeederProxy）,代理类持有委托类的实例，代为执行具体类实例方法。 代理模式就是在访问实际对象时引入一定程度的间接性，因为这种间接性，可以附加多种用途。这里的间接性就是指客户端不直接调用实际对象的方法，客户端依赖公共接口并使用代理类。 那么我们在代理过程中就可以加上一些其他用途。 就这个例子来说在 eatFood 方法调用中，代理类在调用具体实现类之前添加System.out.println(“proxy Lion exec eatFood “);语句 就是添加间接性带来的收益。代理类存在的意义是为了增加一些公共的逻辑代码。 静态代理的缺陷 代理类和委托类实现了相同的接口，代理类通过委托类实现了相同的方法。这样就出现了大量的代码重复。如果接口增加一个方法，除了所有实现类需要实现这个方法外，所有代理类也需要实现此方法。增加了代码维护的复杂度。 代理对象只服务于一种类型的对象，如果要服务多类型的对象。势必要为每一种对象都进行代理，静态代理在程序规模稍大时就无法胜任了。 静态代理一个代理只能代理一种类型，而且是在编译器就已经确定被代理的对象。 动态代理jdk动态代理模式是利用java中的反射技术，在运行时动态创建代理类。 JDK 动态代理基于 JDK 的动态代理涉及到两个核心的类：Proxy类 和 InvocationHandler接口 JDK动态代理的写法比较固定，需要先定义一个接口和接口的实现类，然后再定义一个实现了InvocationHandler接口的实现类。最终调用Proxy类的newInstance()方法即可。示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 先定义一个接口：UserService，接口中有两个方法public interface UserService &#123; int insert(); String query();&#125;// 再定义一个UserService接口的实现类：UserServiceImplpublic class UserServiceImpl implements UserService&#123; @Override public int insert() &#123; System.out.println(&quot;insert&quot;); return 0; &#125; @Override public String query() &#123; System.out.println(&quot;query&quot;); return null; &#125;&#125;// 再定义一个InvocationHandler接口的实现类：UserServiceInvocationHandler。在自定义的InvocationHandler中，定义了一个属性：target，定义这个属性的目的是为了在InvocationHandler中持有对目标对象的引用，target属性的初始化是在构造器中进行初始化的。public class UserServiceInvocationHandler implements InvocationHandler &#123; // 持有目标对象 private Object target; public UserServiceInvocationHandler(Object target)&#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;invocation handler&quot;); // 通过反射调用目标对象的方法 return method.invoke(target,args); &#125;&#125;// 通过Proxy.newProxyInstance()方法创建代理对象public class MainApplication &#123; public static void main(String[] args) &#123; // 指明一个类加载器，要操作class文件，怎么少得了类加载器呢 ClassLoader classLoader = MainApplication.class.getClassLoader(); // 为代理对象指定要是实现哪些接口，这里我们要为UserServiceImpl这个目标对象创建动态代理，所以需要为代理对象指定实现UserService接口 Class[] classes = new Class[]&#123;UserService.class&#125;; // 初始化一个InvocationHandler，并初始化InvocationHandler中的目标对象 InvocationHandler invocationHandler = new UserServiceInvocationHandler(new UserServiceImpl()); // 创建动态代理 UserService userService = (UserService) Proxy.newProxyInstance(classLoader, classes, invocationHandler); // 执行代理对象的方法，通过观察控制台的结果，判断我们是否对目标对象(UserServiceImpl)的方法进行了增强 userService.insert(); &#125;&#125;// 控制台打印结果如下，从打印结果来看，已经完成了对目标对象UserServiceImpl的代理（增强）。Output:invocation handlerinsert jdk实现动态代理可以分为以下几个步骤： 先检查委托类是否实现了相应接口，保证被访问方法在接口中也要有定义 创建一个实现InvocationHandler接口的类 在类中定义一个被代理对象的成员属性，为了扩展方便可以直接使用Object类，也可以根据需求定义相应的接口 在invoke方法中实现对委托对象的调用，根据需求对方法进行增强 使用Proxy.newProxyInstance(…)方法创建代理对象，并提供要给获取代理对象的方法 下面我们通过一些手段，来看下jdk动态代理生成的代理类长什么样子。 手段一： 自定义的一个小工具类将动态生成的代理类保存到本地 12345678910111213141516171819202122232425262728/** * 将生成的代理类保存为.class文件的工具类 */public class ProxyUtils &#123; /** * 将代理类保存到指定路径 * * @param path 保存到的路径 * @param proxyClassName 代理类的Class名称 * @param interfaces 代理类接口 * @return */ public static boolean saveProxyClass(String path, String proxyClassName, Class[] interfaces)&#123; if (proxyClassName == null || path == null) &#123; return false; &#125; // 获取文件字节码，然后输出到目标文件中 byte[] classFile = ProxyGenerator.generateProxyClass(proxyClassName, interfaces); try (FileOutputStream out = new FileOutputStream(path)) &#123; out.write(classFile); out.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); return false; &#125; return true; &#125;&#125; 手段二： 在代码中添加一行代码：System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;)，就能实现将程序运行过程中产生的动态代理对象的class文件写入到磁盘。如下示例： 运行程序，最终发现在项目的根目录下出现了一个包：com.sun.proxy。包下有一个文件$Proxy0.class。在idea打开，发现就是所产生代理类的源代码。 12345678910111213141516public class MainApplication &#123; public static void main(String[] args) &#123; // 让代理对象的class文件写入到磁盘 System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); // 指明一个类加载器，要操作class文件，怎么少得了类加载器呢 ClassLoader classLoader = MainApplication.class.getClassLoader(); // 为代理对象指定要是实现哪些接口，这里我们要为UserServiceImpl这个目标对象创建动态代理，所以需要为代理对象指定实现UserService接口 Class[] classes = new Class[]&#123;UserService.class&#125;; // 初始化一个InvocationHandler，并初始化InvocationHandler中的目标对象 InvocationHandler invocationHandler = new UserServiceInvocationHandler(new UserServiceImpl()); // 创建动态代理 UserService userService = (UserService) Proxy.newProxyInstance(classLoader, classes, invocationHandler); // 执行代理对象的方法，通过观察控制台的结果，判断我们是否对目标对象(UserServiceImpl)的方法进行了增强 userService.insert(); &#125;&#125; 通过上面两种方法获取到代理对象的源代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.sun.proxy;import com.tiantang.study.UserService;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements UserService &#123; private static Method m1; private static Method m3; private static Method m4; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int insert() throws &#123; try &#123; return (Integer)super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String query() throws &#123; try &#123; return (String)super.h.invoke(this, m4, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m3 = Class.forName(&quot;com.tiantang.study.UserService&quot;).getMethod(&quot;insert&quot;); m4 = Class.forName(&quot;com.tiantang.study.UserService&quot;).getMethod(&quot;query&quot;); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 通过源码我们发现，$Proxy0类继承了Proxy类，同时实现了UserService接口。到这里，我们的问题一就能解释了，为什么JDK的动态代理只能基于接口实现，不能基于继承来实现？ 因为Java中不支持多继承，而JDK的动态代理在创建代理对象时，默认让代理对象继承了Proxy类，所以JDK只能通过接口去实现动态代理。 $Proxy0实现了UserService接口，所以重写了接口中的两个方法（$Proxy0同时还重写了Object类中的几个方法）。所以当我们调用query()方法时，先是调用到$Proxy0.query()方法，在这个方法中，直接调用了super.h.invoke()方法，父类是Proxy，父类中的h就是我们定义的InvocationHandler，所以这儿会调用到UserServiceInvocationHandler.invoke()方法。因此当我们通过代理对象去执行目标对象的方法时，会先经过InvocationHandler的invoke()方法，然后在通过反射method.invoke()去调用目标对象的方法，因此每次都会先打印invocation handler这句话。 CGLIB 动态代理cglib动态代理和jdk动态代理类似，也是采用操作字节码机制，在运行时生成代理类。cglib 动态代理采取的是创建目标类的子类的方式，因为是子类化，我们可以达到近似使用被调用者本身的效果。 字节码处理机制-指得是ASM来转换字节码并生成新的类 注：spring中有完整的cglib相关的依赖，所以以下代码基于spring官方下载的demo中直接进行编写的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 1. 订单服务-委托类，不需要再实现接口 **/public class OrderService &#123; /** * 保存订单接口 */ public void saveOrder(String orderInfo) throws InterruptedException &#123; // 随机休眠，模拟订单保存需要的时间 Thread.sleep(System.currentTimeMillis() &amp; 100); System.out.println(&quot;订单：&quot; + orderInfo + &quot; 保存成功&quot;); &#125;&#125;/** * cglib动态代理工厂 * * @author cruder * @date 2019-11-23 18:36 **/public class ProxyFactory implements MethodInterceptor &#123; /** * 委托对象， 即被代理对象 */ private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; /** * 返回一个代理对象 * @return */ public Object getProxyInstance()&#123; // 1. 创建一个工具类 Enhancer enhancer = new Enhancer(); // 2. 设置父类 enhancer.setSuperclass(target.getClass()); // 3. 设置回调函数 enhancer.setCallback(this); // 4.创建子类对象，即代理对象 return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; long start = System.currentTimeMillis(); Object result = method.invoke(target, args); System.out.println(&quot;cglib代理：保存订单用时: &quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); return result; &#125;&#125;/** * 使用cglib代理类来保存订单 **/public class Client &#123; public static void main(String[] args) throws InterruptedException &#123; // 1. 创建委托对象 OrderService orderService = new OrderService(); // 2. 获取代理对象 OrderService orderServiceProxy = (OrderService) new ProxyFactory(orderService).getProxyInstance(); String saveFileName = &quot;CglibOrderServiceDynamicProxy.class&quot;; ProxyUtils.saveProxyClass(saveFileName, orderService.getClass().getSimpleName(), new Class[]&#123;IOrderService.class&#125;); orderServiceProxy.saveOrder(&quot; cruder 新买的花裤衩 &quot;); &#125;&#125; cglib动态代理实现步骤和jdk及其相似，可以分为以下几个步骤： 创建一个实现MethodInterceptor接口的类 在类中定义一个被代理对象的成员属性，为了扩展方便可以直接使用Object类，也可以根据需求定义相应的接口 在invoke方法中实现对委托对象的调用，根据需求对方法进行增强 使用Enhancer创建生成代理对象，并提供要给获取代理对象的方法 cglib动态代理生成的代理类和jdk动态代理代码格式上几乎没有什么区别，唯一的区别在于cglib生成的代理类继承了仅仅Proxy类，而jdk动态代理生成的代理类继承了Proxy类的同时也实现了一个接口。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 生成一个Proxy的子类public final class OrderService extends Proxy &#123; private static Method m1; private static Method m2; private static Method m0; public OrderService(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; jdk proxy vs cglibJDK Proxy 的优势： 最小化依赖关系，减少依赖意味着简化开发和维护，JDK 本身的支持，可能比 cglib 更加可靠。 平滑进行 JDK 版本升级，而字节码类库通常需要进行更新以保证在新版 Java 上能够使用。 代码实现简单。 cglib 优势： 有的时候调用目标可能不便实现额外接口，从某种角度看，限定调用者实现接口是有些侵入性的实践，类似 cglib 动态代理就没有这种限制。 只操作我们关心的类，而不必为其他相关类增加工作量。 代理模式: 为其他对象提供一种代理以控制（隔离，使用接口）对这个对象的访问。 jdk动态代理生成的代理类继承了Proxy类并实现了被代理的接口；而cglib生成的代理类则仅继承了Proxy类。 jdk动态代理最大缺点：只能代理接口，既委托类必须实现相应的接口 cglib缺点：由于是通过“子类化”的方式， 所以不能代理final的委托类或者普通委托类的final修饰的方法。 动态代理导致spring事务失效的场景： https://www.jianshu.com/p/3dd79531fe41","tags":["Java","设计","动态代理"],"categories":["Java"]},{"title":"接口 vs 抽象类的区别？","path":"/java/abstract_interface/","content":"在面向对象编程中，抽象类和接口是两个经常被用到的语法概念，是面向对象四大特性，以及很多设计模式、设计思想、设计原则编程实现的基础。 比如：我们可以使用接口来实现面向对象的抽象特性、多态特性和基于接口而非实现的设计原则，使用抽象类来实现面向对象的继承特性和模板设计模式等。 什么是抽象类和接口？ 区别在哪里？不同的编程语言对接口和抽象类的定义方式可能有些差别，但是差别并不大。本文使用 Java 语言。 抽象类下面我们通过一个例子来看一个典型的抽象类的使用场景。 Logger 是一个记录日志的抽象类，FileLogger 和 MessageQueueLogger 继承Logger，分别实现两种不同的日志记录方式： 记录日志到文件中 记录日志到消息队列中 FileLogger 和 MessageQueuLogger 两个子类复用了父类 Logger 中的name、enabled 以及 minPermittedLevel 属性和 log 方法，但是因为两个子类写日志的方式不同，他们又各自重写了父类中的doLog方法。 父类 1234567891011121314151617181920212223242526import java.util.logging.Level;/** * 抽象父类 * @author yanliang * @date 9/27/2020 5:59 PM */public abstract class Logger &#123; private String name; private boolean enabled; private Level minPermittedLevel; public Logger(String name, boolean enabled, Level minPermittedLevel) &#123; this.name = name; this.enabled = enabled; this.minPermittedLevel = minPermittedLevel; &#125; public void log(Level level, String message) &#123; boolean loggable = enabled &amp;&amp; (minPermittedLevel.intValue() &lt;= level.intValue()); if(!loggable) return; doLog(level, message); &#125; protected abstract void doLog(Level level, String message);&#125; FileLogger 12345678910111213141516171819202122232425import java.io.FileWriter;import java.io.IOException;import java.io.Writer;import java.util.logging.Level;/** * 抽象类Logger的子类：输出日志到文件中 * @author yanliang * @date 9/28/2020 4:44 PM */public class FileLogger extends Logger &#123; private Writer fileWriter; public FileLogger(String name, boolean enabled, Level minPermittedLevel, String filePath) throws IOException &#123; super(name, enabled, minPermittedLevel); this.fileWriter = new FileWriter(filePath); &#125; @Override protected void doLog(Level level, String message) &#123; // 格式化level 和 message，输出到日志文件 fileWriter.write(...); &#125;&#125; MessageQueuLogger 12345678910111213141516171819202122import java.util.logging.Level;/** * 抽象类Logger的子类：输出日志到消息队列中 * @author yanliang * @date 9/28/2020 6:39 PM */public class MessageQueueLogger extends Logger &#123; private MessageQueueClient messageQueueClient; public MessageQueueLogger(String name, boolean enabled, Level minPermittedLevel, MessageQueueClient messageQueueClient) &#123; super(name, enabled, minPermittedLevel); this.messageQueueClient = messageQueueClient; &#125; @Override protected void doLog(Level level, String message) &#123; // 格式化level 和 message，输出到消息队列中 messageQueueClient.send(...) &#125;&#125; 通过上面的例子，我们来看下抽象类有哪些特性。 抽象类不能被实例化，只能被继承。（new 一个抽象类，会报编译错误） 抽象类可以包含属性和方法。方法既可以包含实现，也可以不包含实现。不包含实现的方法叫做抽象方法 子类继承抽象类，必须实现抽象类中的所有抽象方法。 接口同样的，下面我们通过一个例子来看下接口的使用场景。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 过滤器接口 * @author yanliang * @date 9/28/2020 6:46 PM */public interface Filter &#123; void doFilter(RpcRequest req) throws RpcException;&#125;/** * 接口实现类：鉴权过滤器 * @author yanliang * @date 9/28/2020 6:48 PM */public class AuthencationFilter implements Filter &#123; @Override public void doFilter(RpcRequest req) throws RpcException &#123; // 鉴权逻辑 &#125;&#125;/** * 接口实现类：限流过滤器 * @author yanliang * @date 9/28/2020 6:48 PM */public class RateLimitFilter implements Filter&#123; @Override public void doFilter(RpcRequest req) throws RpcException &#123; // 限流逻辑 &#125;&#125;/** * 过滤器使用demo * @author yanliang * @date 9/28/2020 6:48 PM */public class Application &#123; // 过滤器列表 private List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); filters.add(new AuthencationFilter()); filters.add(new RateLimitFilter()); public void handleRpcRequest(RpcRequest req) &#123; try &#123; for (Filter filter : filters) &#123; filter.doFilter(req); &#125; &#125; catch (RpcException e) &#123; // 处理过滤结果 &#125; // ... &#125;&#125; 上面的案例是一个典型的接口使用场景。通过Java中的 interface 关键字定义了一个Filter 接口，AuthencationFilter 和 RetaLimitFilter 是接口的两个实现类，分别实现了对Rpc请求的鉴权和限流的过滤功能。 下面我们来看下接口的特性： JDK 1.8允许给接口添加非抽象的方法实现，但必须使用default关键字修饰；定义了default的方法可以不被实现子类所实现，但只能被实现子类的对象调用；如果子类实现了多个接口，并且这些接口包含一样的默认方法，则子类必须重写默认方法； JDK 1.8中允许使用static关键字修饰一个方法，并提供实现，称为接口静态方法。接口静态方法只能通过接口调用（接口名.静态方法名）。 类实现接口时，必须实现接口中定义的所有方法。 除了语法特性的不同外，从设计的角度，这两者也有较大区别。抽象类本质上就是类，只不过是一种特殊的类，这种类不能被实例化，只能被子类继承。属于is-a的关系。接口则是 has-a 的关系，表示具有某些功能。对于接口，有一个更形象的叫法：协议（contract） 抽象类和接口解决了什么问题？下面我们先来思考一个问题~ 抽象类的存在意义是为了解决代码复用的问题（多个子类可以继承抽象类中定义的属性哈方法，避免在子类中，重复编写相同的代码）。 那么，既然继承本身就能达到代码复用的目的，而且继承也不一定非要求是抽象类。我们不适用抽象类，貌似也可以实现继承和复用。从这个角度上讲，我们好像并不需要抽象类这种语法呀。那抽象类除了解决代码复用的问题，还有其他存在的意义吗？ 这里大家可以先思考一下哈~ 我们还是借用上面Logger的例子，首先对上面的案例实现做一些改造。在改造之后的实现中，Logger不再是抽象类，只是一个普通的父类，删除了Logger中的两个方法，新增了 isLoggable()方法。FileLogger 和 MessageQueueLogger 还是继承Logger父类已达到代码复用的目的。具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 父类：非抽象类，就是普通的类 * @author yanliang * @date 9/27/2020 5:59 PM */public class Logger &#123; private String name; private boolean enabled; private Level minPermittedLevel; public Logger(String name, boolean enabled, Level minPermittedLevel) &#123; this.name = name; this.enabled = enabled; this.minPermittedLevel = minPermittedLevel; &#125; public boolean isLoggable(Level level) &#123; return enabled &amp;&amp; (minPermittedLevel.intValue() &lt;= level.intValue()); &#125; &#125;/** * 抽象类Logger的子类：输出日志到文件中 * @author yanliang * @date 9/28/2020 4:44 PM */public class FileLogger extends Logger &#123; private Writer fileWriter; public FileLogger(String name, boolean enabled, Level minPermittedLevel, String filePath) throws IOException &#123; super(name, enabled, minPermittedLevel); this.fileWriter = new FileWriter(filePath); &#125; protected void log(Level level, String message) &#123; if (!isLoggable(level)) return ; // 格式化level 和 message，输出到日志文件 fileWriter.write(...); &#125;&#125;package com.yanliang.note.java.abstract_demo;import java.util.logging.Level;/** * 抽象类Logger的子类：输出日志到消息队列中 * @author yanliang * @date 9/28/2020 6:39 PM */public class MessageQueueLogger extends Logger &#123; private MessageQueueClient messageQueueClient; public MessageQueueLogger(String name, boolean enabled, Level minPermittedLevel, MessageQueueClient messageQueueClient) &#123; super(name, enabled, minPermittedLevel); this.messageQueueClient = messageQueueClient; &#125; protected void log(Level level, String message) &#123; if (!isLoggable(level)) return ; // 格式化level 和 message，输出到消息队列中 messageQueueClient.send(...) &#125;&#125; 以上实现虽然达到了代码复用的目的（复用了父类中的属性），但是却无法使用多态的特性了。 像下面这样编写代码就会出现编译错误，因为Logger中并没有定义log（）方法。 12Logger logger = new FileLogger(&quot;access-log&quot;, true, Level.WARN, &quot;/user/log&quot;);logger.log(Level.ERROR, &quot;This is a test log message.&quot;); 如果我们在父类中，定义一个空的log（）方法，让子类重写父类的log（）方法，实现自己的记录日志逻辑。使用这种方式是否能够解决上面的问题呢？ 大家可以先思考下~ 这个思路可以用使用，但是并不优雅，主要有一下几点原因： 在Logger中定义一个空的方法，会影响代码的可读性。如果不熟悉Logger背后的设计思想，又没有代码注释的话，在阅读Logger代码时就会感到疑惑（为什么这里会存在一个空的log（）方法） 当创建一个新的子类继承Logger父类时，有时可能会忘记重新实现log方法。之前是基于抽象类的设计思想，编译器会强制要求子类重写父类的log方法，否则就会报编译错误。 Logger可以被实例化，这也就意味着这个空的log方法有可能会被调用。这就增加了类被误用的风险。当然，这个问题 可以通过设置私有的构造函数的方式来解决，但是不如抽象类优雅。 抽象类更多是为了代码复用，而接口更侧重于解耦。接口是对行为的一种抽象，相当于一组协议或者契约（可类比API接口）。调用者只需要关心抽象的接口，不需要了解具体的实现，具体的实现代码对调用者透明。接口实现了约定和实现相分离，可以降低代码间的耦合，提高代码的可扩展性。 实际上，接口是一个比抽象类应用更加广泛、更加重要的知识点。比如，我们经常提到的 ”基于接口而非实现编程“ ,就是一条几乎天天会用到的，并且能极大的提高代码的灵活性、扩展性的设计思想。 如何模拟抽象类和接口在前面列举的例子中，我们使用Java的接口实现了Filter过滤器。不过，在 C++ 中只提供了抽象类，并没有提供接口，那从代码的角度上说，是不是就无法实现 Filter 的设计思路了呢？ 大家可以先思考下 🤔 ~ 我们先会议下接口的定义：接口中没有成员变量，只有方法声明，没有方法实现，实现接口的类必须实现接口中的所有方法。主要满足以上几点从设计的角度上来说，我们就可以把他叫做接口。 实际上，要满足接口的这些特性并不难。下面我们来看下实现： 1234567class Strategy &#123; public: -Strategy(); virtual void algorithm()=0; protected: Strategy();&#125; 抽象类 Strategy 没有定义任何属性，并且所有的方法都声明为 virtual 类型（等同于Java中的abstract关键字），这样，所有的方法都不能有代码实现，并且所有继承了这个抽象类的子类，都要实现这些方法。从语法特性上看，这个抽象类就相当于一个接口。 处理用抽象类来模拟接口外，我们还可以用普通类来模拟接口。具体的Java实现如下所示： 123456public class MockInterface &#123; protected MockInteface(); public void funcA() &#123; throw new MethodUnSupportedException(); &#125;&#125; 我们知道类中的方法必须包含实现，这个不符合接口的定义。但是，我们可以让类中的方法抛出 MethodUnSupportedException 异常，来模拟不包含实现的接口，并且强迫子类来继承这个父类的时候，都主动实现父类的方法，否则就会在运行时抛出异常。 那又如何避免这个类被实例化呢？ 实际上很简单，我们只需要将这个类的构造函数声明为 protected 访问权限就可以了。 如何决定该用抽象还是接口？上面的讲解可能偏理论，现在我们就从真实项目开发的角度来看下。在代码设计/编程时，什么时候该用接口？什么时候该用抽象类？ 实际上，判断的标准很简单。如果我们需要一种is-a关系，并且是为了解决代码复用的问题，就用抽象类。如果我们需要的是一种has-a关系，并且是为了解决抽象而非代码复用问题，我们就用接口。 从类的继承层次来看，抽象类是一种自下而上的设计思路，先有子类的代码复用，然后再抽象成上层的父类（也就是抽象类）。而接口则相反，它是一种自上而下的设计思路，我们在编程的时候，一般都是先设计接口，再去思考具体实现。 好了，你是否掌握了上面的内容呢。你可以通过一下几个维度来回顾自检一下： 抽象类和接口的语法特性 抽象类和接口存在的意义 抽象类和接口的应用场景有哪些","tags":["Java","接口","抽象"],"categories":["Java"]},{"title":"类加载器","path":"/java/jvm/jvm-class-loader2/","content":"类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。 注意：JVM主要在程序第一次主动使用类的时候，才会去加载该类，也就是说，JVM并不是在一开始就把一个程序就所有的类都加载到内存中，而是到不得不用的时候才把它加载进来，而且只加载一次。 类加载器jvm支持两种类型的加载器，分别是引导类加载器和 自定义加载器 引导类加载器是由c/c++实现的 自定义加载器是由java实现的。 jvm规范定义自定义加载器是指派生于抽象类ClassLoder的类加载器。按照这样的加载器的类型划分，在程序中我们最常见的类加载器是：引导类加载器BootStrapClassLoader、自定义类加载器(Extension Class Loader、System Class Loader、User-Defined ClassLoader） 上图中的加载器划分为包含关系而并非继承关系 启动类加载器这个类加载器使用c/c++实现，嵌套再jvm内部，用来加载Java的核心类库（JAVA_HOME/jre/lib/rt.jar、resource.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类。并不继承自java.lang.ClassLoader，没有父加载器 扩展类加载器java语言编写，由sun.misc.Launcher$ExtClassLoader实现。从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext 子目录（扩展目录）下加载类库。如果用户创建的JAR 放在此目录下，也会自动由扩展类加载器加载；派生于 ClassLoader。 父类加载器为启动类加载器 系统类加载器java语言编写，由 sun.misc.Lanucher$AppClassLoader 实现。该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载的，它负责加载环境变量classpath或系统属性java.class.path 指定路径下的类库；派生于 ClassLoader 。父类加载器为扩展类加载器 。通过ClassLoader#getSystemClassLoader() 方法可以获取到该类加载器。 1234567891011121314151617181920212223public class ClassLoaderTest &#123; public static void main(String[] args) &#123; // 获取系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader); // sun.misc.Launcher$AppClassLoader@18b4aac2 // 获取系统类加载器的父类加载器，扩展类加载器 ClassLoader extClassLoader = systemClassLoader.getParent(); System.out.println(extClassLoader); // sun.misc.Launcher$ExtClassLoader@1b6d3586 // 获取扩展类加载器的上层启动类加载器，这里获取不到 ClassLoader bootstrapClassLoader = extClassLoader.getParent(); System.out.println(bootstrapClassLoader); // null // 获取用户自定义类的加载器，classLoader的打印结果和systemClassLoader的结果完全一致 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader); // sun.misc.Launcher$AppClassLoader@18b4aac2 // 核心类库使用的是启动类加载器，以String为例 ClassLoader stringClassLoader = String.class.getClassLoader(); System.out.println(stringClassLoader); // null &#125;&#125; 双亲委派模型双亲委派模型工作过程是：如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即 ClassNotFoundException ），子加载器才会尝试自己去加载。 为什么需要双亲委派模型？假设没有双亲委派模型，试想一个场景： 黑客自定义一个 java.lang.String 类，该 String 类具有系统的 String 类一样的功能，只是在某个函数稍作修改。比如 equals 函数，这个函数经常使用，如果在这这个函数中，黑客加入一些“病毒代码”。并且通过自定义类加载器加入到 JVM 中。此时，如果没有双亲委派模型，那么 JVM 就可能误以为黑客自定义的java.lang.String 类是系统的 String 类，导致“病毒代码”被执行。 而有了双亲委派模型，黑客自定义的 java.lang.String 类永远都不会被加载进内存。因为首先是最顶端的类加载器加载系统的 java.lang.String 类，最终自定义的类加载器无法加载 java.lang.String 类。 或许你会想，我在自定义的类加载器里面强制加载自定义的 java.lang.String 类，不去通过调用父加载器不就好了吗?确实，这样是可行。但是，在 JVM 中，判断一个对象是否是某个类型时，如果该对象的实际类型与待比较的类型的类加载器不同，那么会返回false。 举个简单例子： ClassLoader1 ClassLoader2 都加载 java.lang.String 类，对应Class1、Class2对象。那么 Class1对象不属于 ClassLoad2 对象加载的 java.lang.String 类型。 如何实现双亲委派模型?双亲委派模型的原理很简单，实现也简单。每次通过先委托父类加载器加载，当父类加载器无法加载时，再自己加载。其实 ClassLoader 类默认的 loadClass 方法已经帮我们写好了，我们无需去写。 几个重要函数 loadClass 默认实现如下： 123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125; 再看看 loadClass(String name, boolean resolve) 函数： 123456789101112131415161718192021222324252627282930313233protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 从上面代码可以明显看出， loadClass(String, boolean) 函数即实现了双亲委派模型！整个大致过程如下： 首先，检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。 如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用 parent.loadClass(name, false); ）.或者是调用 bootstrap 类加载器来加载。 如果父加载器及 bootstrap 类加载器都没有找到指定的类，那么调用当前类加载器的 findClass 方法来完成类加载。 换句话说，如果自定义类加载器，就必须重写 findClass 方法！ findClass 的默认实现如下： 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; 可以看出，抽象类 ClassLoader 的 findClass 函数默认是抛出异常的。而前面我们知道， loadClass 在父加载器无法加载类的时候，就会调用我们自定义的类加载器中的 findeClass 函数，因此我们必须要在 loadClass 这个函数里面实现将一个指定类名称转换为 Class 对象. 如果是读取一个指定的名称的类为字节数组的话，这很好办。但是如何将字节数组转为 Class 对象呢？很简单，Java 提供了 defineClass 方法，通过这个方法，就可以把一个字节数组转为Class对象 defineClass 主要的功能是： 将一个字节数组转为 Class 对象，这个字节数组是 class 文件读取后最终的字节数组。如，假设 class 文件是加密过的，则需要解密后作为形参传入 defineClass 函数。 defineClass 默认实现如下： 1234protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError &#123; return defineClass(name, b, off, len, null);&#125; 自定义加类加载器为什么要自定义类加载器 隔离加载类 模块隔离,把类加载到不同的应用选中。比如tomcat这类web应用服务器，内部自定义了好几中类加载器，用于隔离web应用服务器上的不同应用程序。 修改类加载方式 除了Bootstrap加载器外，其他的加载并非一定要引入。根据实际情况在某个时间点按需进行动态加载。扩展加载源比如还可以从数据库、网络、或其他终端上加载 防止源码泄漏 java代码容易被编译和篡改，可以进行编译加密，类加载需要自定义还原加密字节码。 自定义类加载器实现实现方式: 所有用户自定义类加载器都应该继承ClassLoader类 在自定义ClassLoader的子类是,我们通常有两种做法: 重写loadClass方法(是实现双亲委派逻辑的地方,修改他会破坏双亲委派机制,不推荐) 重写findClass方法 (推荐) 首先，我们定义一个待加载的普通 Java 类: Test.java 。 1234567891011public class ClassLoaderTest &#123; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(&quot;d:/&quot;); try &#123; Class&lt;?&gt; clazz = classLoader.loadClass(&quot;TestMain&quot;); System.out.println(&quot;我是由&quot;+clazz.getClassLoader().getClass().getName()+&quot;类加载器加载的&quot;); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接下来就是自定义的类加载器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.io.*;public class MyClassLoader extends ClassLoader&#123; private String codePath; public MyClassLoader(ClassLoader parent, String codePath) &#123; super(parent); this.codePath = codePath; &#125; public MyClassLoader(String codePath) &#123; this.codePath = codePath; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; BufferedInputStream bis = null; ByteArrayOutputStream baos = null; try &#123; //1.字节码路径 String fileName = codePath+name+&quot;.class&quot;; //2.获取输入流 bis = new BufferedInputStream(new FileInputStream(fileName)); //3.获取输出流 baos = new ByteArrayOutputStream(); //4.io读写 int len; byte[] data = new byte[1024]; while ((len = bis.read(data)) != -1)&#123; baos.write(data , 0 , len); &#125; //5.获取内存中字节数组 byte[] byteCode = baos.toByteArray(); //6.调用defineClass 将字节数组转成Class对象 Class&lt;?&gt; defineClass = defineClass(null, byteCode, 0, byteCode.length); return defineClass; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; bis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; baos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125;&#125; 最后运行结果如下： 1我是由 class Main$MyClassLoader 加载进来的","tags":["Java","JVM","类加载器"],"categories":["Java","JVM","类加载器"]},{"title":"JVM 类加载机制","path":"/java/jvm/jvm-class-loader/","content":"类加载子系统主要包含如下几项功能： 负责从文件系统或是网络中加载.class文件，class文件在文件开头有特定的文件标识。 把加载后的class类信息存放于方法区，除了类信息之外，方法区还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射）。 ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。 如果调用构造器实例化对象，则该对象存放在堆区。 虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 类加载的执行过程类从被加载到虚拟机内存中开始，到卸载出内存，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initiallization）、使用（Using）和卸载（Unloading）这7个阶段。其中验证、准备、解析3个部分统称为连接（Linking），这七个阶段的发生顺序如下图： 上图中，加载、验证、准备、初始化、卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段不一定：它在某些情况下可以初始化阶段之后在开始，这是为了支持Java语言的运行时绑定（也称为动态绑定）。接下来讲解加载、验证、准备、解析、初始化五个步骤，这五个步骤组成了一个完整的类加载过程。使用没什么好说的，卸载属于GC的工作 。 加载加载是类加载的第一个阶段。有两种时机会触发类加载： 预加载 虚拟机启动时加载，加载的是JAVA_HOME/lib/下的rt.jar下的.class文件，这个jar包里面的内容是程序运行时非常常常用到的，像java.lang.*、java.util.、java.io. 等等，因此随着虚拟机一起加载。要证明这一点很简单，写一个空的main函数，设置虚拟机参数为”-XX:+TraceClassLoading”来获取类加载信息，运行一下： 12345678[Opened E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.lang.Object from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.io.Serializable from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.lang.Comparable from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.lang.CharSequence from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.lang.String from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar][Loaded java.lang.reflect.AnnotatedElement from E:\\developer\\JDK8\\JDK\\jre\\lib\\rt.jar]...... 运行时加载 虚拟机在用到一个.class文件的时候，会先去内存中查看一下这个.class文件有没有被加载，如果没有就会按照类的全限定名来加载这个类。 那么，加载阶段做了什么，其实加载阶段做了有三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个.class文件的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。一般这个Class是在堆里的，不过HotSpot虚拟机比较特殊，这个Class对象是放在方法区中的。 虚拟机规范对这三点的要求并不具体，因此虚拟机实现与具体应用的灵活度都是相当大的。例如第一条，根本没有指明二进制字节流要从哪里来、怎么来，因此单单就这一条，就能变出许多花样来： 从zip包中获取，这就是以后jar、ear、war格式的基础 从网络中获取，典型应用就是Applet 运行时计算生成，典型应用就是动态代理技术 由其他文件生成，典型应用就是JSP，即由JSP生成对应的.class文件 从数据库中读取，这种场景比较少见 总而言之，在类加载整个过程中，这部分是对于开发者来说可控性最强的一个阶段。 连接链接包含三个步骤： 分别是 验证Verification , 准备Preparation , 解析Resolution 三个过程。 验证 Verification 连接阶段的第一步，这一阶段的目的是为了确保.class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Java语言本身是相对安全的语言（相对C/C++来说），但是前面说过，.class文件未必要从Java源码编译而来，可以使用任何途径产生，甚至包括用十六进制编辑器直接编写来产生.class文件。在字节码语言层面上，Java代码至少从语义上是可以表达出来的。虚拟机如果不检查输入的字节流，对其完全信任的话，很可能会因为载入了有害的字节流而导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。 验证阶段将做一下几个工作，具体就不细讲了（详情可参考《深入理解Java虚拟机》），这是虚拟机实现层面的问题： 文件格式验证 元数据验证 字节码验证 符号引用验证 准备Preparation 准备阶段是正式为类变量分配内存并设置其初始值的阶段，这些变量所使用的内存都将在方法区中分配。关于这点，有两个地方注意一下： 这时候进行内存分配的仅仅是类变量（被static修饰的变量），而不是实例变量，实例变量将会在对象实例化的时候随着对象一起分配在Java堆中 这个阶段赋初始值的变量指的是那些不被final修饰的static变量，比如”public static int value = 123”，value在准备阶段过后是0而不是123，给value赋值为123的动作将在初始化阶段才进行；比如”public static final int value =123;”就不一样了，在准备阶段，虚拟机就会给value赋值为123。 各个数据类型的零值如下表： 数据类型 零值 int 0 long 0L short (short)0 chart ‘\\u0000’ byte (byte)0 boolean false float 0.0f double 0.0d reference null 实战： 说出下面两段代码的表现 1234567891011121314151617code-snippet-1:public class A &#123; static int a ; public static void main(String[] args) &#123; System.out.println(a); &#125;&#125;code-snippet-2:public class B &#123; public static void main(String[] args) &#123; int a ; System.out.println(a); &#125;&#125; Answercode-snippet-1 将会输出 0code-snippet-2 将无法通过编译这是因为局部变量不像类变量那样存在准备阶段。类变量有两次赋初始值的过程，一次在准备阶段，赋予初始值（也可以是指定值）；另外一次在初始化阶段，赋予程序员定义的值。因此，即使程序员没有为类变量赋值也没有关系，它仍然有一个默认的初始值。但局部变量就不一样了，如果没有给它赋初始值，是不能使用的。 解析Resolution 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。来了解一下符号引用和直接引用有什么区别： 符号引用 符号引用是一种定义，可以是任何字面上的含义，而直接引用就是直接指向目标的指针、相对偏移量。 这个其实是属于编译原理方面的概念，符号引用包括了下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 这么说可能不太好理解，结合实际看一下，写一段很简单的代码： 123456789public class TestMain &#123; private static int i; private double d; public static void print() &#123;&#125; private boolean trueOrFalse()&#123; return false; &#125;&#125; 用javap把这段代码的.class反编译一下 1234567891011121314151617181920212223Constant pool:#1 = Class #2 // com/xrq/test6/TestMain#2 = Utf8 com/xrq/test6/TestMain#3 = Class #4 // java/lang/Object#4 = Utf8 java/lang/Object#5 = Utf8 i#6 = Utf8 I#7 = Utf8 d#8 = Utf8 D#9 = Utf8 &lt;init&gt;#10 = Utf8 ()V#11 = Utf8 Code#12 = Methodref #3.#13 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V#13 = NameAndType #9:#10 // &quot;&lt;init&gt;&quot;:()V#14 = Utf8 LineNumberTable#15 = Utf8 LocalVariableTable#16 = Utf8 this#17 = Utf8 Lcom/xrq/test6/TestMain;#18 = Utf8 print#19 = Utf8 trueOrFalse#20 = Utf8 ()Z#21 = Utf8 SourceFile#22 = Utf8 TestMain.java 看到Constant Pool也就是常量池中有22项内容，其中带”Utf8”的就是符号引用。比如#2，它的值是”com/xrq/test6/TestMain”，表示的是这个类的全限定名；又比如#5为i，#6为I，它们是一对的，表示变量时Integer（int）类型的，名字叫做i；#6为D、#7为d也是一样，表示一个Double（double）类型的变量，名字为d； #18、#19表示的都是方法的名字。 总而言之，符号引用和我们上面讲的是一样的，是对于类、变量、方法的描述。符号引用和虚拟机的内存布局是没有关系的，引用的目标未必已经加载到内存中了。 直接引用 直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同的虚拟机示例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经存在在内存中了。 解析阶段负责把整个类激活，串成一个可以找到彼此的网，过程不可谓不重要。那这个阶段都做了哪些工作呢？大体可以分为： 类或接口的解析 类方法解析 接口方法解析 字段解析 初始化类的初始化阶段是类加载过程的最后一个步骤， 之前介绍的几个类加载的动作里， 除了在加载阶段用户应用程序可以通过自定义类加载器的方式局部参与外， 其余动作都完全由Java虚拟机来主导控制。 直到初始化段，Java 虚拟机才真正开始执行类中编写的Java程序代码， 将主导权移交给应用程序。 初始化阶段就是执行类构造器clinit()方法的过程。 clinit()并不是程序员在Java代码中直接编写的方法， 它是Javac编译器的自动生成物。 clinit()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块） 中的语句合并产生的， 编译器收集的顺序是由语句在源文件中出现的顺序决定的， 静态语句块中只能访问到定义在静态语句块之前的变量， 定义在它之后的变量，在前面的静态语句块可以赋值， 但是不能访问， 如下代码 1234567public class TestClinit &#123; static &#123; i = 0; // 给变量复制可以正常编译通过 System.out.print(i); // 这句编译器会提示“非法向前引用” &#125; static int i = 1;&#125; clinit()方法与类的构造函数（即在虚拟机视角中的实例构造器()方法） 不同， 它不需要显式地调用父类构造器， Java虚拟机会保证在子类的clinit()方法执行前， 父类的clinit()方法已经执行 完毕。 因此在Java虚拟机中第一个被执行的clinit()方法的类型肯定是java.lang.Object。 由于父类的clinit()方法先执行， 也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作， 如下代码中， 字段B的值将会是2而不是1。方法执行顺序 123456789101112131415161718class TestClinit02 &#123; static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; &#125; static class Sub extends Parent &#123; public static int B = A; &#125; public static void main(String[] args) &#123; System.out.println(Sub.B); &#125;&#125;output: 2 clinit()方法对于类或接口来说并不是必需的， 如果一个类中没有静态语句块， 也没有对变量的赋值操作， 那么编译器可以不为这个类生成clinit()方法。 接口中不能使用静态语句块， 但仍然有变量初始化的赋值操作， 因此接口与类一样都会生成 clinit()方法。 但接口与类不同的是， 执行接口的clinit()方法不需要先执行父接口的clinit()方法， 因为只有当父接口中定义的变量被使用时， 父接口才会被初始化。 此外， 接口的实现类在初始化时也一样不会执行接口的clinit()方法。 Java虚拟机必须保证一个类的clinit()方法在多线程环境中被正确地加锁同步， 如果多个线程同时去初始化一个类， 那么只会有其中一个线程去执行这个类的clinit()方法， 其他线程都需要阻塞等待， 直到活动线程执行完毕clinit()方法。 如果在一个类的clinit()方法中有耗时很长的操作， 那就可能造成多个进程阻塞， 在实际应用中这种阻塞往往是很隐蔽的。 12345678910111213141516171819202122232425class TestDeadLoop &#123; static class DeadLoopClass &#123; static &#123; // 如果不加上这个if语句， 编译器将提示“Initializer does not complete normally”拒绝编译 if (true) &#123; System.out.println(Thread.currentThread() + &quot;init DeadLoopClass&quot;); while (true) &#123; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Runnable script = new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread() + &quot;start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot; run over&quot;); &#125; &#125;; Thread thread1 = new Thread(script); Thread thread2 = new Thread(script); thread1.start(); thread2.start(); &#125;&#125; cinit 和 init 的区别主要是为了弄明白类的初始化和对象的初始化之间的差别。 12345678910111213141516171819202122232425262728293031323334public class ParentA &#123; static &#123; System.out.println(&quot;1&quot;); &#125; public ParentA() &#123; System.out.println(&quot;2&quot;); &#125;&#125;class SonB extends ParentA &#123; static &#123; System.out.println(&quot;a&quot;); &#125; public SonB() &#123; System.out.println(&quot;b&quot;); &#125; public static void main(String[] args) &#123; ParentA ab = new SonB(); ab = new SonB(); &#125;&#125;Answer:1a2b2b 其中 static 字段和 static 代码块，是属于类的，在类的加载的初始化阶段就已经被执行。类信息会被存放在方法区，在同一个类加载器下，这些信息有一份就够了，所以上面的 static 代码块只会执行一次，它对应的是 cinit 方法。 所以，上面代码的 static 代码块只会执行一次，对象的构造方法执行两次。再加上继承关系的先后原则，不难分析出正确结果。 结论: 方法 cinit 的执行时期: 类初始化阶段(该方法只能被jvm调用, 专门承担类变量的初始化工作) ,只执行一次 方法 init 的执行时期: 对象的初始化阶段","tags":["Java","JVM","类加载机制"],"categories":["Java","JVM"]},{"title":"JVM 内存管理","path":"/java/jvm/jvm-memory-manager/","content":"JVM 整体架构根据 JVM 规范，JVM 内存共分为: 程序计数器、虚拟机栈、本地方法栈、堆、方法区 这五个部分。 名 称 特征 作用 配置参数 异常 程 序 计 数 器 占用内存小，线程私有，生命周 期与线程相同 大致为字节码行号指示器 无 无 虚 拟 机 栈 线程私有，生命周期与线程相 同，使用连续的 内存空间 Java 方法执行的内存模 型，存储局部变量表、 操作栈、动态链接、方 法出口等信息 -Xss StackOverflowError/ OutOfMemoryError 本 地 方 法 栈 线程私有 为虚拟机使用到的 Native 方法服务 无 StackOverflowError/ OutOfMemoryError 堆 线程共享，生命周期与虚拟机相 同，可以不使用连续的内存地址 保存对象实例，所有对 象实例（包括数组）都 要在堆上分配 -Xms -Xsx -Xmn OutOfMemoryError 方 法 区 线程共享，生命周期与虚拟机相 同，可以不使用连续的内存地址 存储已被虚拟机加载的 类信息、常量、静态变 量、即时编译器编译后 的代码等数据 -XX:PermSize:16M-XX:MaxPermSize64M-XX:MetaspaceSize=16M-XX:MaxMetaspaceSize=64M OutOfMemoryError JVM分为五大模块： 类装载器子系统 、 运行时数据区 、 执行引擎 、 本地方法接口 和 垃圾收集模块 。 JVM 运行时内存Java 虚拟机有自动内存管理机制，如果出现面的问题，排查错误就必须要了解虚拟机是怎样使用内存的。 Java7和Java8内存结构的不同主要体现在方法区的实现，方法区是java虚拟机规范中定义的一种概念上的区域，不同的厂商可以对虚拟机进行不同的实现。我们通常使用的Java SE都是由Sun JDK和OpenJDK所提供，这也是应用最广泛的版本。而该版本使用的VM就是 HotSpot VM。通常情况下，我们所讲的java虚拟机指的就是HotSpot的版本。 线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存(非运行时数据区的一部分) 对于Java8，HotSpots取消了永久代，那么是不是就没有方法区了呢？ 当然不是，方法区只是一个规范，只不过它的实现变了。在Java8中，元空间(Metaspace)登上舞台，方法区存在于元空间(Metaspace)。同时，元空间不再与堆连续，而且是存在于本地内存（Native memory）。 方法区Java8之后的变化 移除了永久代（PermGen），替换为元空间（Metaspace） 永久代中的class metadata（类元信息）转移到了native memory（本地内存，而不是虚拟机） 永久代中的interned Strings（字符串常量池） 和 class static variables（类静态变量）转移到了Java heap 永久代参数（PermSize MaxPermSize）-&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize） Java8为什么要将永久代替换成Metaspace？ 字符串存在永久代中，容易出现性能问题和内存溢出。 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。 Oracle 可能会将HotSpot 与 JRockit 合二为一，JRockit没有所谓的永久代。 程序计数器程序计数器（Program Counter Register）:也叫PC寄存器，是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令、分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 特点： 区别于计算机硬件的pc寄存器，两者不略有不同。计算机用pc寄存器来存放“伪指令”或地址，而相对于虚拟机，pc寄存器它表现为一块内存，虚拟机的pc寄存器的功能也是存放伪指令，更确切的说存放的是将要执行指令的地址。 当虚拟机正在执行的方法是一个本地（native）方法的时候，jvm的pc寄存器存储的值是undefined。 程序计数器是线程私有的，它的生命周期与线程相同，每个线程都有一个。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器只会执行一条线程中的指令。 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 虚拟机栈Java虚拟机栈(Java Virtual Machine Stacks)也是线程私有的，即生命周期和线程相同。Java虚拟机栈和线程同时创建，用于存储栈帧。每个方法在执行时都会创建一个栈帧(Stack Frame)，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直到执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 12345678910111213141516171819202122232425262728package com.lagou.unit;public class StackDemo &#123; public static void main(String[] args) &#123; StackDemo sd = new StackDemo(); sd.A(); &#125; public void A()&#123; int a = 10; System.out.println(&quot; method A start&quot;); System.out.println(a); B(); System.out.println(&quot;method A end&quot;); &#125; public void B()&#123; int b = 20; System.out.println(&quot; method B start&quot;); C(); System.out.println(&quot;method B end&quot;); &#125; private void C() &#123; int c = 30; System.out.println(&quot; method C start&quot;); System.out.println(&quot;method C end&quot;); &#125;&#125; 什么是栈帧？栈帧(Stack Frame)是用于支持虚拟机进行方法调用和方法执行的数据结构。栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。每一个方法从调用至执行完成的过程，都对应着一个栈帧在虚拟机栈里从入栈到出栈的过程。 设置虚拟机栈的大小-Xss 为jvm启动的每个线程分配的内存大小，默认JDK1.4中是256K，JDK1.5+中是1M - Linux/x64 (64-bit): 1024 KB - macOS (64-bit): 1024 KB - Oracle Solaris/x64 (64-bit): 1024 KB - Windows: The default value depends on virtual memory -Xss1m-Xss1024k-Xss1048576 局部变量表局部变量表(Local Variable Table)是一组变量值存储空间，用于存放方法参数和方法内定义的局部变量。包括8种基本数据类型、对象引用（reference类型）和returnAddress类型（指向一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。 操作数栈操作数栈(Operand Stack)也称作操作栈，是一个后入先出栈(LIFO)。随着方法执行和字节码指令的执行，会从局部变量表或对象实例的字段中复制常量或变量写入到操作数栈，再随着计算的进行将栈中元素出栈到局部变量表或者返回给方法调用者，也就是出栈/入栈操作。 动态链接Java虚拟机栈中，每个栈帧都包含一个指向运行时常量池中该栈所属方法的符号引用，持有这个引用的目的是为了支持方法调用过程中的动态链接(Dynamic Linking)。 方法返回地址方法返回地址存放调用该方法的PC寄存器的值。一个方法的结束，有两种方式：正常地执行完成，出现未处理的异常非正常的退出。无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的PC计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。无论方法是否正常完成，都需要返回到方法被调用的位置，程序才能继续进行。 本地方法栈本地方法栈（Native Method Stacks） 与虚拟机栈所发挥的作用是非常相似的， 其区别只是虚拟机栈为虚拟机执行 Java方法（也就是字节码） 服务， 而本地方法栈则是为虚拟机使用到的本地（Native） 方法服务。 特点： 本地方法栈加载native的但是方法, native类方法存在的意义当然是填补java代码不方便实现的缺陷而提出的。 虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的Native方法服务。 是线程私有的，它的生命周期与线程相同，每个线程都有一个。 在Java虚拟机规范中，对本地方法栈这块区域，与Java虚拟机栈一样，规定了两种类型的异常： StackOverFlowError :线程请求的栈深度&gt;所允许的深度。 OutOfMemoryError：本地方法栈扩展时无法申请到足够的内存。 堆对于Java应用程序来说， Java堆（Java Heap） 是虚拟机所管理的内存中最大的一块。 Java堆是被所有线程共享的一块内存区域， 在虚拟机启动时创建。 此内存区域的唯一目的就是存放对象实例， Java 世界里“几乎”所有的对象实例都在这里分配内存。 “几乎”是指从实现角度来看， 随着Java语言的发展，现在已经能看到些许迹象表明日后可能出现值类型的支持， 即使只考虑现在， 由于即时编译技术的进步， 尤其是逃逸分析技术的日渐强大， 栈上分配、 标量替换优化手段已经导致一些微妙的变化悄然发生， 所以说Java对象实例都分配在堆上也渐渐变得不是那么绝对了。 特点： 是Java虚拟机所管理的内存中最大的一块。 堆是jvm所有线程共享的。堆中也包含私有的线程缓冲区 Thread Local Allocation Buffer (TLAB) 在虚拟机启动的时候创建。 唯一目的就是存放对象实例，几乎所有的对象实例以及数组都要在这里分配内存。 Java堆是垃圾收集器管理的主要区域。 因此很多时候java堆也被称为“GC堆”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代；新生代又可以分为：Eden 空间、FromSurvivor空间、To Survivor空间。 java堆是计算机物理存储上不连续的、逻辑上是连续的，也是大小可调节的（通过-Xms和-Xmx控制）。 方法结束后,堆中对象不会马上移出仅仅在垃圾回收的时候时候才移除。 如果在堆中没有内存完成实例的分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常 设置堆空间大小 内存大小-Xmx/-Xms 使用示例: -Xmx20m -Xms5m 说明： 当下Java应用最大可用内存为20M， 最小内存为5M 测试: 12345678910111213141516171819public class TestVm &#123; public static void main(String[] args) &#123; //补充 //byte[] b=new byte[5*1024*1024]; //System.out.println(&quot;分配了1M空间给数组&quot;); System.out.print(&quot;Xmx=&quot;); System.out.println(Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + &quot;M&quot;); System.out.print(&quot;free mem=&quot;); System.out.println(Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + &quot;M&quot;); System.out.print(&quot;total mem=&quot;); System.out.println(Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + &quot;M&quot;); &#125;&#125;Output:Xmx=20.0Mfree mem=4.1877593994140625Mtotal mem=6.0M 可以发现，打印出来的Xmx值和设置的值之间是由差异的，total Memory和最大的内存之间还是存在一定差异的，就是说JVM一般会尽量保持内存在一个尽可能底的层面，而非贪婪做法按照最大的内存来进行分配。 在测试代码中新增如下语句，申请内存分配： 12byte[] b=new byte[4*1024*1024];System.out.println(&quot;分配了1M空间给数组&quot;); 在申请分配了4m内存空间之后，total memory上升了，同时可用的内存也上升了，可以发现其实JVM在分配内存过程中是动态的， 按需来分配的。 堆的分类现在垃圾回收器都使用分代理论,堆空间也分类如下: 在Java7 Hotspot虚拟机中将Java堆内存分为3个部分： 青年代Young Generation 老年代Old Generation 永久代Permanent Generation 在Java8以后，由于方法区的内存不在分配在Java堆上，而是存储于本地内存元空间Metaspace中，所以永久代就不存在了，在几天前(2018年9约25日)Java11正式发布以后，我从官网上找到了关于Java11中垃圾收集器的官方文档， 文档中没有提到“永久代”，而只有青年代和老年代。 年轻代 &amp; 老年代JVM中存储java对象可以被分为两类: 年轻代(Young Gen)：年轻代主要存放新创建的对象，内存大小相对会比较小，垃圾回收会比较频繁。年轻代分成1个Eden Space和2个Suvivor Space（from 和to）。 年老代(Tenured Gen)：年老代主要存放JVM认为生命周期比较长的对象（经过几次的Young Gen的垃圾回收后仍然存在），内存大小相对会比较大，垃圾回收也相对没有那么频繁。 默认 -XX:NewRatio=2 , 标识新生代占1 , 老年代占2 ,新生代占整个堆的1/3修改占比 -XX:NewPatio=4 , 标识新生代占1 , 老年代占4 , 新生代占整个堆的1/5 Eden空间和另外两个Survivor空间占比分别为8:1:1。可以通过操作选项 -XX:SurvivorRatio 调整这个空间比例。 比如 -XX:SurvivorRatio=8 几乎所有的java对象都在Eden区创建, 但80%的对象生命周期都很短,创建出来就会被销毁. 从图中可以看出： 堆大小 = 新生代 + 老年代。其中，堆的大小可以通过参数 –Xms、-Xmx 来指定。 默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。 默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。 JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间。 对象分配过程JVM设计者不仅需要考虑到内存如何分配，在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，因此还需要考虑GC执行完内存回收后是否存在空间中间产生内存碎片。 分配过程： new的对象先放在伊甸园区。该区域有大小限制 当伊甸园区域填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园预期进行垃圾回收（Minor GC）,将伊甸园区域中不再被其他对象引用的额对象进行销毁，再加载新的对象放到伊甸园区 然后将伊甸园区中的剩余对象移动到幸存者0区 如果再次触发垃圾回收，此时上次幸存下来的放在幸存者0区的，如果没有回收，就会放到幸存者1区 如果再次经历垃圾回收，此时会重新返回幸存者0区，接着再去幸存者1区。 如果累计次数到达默认的15次，这会进入养老区。可以通过设置参数，调整阈值 -XX:MaxTenuringThreshold=N 养老区内存不足时,会再次触发GC:Major GC 进行养老区的内存清理 如果养老区执行了Major GC后仍然没有办法进行对象的保存,就会报OOM异常. GC 堆Java 中的堆也是 GC 收集垃圾的主要区域。GC 分为两种：一种是部分收集器（Partial GC）另一类是整堆收集器（Fu’ll GC） 部分收集器: 不是完整收集java堆的的收集器,它又分为: 新生代收集（Minor GC / Young GC）: 只是新生代的垃圾收集 老年代收集 （Major GC / Old GC）: 只是老年代的垃圾收集 (CMS GC 单独回收老年代) 混合收集（Mixed GC）:收集整个新生代及老年代的垃圾收集 (G1 GC会混合回收, region区域回收) 整堆收集（Full GC）:收集整个java堆和方法区的垃圾收集器 年轻代GC触发条件: 年轻代空间不足,就会触发Minor GC， 这里年轻代指的是Eden代满，Survivor不满不会引发GCMinor GC会引发STW(stop the world) ,暂停其他用户的线程,等垃圾回收接收,用户的线程才恢复. 老年代GC (Major GC)触发条件： 老年代空间不足时,会尝试触发MinorGC. 如果空间还是不足,则触发Major GC。如果Major GC , 内存仍然不足,则报错OOM，Major GC的速度比Minor GC慢10倍以上. FullGC 触发条件: 调用System.gc() , 系统会执行Full GC ,不是立即执行. 老年代空间不足 方法区空间不足 通过Minor GC进入老年代平均大小大于老年代可用内存 元空间在JDK1.7之前，HotSpot 虚拟机把方法区当成永久代来进行垃圾回收。而从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。 HotSpots取消了永久代，那么是不是也就没有方法区了呢？当然不是，方法区是一个规范，规范没变，它就一直在，只不过取代永久代的是元空间（Metaspace）而已。 它和永久代有什么不同的？ 存储位置不同：永久代在物理上是堆的一部分，和新生代、老年代的地址是连续的，而元空间属于本地内存。 存储内容不同：在原来的永久代划分中，永久代用来存放类的元数据信息、静态变量以及常量池等。现在类的元信息存储在元空间中，静态变量和常量池等并入堆中，相当于原来的永久代中的数据，被元空间和堆内存给瓜分了。 为什么要废弃永久代，引入元空间？ 相比于之前的永久代划分，Oracle为什么要做这样的改进呢？ 在原来的永久代划分中，永久代需要存放类的元数据、静态变量和常量等。它的大小不容易确定，因为这其中有很多影响因素，比如类的总数，常量池的大小和方法数量等，-XX:MaxPermSize 指定太小很容易造成永久代内存溢出。 移除永久代是为融合HotSpot VM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代 永久代会为GC带来不必要的复杂度，并且回收效率偏低。 废除永久代的好处 由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。不会遇到永久代存在时的内存溢出错误。 将运行时常量池从PermGen分离出来，与类的元数据分开，提升类元数据的独立性。 将元数据从PermGen剥离出来到Metaspace，可以提升对元数据的管理同时提升GC效率。 Metaspace相关参数 -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的。如果没有使用该参数来设置类的元数据的大小，其最大可利用空间是整个系统内存的可用空间。JVM也可以增加本地内存空间来满足类元数据信息的存储。但是如果没有设置最大值，则可能存在bug导致Metaspace的空间在不停的扩展，会导致机器的内存不足；进而可能出现swap内存被耗尽；最终导致进程直接被系统直接kill掉。如果设置了该参数，当Metaspace剩余空间不足，会抛出：java.lang.OutOfMemoryError: Metaspace space -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 方法区方法区（Method Area） 与Java堆一样， 是各个线程共享的内存区域， 它用于存储已被虚拟机加载 的类型信息、常量、 静态变量、 即时编译器编译后的代码缓存等数据。 《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上是属于堆的一部分，但些简单的实现可能不会选择去进行垃圾收集或者进行压缩”。对HotSpot而言，方法区还有一个别名叫做Non-Heap（非堆），的就是要和堆分开。 元空间、永久代是方法区具体的落地实现。方法区看作是一块独立于Java堆的内存空间，它主要是用来存储所加载的类信息的 方法区的特点 方法区与堆一样是各个线程共享的内存区域 方法区在JVM启动的时候就会被创建并且它实例的物理内存空间和Java堆一样都可以不连续 方法区的大小跟堆空间一样 可以选择固定大小或者动态变化 方法区的对象决定了系统可以保存多少个类,如果系统定义了太多的类 导致方法区溢出虚拟机同样会跑出(OOM)异常(Java7之前是 PermGen Space (永久带) Java 8之后 是MetaSpace(元空间) ) 关闭JVM就会释放这个区域的内存 方法区结构 类加载器将Class文件加载到内存之后，将类的信息存储到方法区中。 方法区中存储的内容： 类型信息（域信息、方法信息） 运行时常量池 类型信息 对每个加载的类型（类Class、接口 interface、枚举enum、注解 annotation），JVM必须在方法区中存储以下类型信息： 这个类型的完整有效名称（全名 = 包名.类名） 这个类型直接父类的完整有效名（对于 interface或是java.lang. Object，都没有父类） 这个类型的修饰符（ public, abstract，final的某个子集） 这个类型直接接口的一个有序列表 域信息 域信息，即为类的属性，成员变量。JVM必须在方法区中保存类所有的成员变量相关信息及声明顺序。 域的相关信息包括：域名称、域类型、域修饰符（pυblic、private、protected、static、final、volatile、transient的某个子集） 方法信息 JVM必须保存所有方法的以下信息，同域信息一样包括声明顺序： 方法名称方法的返回类型（或void） 方法参数的数量和类型（按顺序） 方法的修饰符public、private、protected、static、final、synchronized、native,、abstract的一个子集 方法的字节码bytecodes、操作数栈、局部变量表及大小（ abstract和native方法除外） 异常表（ abstract和 native方法除外）。每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引 方法区设置方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。 jdk7及以前 通过-xx:Permsize来设置永久代初始分配空间。默认值是20.75M -XX:MaxPermsize来设定永久代最大可分配空间。32位机器默认是64M，64位机器模式是82M 当JVM加载的类信息容量超过了这个值，会报异常OutofMemoryError:PermGen space。 查看JDK PermSpace区域默认大小 123jps #是java提供的一个显示当前所有java进程pid的命令jinfo -flag PermSize 进程号 #查看进程的PermSize初始化空间大小jinfo -flag MaxPermSize 进程号 #查看PermSize最大空间 JDK8以后 元数据区大小可以使用参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize指定 默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是-1，即没有限制。 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError:Metaspace -XX:MetaspaceSize：设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的-xx:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，FullGC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活）然后这个高水位线将会置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。 如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到FullGC多次调用。为了避免频繁地GC，建议将-XX:MetaspaceSize设置为一个相对较高的值。 123456jps #是java提供的一个显示当前所有java进程pid的命令jinfo -flag PermSize 进程号 #查看进程的PermSize初始化空间大小jinfo -flag MaxPermSize 进程号 #查看PermSize最大空间jps #查看进程号jinfo -flag MetaspaceSize 进程号 #查看Metaspace 最大分配内存空间jinfo -flag MaxMetaspaceSize 进程号 #查看Metaspace最大空间 运行时常量池字节码文件中，内部包含了常量池。方法区中，内部包含了运行时常量池 常量池：存放编译期间生成的各种字面量与符号引用 运行时常量池：常量池表在运行时的表现形式 编译后的字节码文件中包含了类型信息、域信息、方法信息等。通过ClassLoader将字节码文件的常量池中的信息加载到内存中，存储在了方法区的运行时常量池中。 可以理解为字节码中的常量池 Constant pool 只是文件信息，它想要执行就必须加载到内存中。而Java程序是靠JVM，更具体的来说是JVM的执行引擎来解释执行的。执行引擎在运行时常量池中取数据，被加载的字节码常量池中的信息是放到了方法区的运行时常量池中。它们不是一个概念，存放的位置是不同的。一个在字节码文件中，一个在方法区中。 对字节码文件反编译之后，查看常量池相关信息： 要弄清楚方法区的运行时常量池，需要理解清楚字节码中的常量池。 一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（ Constant pool table），包括各种字面量和对类型、域和方法的符号引用。常量池，可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。 常量池表Constant pool table： 在方法中对常量池表的符号引用 为什么需要常量池？ 举例来说： 12345public class Solution &#123; public void method() &#123; System.out.println(&quot;are you ok&quot;); &#125;&#125; 这段代码很简单，但是里面却使用了 String、 System、 PrintStream及Object等结构。如果代码多，引用到的结构会更多！这里就需要常暈池，将这些引用转变为符号引用，具体用到时，采取加载。 直接内存直接内存（Direct Memory） 并不是虚拟机运行时数据区的一部分。 在JDK 1.4中新加入了NIO（New Input/Output） 类， 引入了一种基于通道（Channel） 与缓冲区 （Buer） 的I/O方式， 它可以使用Native函数库直接分配堆外内存， 然后通过一个存储在Java堆里面的 DirectByteBuer对象作为这块内存的引用进行操作。 这样能在一些场景中显著提高性能， 因为避免了 在Java堆和Native堆中来回复制数据。 NIO的Buer提供一个可以直接访问系统物理内存的类——DirectBuer。DirectBuer类继承自ByteBuer，但和普通的ByteBuer不同。普通的ByteBuer仍在JVM堆上分配内存，其最大内存受到最大堆内存的 限制。而DirectBuer直接分配在物理内存中，并不占用堆空间。在访问普通的ByteBuer时，系统总是会使用一个“内核缓冲区”进行操作。 而DirectBuer所处的位置，就相当于这个“内核缓冲区”。因此，使用DirectBuer是一种更加接近内存底层的方法，所以它的速度比普通的ByteBuer更快。 通过使用堆外内存，可以带来以下好处： 改善堆过大时垃圾回收效率，减少停顿。Full GC时会扫描堆内存，回收效率和堆大小成正比。Native的内存，由OS负责管理和回收。 减少内存在Native堆和JVM堆拷贝过程，避免拷贝损耗，降低内存使用。 可突破JVM内存大小限制。 OOM 常见异常Java堆溢出堆内存中主要存放对象、数组等，只要不断地创建这些对象，并且保证 GC Roots 到对象之间有可达路径来避免垃圾收集回收机制清除这些对象，当这些对象所占空间超过最大堆容量时，就会产生 OutOfMemoryError 的异常。堆内存异常示例如下： 12345678910111213/*** 设置最大堆最小堆：-Xms20m -Xmx20m*/public class HeapOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; oomObjectList = new ArrayList&lt;&gt;(); while (true) &#123; oomObjectList.add(new OOMObject()); &#125; &#125;&#125; 运行后会报异常，在堆栈信息中可以看到 java.lang.OutOfMemoryError: Java heap space 的信息，说明在堆内存空间产生内存溢出的异常。 新产生的对象最初分配在新生代，新生代满后会进行一次 Minor GC ，如果 Minor GC 后空间不足会把该对象和新生代满足条件的对象放入老年代，老年代空间不足时会进行 Full GC ，之后如果空间还不足以存放新对象则抛出 OutOfMemoryError 异常。 常见原因： 内存中加载的数据过多，如一次从数据库中取出过多数据； 集合对对象引用过多且使用完后没有清空； 代码中存在死循环或循环产生过多重复对象； 堆内存分配不合理 虚拟机栈和本地方法栈溢出由于HotSpot虚拟机中并不区分虚拟机栈和本地方法栈， 因此对于HotSpot来说， -Xoss参数（设置本地方法栈大小） 虽然存在， 但实际上是没有任何效果的， 栈容量只能由-Xss参数来设定。 关于虚拟机栈和本地方法栈， 在《Java虚拟机规范》 中描述了两种异常： 如果线程请求的栈深度大于虚拟机所允许的最大深度， 将抛出StackOverflowError异常。 如果虚拟机的栈内存允许动态扩展， 当扩展栈容量无法申请到足够的内存时， 将抛出 OutOfMemoryError异常。 《Java虚拟机规范》 明确允许Java虚拟机实现自行选择是否支持栈的动态扩展， 而HotSpot虚拟机的选择是不支持扩展， 所以除非在创建线程申请内存时就因无法获得足够内存而出现 OutOfMemoryError异常， 否则在线程运行时是不会因为扩展而导致内存溢出的， 只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。 运行时常量池和方法区溢出前面曾经提到HotSpot从JDK 7开始逐步“去永久代”的计划， 并在JDK 8中完全使用元空间来代替永久代的背景故事， 在此我们就以测试代码来观察一下， 使用“永久代”还是“元空间”来实现方法区， 对程序有什么 实际的影响。 String::intern()是一个本地方法， 它的作用是如果字符串常量池中已经包含一个等于此String对象的 字符串， 则返回代表池中这个字符串的String对象的引用； 否则， 会将此String对象包含的字符串添加到常量池中， 并且返回此String对象的引用。 在JDK 6或更早之前的HotSpot虚拟机中， 常量池都是分配在永久代中， 我们可以通过-XX：PermSize和-XX： MaxPermSize限制永久代的大小， 即可间接限制其中常量池的容量， 具体实现如代码清单 12345678910111213// OOM异常一：Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.base/java.lang.Integer.toString(Integer.java:440) at java.base/java.lang.String.valueOf(String.java:3058) at RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:12)// OOM异常二：//根据Oracle官方文档，默认情况下，如果Java进程花费98%以上的时间执行GC，并且每次只有不到2%的堆被恢复，则JVM抛出此错误Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded at java.lang.Integer.toString(Integer.java:401) at java.lang.String.valueOf(String.java:3099) at com.lagou.unit.RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:17) 方法区的其他部分的内容， 方法区的主要职责是用于存放类型的相关信息， 如类名、 访问修饰符、 常量池、 字段描述、 方法描述等。 对于这部分区域的测试， 基本的思路是运行时产 生大量的类去填满方法区， 直到溢出为止。 虽然直接使用Java SE API也可以动态产生类（如反射时的 GeneratedConstructorAccessor和动态代理等） ， 但在本次实验中操作起来比较麻烦。 在代码清单 借助CGLib使得方法区出现内存溢出异常 123456789101112131415161718192021/*** VM Args： -XX:PermSize=10M -XX:MaxPermSize=10M*/public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws ThrowException&#123; return proxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; static class OOMObject &#123; &#125;&#125; 在JDK 6中的运行结果 12345Caused by: java.lang.OutOfMemoryError: PermGen spaceat java.lang.ClassLoader.defineClass1(Native Method)at java.lang.ClassLoader.defineClassCond(ClassLoader.java:632)at java.lang.ClassLoader.defineClass(ClassLoader.java:616)... 8 more 方法区溢出也是一种常见的内存溢出异常， 一个类如果要被垃圾收集器回收， 要达成的条件是比较苛刻的。 在经常运行时生成大量动态类的应用场景里， 就应该特别关注这些类的回收状况。 这类场 景除了之前提到的程序使用了CGLib字节码增强和动态语言外， 常见的还有： 大量JSP或动态产生JSP 文件的应用（JSP第一次运行时需要编译为Java类） 、 基于OSGi的应用（即使是同一个类文件， 被不同 的加载器加载也会视为不同的类） 等。 在JDK 8以后， 永久代便完全退出了历史舞台， 元空间作为其替代者登场。 在默认设置下， 前面列举的那些正常的动态创建新类型的测试用例已经很难再迫使虚拟机产生方法区的溢出异常了。 不过 为了让使用者有预防实际应用里出现破坏性的操作， HotSpot还是提供了一 些参数作为元空间的防御措施， 主要包括： -XX： MaxMetaspaceSize： 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存 大小。 -XX： MetaspaceSize： 指定元空间的初始空间大小， 以字节为单位， 达到该值就会触发垃圾收集 进行类型卸载，同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放 了很少的空间， 那么在不超过-XX： MaxMetaspaceSize（如果设置了的话） 的情况下， 适当提高该值。 -XX： MinMetaspaceFreeRatio： 作用是在垃圾收集之后控制最小的元空间剩余容量的百分比， 可 减少因为元空间不足导致的垃圾收集的频率。 类似的还有-XX： Max-MetaspaceFreeRatio， 用于控制最 大的元空间剩余容量的百分比。 直接内存溢出直接内存（Direct Memory） 的容量大小可通过-XX： MaxDirectMemorySize参数来指定， 如果不去指定， 则默认与Java堆最大值（由-Xmx指定） 一致， 越过了DirectByteBuer类直接通 过反射获取Unsafe实例进行内存分配（Unsafe类的getUnsafe()方法指定只有引导类加载器才会返回实例， 体现了设计者希望只有虚拟机标准类库里面的类才能使用Unsafe的功能， 在JDK 10时才将Unsafe 的部分功能通过VarHandle开放给外部使用） ， 因为虽然使用DirectByteBuer分配内存也会抛出内存溢出异常， 但它抛出异常时并没有真正向操作系统申请分配内存， 而是通过计算得知内存无法分配就会 在代码里手动抛出溢出异常， 真正申请分配内存的方法是Unsafe::allocateMemory() 1234567891011121314151617181920/*** VM Args： -Xmx20M -XX:MaxDirectMemorySize=10M*/public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125;Output:Exception in thread &quot;main&quot; java.lang.OutOfMemoryErrorat sun.misc.Unsafe.allocateMemory(Native Method)at org.fenixsoft.oom.DMOOM.main(DMOOM.java:20) 由直接内存导致的内存溢出， 一个明显的特征是在Heap Dump文件中不会看见有什么明显的异常 情况， 如果发现内存溢出之后产生的Dump文件很小， 而程序中又直接或间接使用了 DirectMemory（典型的间接使用就是NIO） ，那就可以考虑重点检查一下直接内存方面的原因了。","tags":["Java","JVM","Java 虚拟机","内存管理"],"categories":["Java","JVM"]},{"title":"JVM 基础知识","path":"/java/jvm/jvm/","content":"什么是JVMJVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 主流的JVM 虚拟机名称 介绍 HotSpot Oracle/Sun JDK和OpenJDK都使用HotSPot VM的相同核心 J9 J9是IBM开发的高度模块化的JVM JRockit JRockit 与 HotSpot 同属于 Oracle，目前为止 Oracle 一直在推进 HotSpot 与 JRockit 两款各有优势的虚拟机进行融合互补 Zing 由Azul Systems根据HostPot为基础改进的高性能低延迟的JVM Dalvik Android上的Dalvik 虽然名字不叫JVM，但骨子里就是不折不扣的JVM JVM 与 操作系统的关系首选我们考虑这样一个问题，为什么要在程序和操作系统中间添加一个JVM？ Java 是一门抽象程度特别高的语言，提供了自动内存管理等一系列的特性。这些特性直接在操作系统上实现是不太可能的，所以就需要 JVM 进行一番转换。 从上图中可以看到，有了 JVM 这个抽象层之后，Java 就可以实现跨平台了。JVM 只需要保证能够正确执行 .class 文件，就可以运行在诸如 Linux、Windows、MacOS 等平台上了。 而 Java 跨平台的意义在于一次编译，处处运行，能够做到这一点 JVM 功不可没。比如我们在 Maven 仓库下载同一版本的 jar 包就可以到处运行，不需要在每个平台上再编译一次。 现在的一些 JVM 的扩展语言，比如 Clojure、JRuby、Groovy 等，编译到最后都是 .class 文件，Java 语言的维护者，只需要控制好 JVM 这个解析器，就可以将这些扩展语言无缝的运行在 JVM 之上了。 应用程序、JVM、操作系统之间的关系如下图所示： 我们用一句话概括 JVM 与操作系统之间的关系：JVM 上承开发语言，下接操作系统，它的中间接口就是字节码。 JVM JRE JDK的关系 JVM 是 Java 程序能够运行的核心。但是需要注意，JVM 自己什么也干不了，你需要给它提供生产原料（.class 文件）。仅仅是 JVM，是无法完成一次编译，处处运行的。它需要一个基本的类库，比如怎么操作文件、怎么连接网络等。 而 Java 体系很慷慨，会一次性将 JVM 运行所需的类库都传递给它。JVM 标准加上实现的一大堆基础类库，就组成了 Java 的运行时环境，也就是我们常说的 JRE（Java Runtime Environment）对于 JDK 来说，就更庞大了一些。除了 JRE，JDK 还提供了一些非常好用的小工具，比如 javac、java、jar 等。它是 Java 开发的核心，让外行也可以炼剑！ JVM、JRE、JDK 它们三者之间的关系，可以用一个包含关系表示。 java虚拟机规范和java语言规范的关系 左半部分是 Java 虚拟机规范，其实就是为输入和执行字节码提供一个运行环境。右半部分是我们常说的 Java 语法规范，比如 switch、for、泛型、lambda 等相关的程序，最终都会编译成字节码。而连接左右两部分的桥梁依然是Java 的字节码。 如果 .class 文件的规格是不变的，这两部分是可以独立进行优化的。但 Java 也会偶尔扩充一下 .class 文件的格式，增加一些字节码指令，以便支持更多的特性。 我们可以把 Java 虚拟机可以看作是一台抽象的计算机，它有自己的指令集以及各种运行时内存区域。 最后，我们简单看一下一个 Java 程序的执行过程，它到底是如何运行起来的。 这里的 Java 程序是文本格式的。比如下面这段 HelloWorld.java，它遵循的就是 Java 语言规范。其中，我们调用了System.out 等模块，也就是 JRE 里提供的类库。 12345public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello World&quot;); &#125;&#125; 使用 JDK 的工具 javac 进行编译后，会产生 HelloWorld 的字节码。 我们一直在说 Java 字节码是沟通 JVM 与 Java 程序的桥梁，下面使用 javap 来稍微看一下字节码到底长什么样子。 12345670 getstatic #2 &lt;java/lang/System.out&gt; // getstatic 获取静态字段的值3 ldc #3 &lt;Hello World&gt; // ldc 常量池中的常量值入栈5 invokevirtual #4 &lt;java/io/PrintStream.println&gt; // invokevirtual 运行时方法绑定调用方法8 return //void 函数返回 Java 虚拟机采用基于栈的架构，其指令由操作码和操作数组成。这些 字节码指令 ，就叫作 opcode。其中，getstatic、ldc、invokevirtual、return 等，就是 opcode，可以看到是比较容易理解的。 JVM 就是靠解析这些 opcode 和操作数来完成程序的执行的。当我们使用 Java 命令运行 .class 文件的时候，实际上就相当于启动了一个 JVM 进程。 然后 JVM 会翻译这些字节码，它有两种执行方式。常见的就是解释执行，将 opcode + 操作数翻译成机器代码；另外一种执行方式就是 JIT，也就是我们常说的即时编译，它会在一定条件下将字节码编译成机器码之后再执行。","tags":["Java","JVM","Java 虚拟机"],"categories":["Java","JVM"]},{"title":"撸一个JSON解析器","path":"/JSONParser/","content":"JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成。采用完全独立于语言的文本格式，但是也使用了类似于 C 语言家族的习惯（包括 C, C++, C#, Java, JavaScript, Perl, Python 等）。这些特性使 JSON 成为理想的数据交换语言。 JSON 与 JS 的区别以及和 XML 的区别具体请参考百度百科 JSON 有两种结构： 第一种：对象 “名称 / 值” 对的集合不同的语言中，它被理解为对象（object），纪录（record），结构（struct），字典（dictionary），哈希表（hash table），有键列表（keyed list），或者关联数组 （associative array）。 对象是一个无序的 “‘名称 / 值’对” 集合。一个对象以 “{”（左括号）开始，“}”（右括号）结束。每个“名称” 后跟一个 “:”（冒号）；“‘名称 / 值’ 对” 之间使用“,”（逗号）分隔。 1&#123;&quot;姓名&quot;: &quot;张三&quot;, &quot;年龄&quot;: &quot;18&quot;&#125; 第二种：数组 值的有序列表（An ordered list of values）。在大部分语言中，它被理解为数组（array）。 数组是值（value）的有序集合。一个数组以 “[”（左中括号）开始，“]”（右中括号）结束。值之间使用 “,”（逗号）分隔。 值（value）可以是双引号括起来的字符串（string）、数值 (number)、true、false、 null、对象（object）或者数组（array）。这些结构可以嵌套。 12345678910111213[ &#123; &quot;姓名&quot;: &quot;张三&quot;, &quot;年龄&quot;:&quot;18&quot; &#125;, &#123; &quot;姓名&quot;: &quot;里斯&quot;, &quot;年龄&quot;:&quot;19&quot; &#125;] 通过上面的了解可以看出，JSON 存在以下几种数据类型（以 Java 做类比）： json java string Java 中的 String number Java 中的 Long 或 Double true/false Java 中的 Boolean null Java 中的 null [array] Java 中的 List 或 Object[] {“key”:”value”} Java 中的 Map&lt;String, Object&gt; 解析 JSON输入一串 JSON 字符串，输出一个 JSON 对象。 步骤 JSON 解析的过程主要分以下两步： 第一步： 对于输入的一串 JSON 字符串我们需要将其解析成一组 token 流。 例如 JSON 字符串 {“姓名”: “张三”, “年龄”: “18”} 我们需要将它解析成 1&#123;、 姓名、 :、 张三、 ,、 年龄、 :、 18、 &#125; 这样一组 token 流 第二步：根据得到的 token 流将其解析成对应的 JSON 对象（JSONObject）或者 JSON 数组（JSONArray） 下面我们来详细分析下这两个步骤： 获取 token 流根据 JSON 格式的定义，token 可以分为以下几种类型 token 含义 NULL null NUMBER 数字 STRING 字符串 BOOLEAN true/false SEP_COLON : SEP_COMMA , BEGIN_OBJECT { END_OBJECT } BEGIN_ARRAY [ END_ARRAY ] END_DOCUMENT 表示 JSON 数据结束 根据以上的 JSON 类型，我们可以将其封装成 enum 类型的 TokenType 123456789101112131415161718192021222324252627282930313233343536373839package com.json.demo.tokenizer;/** BEGIN_OBJECT（&#123;） END_OBJECT（&#125;） BEGIN_ARRAY（[） END_ARRAY（]） NULL（null） NUMBER（数字） STRING（字符串） BOOLEAN（true/false） SEP_COLON（:） SEP_COMMA（,） END_DOCUMENT（表示JSON文档结束） */public enum TokenType &#123; BEGIN_OBJECT(1), END_OBJECT(2), BEGIN_ARRAY(4), END_ARRAY(8), NULL(16), NUMBER(32), STRING(64), BOOLEAN(128), SEP_COLON(256), SEP_COMMA(512), END_DOCUMENT(1024); private int code; // 每个类型的编号 TokenType(int code) &#123; this.code = code; &#125; public int getTokenCode() &#123; return code; &#125;&#125; 在 TokenType 中我们为每一种类型都赋一个数字，目的是在 Parser 做一些优化操作（通过位运算来判断是否是期望出现的类型） 在进行第一步之前 JSON 串对计算机来说只是一串没有意义的字符而已。第一步的作用就是把这些无意义的字符串变成一个一个的 token，上面我们已经为每一种 token 定义了相应的类型和值。所以计算机能够区分不同的 token，并能以 token 为单位解读 JSON 数据。 下面我们封装一个 token 类来存储每一个 token 对应的值 12345678910111213141516171819202122232425262728293031323334353637383940package com.json.demo.tokenizer;/** * 存储对应类型的字面量 */public class Token &#123; private TokenType tokenType; private String value; public Token(TokenType tokenType, String value) &#123; this.tokenType = tokenType; this.value = value; &#125; public TokenType getTokenType() &#123; return tokenType; &#125; public void setTokenType(TokenType tokenType) &#123; this.tokenType = tokenType; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; @Override public String toString() &#123; return &quot;Token&#123;&quot; + &quot;tokenType=&quot; + tokenType + &quot;, value=&#x27;&quot; + value + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 在解析的过程中我们通过字符流来不断的读取字符，并且需要经常根据相应的字符来判断状态的跳转。所以我们需要自己封装一个 ReaderChar 类，以便我们更好的操作字符流。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.json.demo.tokenizer;import java.io.IOException;import java.io.Reader;public class ReaderChar &#123; private static final int BUFFER_SIZE = 1024; private Reader reader; private char[] buffer; private int index; // 下标 private int size; public ReaderChar(Reader reader) &#123; this.reader = reader; buffer = new char[BUFFER_SIZE]; &#125; /** * 返回 pos 下标处的字符，并返回 * @return */ public char peek() &#123; if (index - 1 &gt;= size) &#123; return (char) -1; &#125; return buffer[Math.max(0, index - 1)]; &#125; /** * 返回 pos 下标处的字符，并将 pos + 1，最后返回字符 * @return * @throws IOException */ public char next() throws IOException &#123; if (!hasMore()) &#123; return (char) -1; &#125; return buffer[index++]; &#125; /** * 下标回退 */ public void back() &#123; index = Math.max(0, --index); &#125; /** * 判断流是否结束 */ public boolean hasMore() throws IOException &#123; if (index &lt; size) &#123; return true; &#125; fillBuffer(); return index &lt; size; &#125; /** * 填充buffer数组 * @throws IOException */ void fillBuffer() throws IOException &#123; int n = reader.read(buffer); if (n == -1) &#123; return; &#125; index = 0; size = n; &#125;&#125; 另外我们还需要一个 TokenList 来存储解析出来的 token 流 12345678910111213141516171819202122232425262728293031323334353637383940package com.json.demo.tokenizer;import java.util.ArrayList;import java.util.List;/** * 存储词法解析所得的token流 */public class TokenList &#123; private List&lt;Token&gt; tokens = new ArrayList&lt;Token&gt;(); private int index = 0; public void add(Token token) &#123; tokens.add(token); &#125; public Token peek() &#123; return index &lt; tokens.size() ? tokens.get(index) : null; &#125; public Token peekPrevious() &#123; return index - 1 &lt; 0 ? null : tokens.get(index - 2); &#125; public Token next() &#123; return tokens.get(index++); &#125; public boolean hasMore() &#123; return index &lt; tokens.size(); &#125; @Override public String toString() &#123; return &quot;TokenList&#123;&quot; + &quot;tokens=&quot; + tokens + &#x27;&#125;&#x27;; &#125;&#125; JSON 解析比其他文本解析要简单的地方在于，我们只需要根据下一个字符就可知道接下来它所期望读取的到的内容是什么样的。如果满足期望了，则返回 Token，否则返回错误。 为了方便程序出错时更好的 debug，程序中自定义了两个 exception 类来处理错误信息。（具体实现参考 exception 包） 下面就是第一步中的重头戏（核心代码）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public TokenList getTokenStream(ReaderChar readerChar) throws IOException &#123; this.readerChar = readerChar; tokenList = new TokenList(); // 词法解析，获取token流 tokenizer(); return tokenList; &#125; /** * 将JSON文件解析成token流 * @throws IOException */ private void tokenizer() throws IOException &#123; Token token; do &#123; token = start(); tokenList.add(token); &#125; while (token.getTokenType() != TokenType.END_DOCUMENT); &#125; /** * 解析过程的具体实现方法 * @return * @throws IOException * @throws JsonParseException */ private Token start() throws IOException, JsonParseException &#123; char ch; while (true)&#123; //先读一个字符，若为空白符（ASCII码在[0, 20H]上）则接着读，直到刚读的字符非空白符 if (!readerChar.hasMore()) &#123; return new Token(TokenType.END_DOCUMENT, null); &#125; ch = readerChar.next(); if (!isWhiteSpace(ch)) &#123; break; &#125; &#125; switch (ch) &#123; case &#x27;&#123;&#x27;: return new Token(TokenType.BEGIN_OBJECT, String.valueOf(ch)); case &#x27;&#125;&#x27;: return new Token(TokenType.END_OBJECT, String.valueOf(ch)); case &#x27;[&#x27;: return new Token(TokenType.BEGIN_ARRAY, String.valueOf(ch)); case &#x27;]&#x27;: return new Token(TokenType.END_ARRAY, String.valueOf(ch)); case &#x27;,&#x27;: return new Token(TokenType.SEP_COMMA, String.valueOf(ch)); case &#x27;:&#x27;: return new Token(TokenType.SEP_COLON, String.valueOf(ch)); case &#x27;n&#x27;: return readNull(); case &#x27;t&#x27;: case &#x27;f&#x27;: return readBoolean(); case &#x27;&quot;&#x27;: return readString(); case &#x27;-&#x27;: return readNumber(); &#125; if (isDigit(ch)) &#123; return readNumber(); &#125; throw new JsonParseException(&quot;Illegal character&quot;); &#125; 在 start 方法中，我们将每个处理方法都封装成了单独的函数。主要思想就是通过一个死循环不停的读取字符，然后再根据字符的期待值，执行不同的处理函数。 下面我们详解分析几个处理函数： 12345678910111213141516171819202122232425262728293031private Token readString() throws IOException &#123; StringBuilder sb = new StringBuilder(); while(true) &#123; char ch = readerChar.next(); if (ch == &#x27;\\\\&#x27;) &#123; // 处理转义字符 if (!isEscape()) &#123; throw new JsonParseException(&quot;Invalid escape character&quot;); &#125; sb.append(&#x27;\\\\&#x27;); ch = readerChar.peek(); sb.append(ch); if (ch == &#x27;u&#x27;) &#123; // 处理 Unicode 编码，形如 \\u4e2d。且只支持 \\u0000 ~ \\uFFFF 范围内的编码 for (int i = 0; i &lt; 4; i++) &#123; ch = readerChar.next(); if (isHex(ch)) &#123; sb.append(ch); &#125; else &#123; throw new JsonParseException(&quot;Invalid character&quot;); &#125; &#125; &#125; &#125; else if (ch == &#x27;&quot;&#x27;) &#123; // 碰到另一个双引号，则认为字符串解析结束，返回 Token return new Token(TokenType.STRING, sb.toString()); &#125; else if (ch == &#x27;\\r&#x27; || ch == &#x27; &#x27;) &#123; // 传入的 JSON 字符串不允许换行 throw new JsonParseException(&quot;Invalid character&quot;); &#125; else &#123; sb.append(ch); &#125; &#125; &#125; 该方法也是通过一个死循环来读取字符，首先判断的是 JSON 中的转义字符。 JSON 中允许出现的有以下几种 12345678910\\&quot;\\\\\\b\\f \\r\\t\\u four-hex-digits\\/ 具体的处理方法封装在了 isEscape() 方法中，处理 Unicode 编码时要特别注意一下 u 的后面会出现四位十六进制数。当读取到一个双引号或者读取到了非法字符（’r’或’、’n’）循环退出。 判断数字的时候也要特别小心，注意负数，frac，exp 等等情况。 通过上面的解析，我们可以得到一组 token，接下来我们需要以这组 token 作为输入，解析出相应的 JSON 对象 解析出 JSON 对象解析之前我们需要定义出 JSON 对象（JSONObject）和 JSON 数组 (JSONArray) 的实体类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.json.demo.jsonstyle;import com.json.demo.exception.JsonTypeException;import com.json.demo.util.FormatUtil;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * JSON的对象形式 * 对象是一个无序的“‘名称/值’对”集合。一个对象以“&#123;”（左括号）开始，“&#125;”（右括号）结束。每个“名称”后跟一个“:”（冒号）；“‘名称/值’ 对”之间使用“,”（逗号）分隔。 */public class JsonObject &#123; private Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); public void put(String key, Object value) &#123; map.put(key, value); &#125; public Object get(String key) &#123; return map.get(key); &#125; ... &#125;package com.json.demo.jsonstyle;import com.json.demo.exception.JsonTypeException;import com.json.demo.util.FormatUtil;import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * JSON的数组形式 * 数组是值（value）的有序集合。一个数组以“[”（左中括号）开始，“]”（右中括号）结束。值之间使用“,”（逗号）分隔。 */public class JsonArray &#123; private List list = new ArrayList(); public void add(Object obj) &#123; list.add(obj); &#125; public Object get(int index) &#123; return list.get(index); &#125; public int size() &#123; return list.size(); &#125; ...&#125; 之后我们就可以写解析类了，由于代码较长，这里就不展示了。有兴趣的可以去 GitHub 上下载。实现逻辑比较简单，也易于理解。 解析类中的 parse 方法首先根据第一个 token 的类型选择调用 parseJsonObject（）或者 parseJsonArray（），进而返回 JSON 对象或者 JSON 数组。上面的解析方法中利用位运算来判断字符的期待值既提高了程序的执行效率也有助于提高代码的 ke’du’xi 完成之后我们可以写一个测试类来验证下我们的解析器的运行情况。我们可以自己定义一组 JSON 串也可以通过 HttpUtil 工具类从网上获取。最后通过 FormatUtil 类来规范我们输出。 具体效果如下图所示： 参考文章 http://www.cnblogs.com/absfre… https://www.liaoxuefeng.com/a… https://segmentfault.com/a/11… http://json.org/json-zh.html","tags":["json","json 解析器"],"categories":["json"]},{"title":"常见排序算法的 Java 实现","path":"/algorithm/sort/","content":"https://www.cnblogs.com/shixiangwan/p/6724292.html 本文主要记录了几种常见的排序算法的 Java 实现，如冒泡排序、快速排序、直接插入排序、希尔排序、选择排序等等。 1. 冒泡排序将序列中所有元素两两比较，将最大的放在最后面。 将剩余序列中所有元素两两比较，将最大的放在最后面。 重复第二步，直到只剩下一个数。 123456789101112131415161718/** * 冒泡排序：两两比较，大者交换位置,则每一轮循环结束后最大的数就会移动到最后. * 时间复杂度为O(n²) 空间复杂度为O(1) */private static void bubbleSort(int[] arr) &#123; //外层循环length-1次 for (int i = 0; i &lt; arr.length-1; i++) &#123; //外层每循环一次最后都会排好一个数 //所以内层循环length-1-i次 for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125;&#125; 2. 快速排序快速排序（Quicksort）是对冒泡排序的一种改进，借用了分治的思想，由 C. A. R. Hoare 在 1962 年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列. 具体步骤 快速排序使用分治策略来把一个序列（list）分为两个子序列（sub-lists）。 ①. 从数列中挑出一个元素，称为” 基准”（pivot）。 ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 ③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 123456789101112131415161718192021222324252627282930313233/** * 快速排序 * 时间复杂度为O(nlogn) 空间复杂度为O(1) */ public static void quickSort(int[] arr, int start, int end) &#123; if (start &lt; end) &#123; int baseNum = arr[start];//选基准值 int midNum;//记录中间值 int left = start;//左指针 int right = end;//右指针 while(left&lt;right)&#123; while ((arr[left] &lt; baseNum) &amp;&amp; left &lt; end) &#123; left++; &#125; while ((arr[right] &gt; baseNum) &amp;&amp; right &gt; start) &#123; right--; &#125; if (left &lt;= right) &#123; midNum = arr[left]; arr[left] = arr[right]; arr[right] = midNum; left++; right--; &#125; &#125; if (start &lt; right) &#123; quickSort(arr, start, right); &#125; if (end &gt; left) &#123; quickSort(arr, left, end); &#125; &#125; &#125; 3. 插入排序直接插入排序（Straight Insertion Sorting）的基本思想：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过为止。 首先设定插入次数，即循环次数，for(int i=1;i&lt;length;i++)，1 个数的那次不用插入。 设定插入数和得到已经排好序列的最后一个数的位数。insertNum 和 j=i-1。 从最后一个数开始向前循环，如果插入数小于当前数，就将当前数向后移动一位。 将当前数放置到空着的位置，即 j+1。 12345678910111213141516/** * 直接插入排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void straightInsertion(int[] arr) &#123; int current;//要插入的数 for (int i = 1; i &lt; arr.length; i++) &#123; //从1开始 第一次一个数不需要排序 current = arr[i]; int j = i - 1;//序列元素个数 while (j &gt;= 0 &amp;&amp; arr[j] &gt; current) &#123;//从后往前循环，将大于当前插入数的向后移动 arr[j + 1] = arr[j];//元素向后移动 j--; &#125; arr[j + 1] = current;//找到位置，插入当前元素 &#125;&#125; 4. 希尔排序是插入排序的一种高速而稳定的改进版本。 希尔排序是先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录 “基本有序” 时，再对全体记录进行依次直接插入排序。 123456789101112131415161718192021/** * 希尔排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void shellSort(int[] arr) &#123; int gap = arr.length / 2; for (; gap &gt; 0; gap = gap / 2) &#123; //不断缩小gap，直到1为止 for (int j = 0; (j + gap) &lt; arr.length; j++) &#123; //使用当前gap进行组内插入排序 for (int k = 0; (k + gap) &lt; arr.length; k += gap) &#123; if (arr[k] &gt; arr[k + gap]) &#123; //交换操作 int temp = arr[k]; arr[k] = arr[k + gap]; arr[k + gap] = temp; &#125; &#125; &#125; &#125;&#125; 5. 选择排序遍历整个序列，将最小的数放在最前面。 遍历剩下的序列，将最小的数放在最前面。 重复第二步，直到只剩下一个数。 12345678910111213141516171819/** * 选择排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void selectSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; //循环次数 int min = arr[i];//等会用来放最小值 int index = i;//用来放最小值的索引 for (int j = i + 1; j &lt; arr.length; j++) &#123; //找到最小值 if (arr[j] &lt; min) &#123; min = arr[j]; index = j; &#125; &#125; //内层循环结束后进行交换 arr[index] = arr[i];//当前值放到最小值所在位置 arr[i] = min;//当前位置放最小值 &#125;&#125; 6. 堆排序对简单选择排序的优化。 将序列构建成大顶堆。 将根节点与最后一个节点交换，然后断开最后一个节点。 重复第一、二步，直到所有节点断开。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void heapSort(int[] a)&#123; int len=a.length; //循环建堆 for(int i=0;i&lt;len-1;i++)&#123; //建堆 buildMaxHeap(a,len-1-i); //交换堆顶和最后一个元素 swap(a,0,len-1-i); &#125; &#125; //交换方法 private void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125; //对data数组从0到lastIndex建大顶堆 private void buildMaxHeap(int[] data, int lastIndex) &#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; 7. 归并排序速度仅次于快速排序，内存少的时候使用，可以进行并行计算的时候使用。 选择相邻两个数组成一个有序序列。 选择相邻的两个有序序列组成一个有序序列。 重复第二步，直到全部组成一个有序序列。 1234567891011121314151617181920212223242526272829303132333435363738public void mergeSort(int[] a, int left, int right) &#123; int t = 1;// 每组元素个数 int size = right - left + 1; while (t &lt; size) &#123; int s = t;// 本次循环每组元素个数 t = 2 * s; int i = left; while (i + (t - 1) &lt; size) &#123; merge(a, i, i + (s - 1), i + (t - 1)); i += t; &#125; if (i + (s - 1) &lt; right) merge(a, i, i + (s - 1), right); &#125; &#125; private static void merge(int[] data, int p, int q, int r) &#123; int[] B = new int[data.length]; int s = p; int t = q + 1; int k = p; while (s &lt;= q &amp;&amp; t &lt;= r) &#123; if (data[s] &lt;= data[t]) &#123; B[k] = data[s]; s++; &#125; else &#123; B[k] = data[t]; t++; &#125; k++; &#125; if (s == q + 1) B[k++] = data[t++]; else B[k++] = data[s++]; for (int i = p; i &lt;= r; i++) data[i] = B[i]; &#125; 8. 基数排序用于大量数，很长的数进行排序时。 将所有的数的个位数取出，按照个位数进行排序，构成一个序列。 将新构成的所有的数的十位数取出，按照十位数进行排序，构成一个序列。 123456789101112131415161718192021222324252627282930313233343536373839404142public void baseSort(int[] a) &#123; //首先确定排序的趟数; int max = a[0]; for (int i = 1; i &lt; a.length; i++) &#123; if (a[i] &gt; max) &#123; max = a[i]; &#125; &#125; int time = 0; //判断位数; while (max &gt; 0) &#123; max /= 10; time++; &#125; //建立10个队列; List&lt;ArrayList&lt;Integer&gt;&gt; queue = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); &#125; //进行time次分配和收集; for (int i = 0; i &lt; time; i++) &#123; //分配数组元素; for (int j = 0; j &lt; a.length; j++) &#123; //得到数字的第time+1位数; int x = a[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(a[j]); queue.set(x, queue2); &#125; int count = 0;//元素计数器; //收集队列元素; for (int k = 0; k &lt; 10; k++) &#123; while (queue.get(k).size() &gt; 0) &#123; ArrayList&lt;Integer&gt; queue3 = queue.get(k); a[count] = queue3.get(0); queue3.remove(0); count++; &#125; &#125; &#125; &#125; 排序法平均时间最小时间最大时间稳定度额外空间备注冒泡排序O(n2)O(n)O(n2)稳定O(1)n 小时较好选择排序O(n2)O(n2)O(n2)不稳定O(1)n 小时较好插入排序O(n2)O(n)O(n2)稳定O(1)大部分已排序时较好基数排序O(logRB)O(n)O(logRB)稳定O(n)B 是真数 (0-9)，R 是基数 (个十百)Shell 排序O(nlogn)- O(ns) 不稳定O(1)s 是所选分组快速排序O(nlogn)O(n2)O(n2)不稳定O(logn)n 大时较好归并排序O(nlogn)O(nlogn)O(nlogn)稳定O(n)要求稳定性时较好堆排序O(nlogn)O(nlogn)O(nlogn)不稳定O(1)n 大时较好","tags":["algorithm","sort","排序"],"categories":["algorithm"]},{"title":"常见思维题三","path":"/algorithm/algo3/","content":"赛马问题一般有这么几种问法： 25匹马5条跑道找最快的3匹马，需要跑几次？ 7 25匹马5条跑道找最快的5匹马，需要跑几次？ 8/9 64匹马8条跑道找最快的4匹马，需要跑几次？ 11 答案25匹马5条跑道找最快的3匹马，需要跑几次？将马分成A、B、C、D、E五组。第1-5次比赛：各组分别进行比赛，决出各组名次,取每组前三名12345A1、A2、A3，B1、B2、B3，C1、C2、C3，D1、D2、D3，E1、E2、E3。第6次比赛：A1、B1、C1、D1、E1，假设得到的结果是A1、B1、C1、D1、E1，A1是跑的最快的，那么分析A组A2、A3还有希望冲进前3，B组呢？只有B2还有希望冲进前3，C组的C1还有希望冲进前3，C2并没有希望冲进前3了，因为C1是比赛的名次是第3名了，D组E组都没有希望了。现在已经知道A1肯定是第一名，剩下A2、A3、B1、B2、C1是有希望冲进前三的。第7次比赛：A2、A3、B1、B2、C1比赛求出第2，第3即可。25匹马5条跑道找最快的5匹马，需要跑几次？(1) 首先将25匹马分成5组，并分别进行5场比赛之后得到的名次排列如下：A组： [A1 A2 A3 A4 A5]B组： [B1 B2 B3 B4 B5]C组： [C1 C2 C3 C4 C5]D组： [D1 D2 D3 D4 D5]E组： [E1 E2 E3 E4 E5]其中，每个小组最快的马为[A1、B1、C1、D1、E1]。(2) 将[A1、B1、C1、D1、E1]进行第6场，选出第1名的马，不妨设 A1&gt;B1&gt;C1&gt;D1&gt;E1. 此时第1名的马为A1。(3) 将[A2、B1、C1、D1、E1]进行第7场，此时选择出来的必定是第2名的马，不妨假设为B1。因为这5匹马是除去A1之外每个小组当前最快的马。(3) 进行第8场，选择[A2、B2、C1、D1、E1]角逐出第3名的马。(4) 依次类推，第9，10场可以分别决出第4，5名因此，依照这种竞标赛排序思想，需要10场比赛是一定可以取出前5名的。仔细想一下，如果需要减少比赛场次，就一定需要在某一次比赛中同时决出2个名次，而且每一场比赛之后，有一些不可能进入前5名的马可以提前出局。 当然要做到这一点，就必须小心选择每一场比赛的马匹。我们在上面的方法基础上进一步思考这个问题，希望能够得到解决。优化解法(1) 首先利用5场比赛角逐出每个小组的排名次序是绝对必要的。(2) 第6场比赛选出第1名的马也是必不可少的。假如仍然是A1马(A1&gt;B1&gt;C1&gt;D1&gt;E1)。那么此时我们可以得到一个重要的结论：有一些马在前6场比赛之后就决定出局的命运了(下面粉色字体标志出局)。A组： [A1 A2 A3 A4 A5]B组： [B1 B2 B3 B4 B5 ]C组： [C1 C2 C3 C4 C5 ]D组： [D1 D2 D3 D4 D5 ]E组： [E1 E2 E3 E4 E5 ](3) 第7场比赛是关键，能否同时决出第2，3名的马呢？我们首先做下分析：在上面的方法中，第7场比赛[A2、B1、C1、D1、E1]是为了决定第2名的马。但是在第6场比赛中我们已经得到(B1&gt;C1&gt;D1&gt;E1)，试问？有B1在的比赛，C1、D1、E1还有可能争夺第2名吗？ 当然不可能，也就是说第2名只能在A2、B1中出现。实际上只需要2条跑道就可以决出第2名，剩下C1、D1、E1的3条跑道都只能用来凑热闹的吗？能够优化的关键出来了，我们是否能够通过剩下的3个跑道来决出第3名呢？当然可以，我们来进一步分析第3名的情况？如果A2&gt;B1(即第2名为A2)，那么根据第6场比赛中的(B1&gt;C1&gt;D1&gt;E1)。 可以断定第3名只能在A3和B1中产生。如果B1&gt;A2(即第2名为B1)，那么可以断定的第3名只能在A2, B2,C1 中产生。好了，结论也出来了，只要我们把[A2、B1、A3、B2、C1]作为第7场比赛的马，那么这场比赛的第2，3名一定是整个25匹马中的第2，3名。我们在这里列举出第7场的2，3名次的所有可能情况：第2名=A2，第3名=A3第2名=A2，第3名=B1第2名=B1，第3名=A2第2名=B1，第3名=B2第2名=B1，第3名=C1(4) 第8场比赛很复杂，我们要根据第7场的所有可能的比赛情况进行分析。① 第2名=A2，第3名=A3。那么此种情况下第4名只能在A4和B1中产生。如果第4名=A4，那么第5名只能在A5、B1中产生。如果第4名=B1，那么第5名只能在A4、B2、C1中产生。不管结果如何，此种情况下，第4、5名都可以在第8场比赛中决出。其中比赛马匹为[A4、A5、B1、B2、C1]② 第2名=A2，第3名=B1。那么此种情况下第4名只能在A3、B2、C1中产生。如果第4名=A3，那么第5名只能在A4、B2、C1中产生。如果第4名=B2，那么第5名只能在A3、B3、C1中产生。如果第4名=C1，那么第5名只能在A3、B2、C2、D1中产生。那么，第4、5名需要在马匹[A3、B2、B3、C1、A4、C2、D1]七匹马中产生，则必须比赛两场才行，也就是到第9场角逐出全部的前5名。③ 第2名=B1，第3名=A2。那么此种情况下第4名只能在A3、B2、C1中产生。情况和②一样，必须角逐第9场④ 第2名=B1，第3名=B2。 那么此种情况下第4名只能在A2、B3、C1中产生。如果第4名=A2，那么第5名只能在A3、B3、C1中产生。如果第4名=B3，那么第5名只能在A2、B4、C1中产生。如果第4名=C1，那么第5名只能在A2、B3、C2、D1中产生。那么，第4、5名需要在马匹[A2、B3、B4、C1、A3、C2、D1]七匹马中产 生，则必须比赛两场才行，也就是到第9场角逐出全部的前5名。⑤ 第2名=B1，第3名=C1。那么此种情况下第4名只能在A2、B2、C2、D1中产生。如果第4名=A2，那么第5名只能在A3、B2、C2、D1中产生。如果第4名=B2，那么第5名只能在A2、B3、C2、D1中产生。如果第4名=C2，那么第5名只能在A2、B2、C3、D1中产生。如果第4名=D1，那么第5名只能在A2、B2、C2、D2、E2中产生。那么，第4、5名需要在马匹[A2、B2、C2、D1、A3、B3、C3、D2、E1]九匹马中 产 生，因此也必须比赛两场，也就是到第9长决出胜负。总结：最好情况可以在第8场角逐出前5名，最差也可以在第9场搞定。64匹马8条跑道找最快的4匹马，需要跑几次？第一步全部马分为8组，每组8匹，每组各跑一次，然后淘汰掉每组的后四名，如下图（需要比赛8场）第二步取每组第一名进行一次比赛，然后淘汰最后四名所在组的所有马，如下图（需要比赛1场）这个时候总冠军已经诞生，它就是A1，蓝域（它不需要比赛了），而其他可能跑得最快的三匹马只可能是下图中的黄域了（A2,A3,A4,B1,B2,B3,C1,C2,D1，共9匹马）第三步只要从上面的9匹马中找出跑得最快的三匹马就可以了，但是现在只要8个跑道，怎么办？那就随机选出8匹马进行一次比赛吧（需要比赛一场）第四步上面比赛完，选出了前三名，但是9匹马中还有一匹马没跑呢，它可能是一个潜力股啊，那就和前三名比一比吧，这四匹马比一场，选出前三名。最后加上总冠军，跑得最快的四匹马诞生了！！！（需要一场比赛）最后，一共需要比赛的场次：8 + 1 + 1 + 1 = 11 场来源：https://blog.csdn.net/u013829973/article/details/80787928 砝码称轻重这一类的题目有很多 这里只举几个经典的： 有一个天平，九个砝码，其中一个砝码比另八个要轻一些，问至少要用天平称几次才能将轻的那个找出来？ 十组砝码每组十个，每个砝码都是10g重，但是现在其中有一组砝码每个都只有9g重，现有一个能显示克数的秤，最少称几次能找到轻的那组？ 答案问题一：至少2次：第一次，一边3个，哪边轻就在哪边，一样重就是剩余的3个；第二次，一边1个，哪边轻就是哪个，一样重就是剩余的那个；答：至少称2次．问题二：将砝码分组1~10，第一组拿一个，第二组拿两个以此类推。。第十组拿十个放到秤上称出克数x，则y = 550 - x，第y组就是轻的那组 药瓶毒白鼠有1000个一模一样的瓶子，其中有999瓶是普通的水，有1瓶是毒药。任何喝下毒药的生命都会在一星期之后死亡。现在你只有10只小白鼠和1个星期的时间，如何检验出哪个瓶子有毒药？ 答案首先一共有1000瓶，2的10次方是1024，刚好大于1000，也就是说，1000瓶药品可以使用10位二进制数就可以表示。从第一个开始：第一瓶 ： 00 0000 0001第二瓶： 00 0000 0010第三瓶： 00 0000 0011……第999瓶： 11 1111 0010第1000瓶： 11 1111 0011需要十只老鼠，如果按顺序编号，ABCDEFGHIJ分别代表从低位到高位每一个位。 每只老鼠对应一个二进制位，如果该位上的数字为1，则给老鼠喝瓶里的药。观察，若死亡的老鼠编号为：ACFGJ，一共死去五只老鼠，则对应的编号为 10 0110 0101，则有毒的药品为该编号的药品，转为十进制数为：613号。 绳子两头烧现有若干不均匀的绳子，烧完这根绳子需要一个小时，问如何准确计时15分钟，30分钟，45分钟，75分钟。。。 答案15：对折之后两头烧(要求对折之后绑的够紧，否则看45分钟解法)30：两头烧45：两根，一根两头烧一根一头烧，两头烧完过了30分钟，立即将第二根另一头点燃，到烧完又过15分钟，加起来45分钟75：= 30 + 45 犯人猜颜色一百个犯人站成一纵列，每人头上随机带上黑色或白色的帽子，各人不知道自己帽子的颜色，但是能看见自己前面所有人帽子的颜色． 然后从最后一个犯人开始，每人只能用同一种声调和音量说一个字：”黑”或”白”， 如果说中了自己帽子的颜色，就存活，说错了就拉出去斩了， 说的答案所有犯人都能听见， 是否说对，其他犯人不知道， 在这之前，所有犯人可以聚在一起商量策略， 问如果犯人都足够聪明而且反应足够快，100个人最大存活率是多少？ 答案1、最后一个人如果看到奇数顶黑帽子报“黑”否则报“白”，他可能死2、其他人记住这个值（实际是黑帽奇偶数），在此之后当再听到黑时，黑帽数量减一3、从倒数第二人开始，就有两个信息：记住的值与看到的值，相同报“白”，不同报“黑”99人能100%存活，1人50%能活除此以外，此题还有变种：每个犯人只能看见前面一个人帽子颜色又能最多存活多少人？答案：在上题基础上，限制了条件，这时上次的方法就不管用了，此时只能约定偶数位犯人说他前一个人的帽子颜色，奇数犯人获取信息100%存活，偶数犯人50几率存活。 猴子搬香蕉一个小猴子边上有100根香蕉，它要走过50米才能到家，每次它最多搬50根香蕉，（多了就被压死了），它每走 1 米就要吃掉一根，请问它最多能把多少根香蕉搬到家里。 （提示：他可以把香蕉放下往返的走，但是必须保证它每走一米都能有香蕉吃。也可以走到n米时，放下一些香蕉，拿着n根香蕉走回去重新搬50根。） 答案这种试题通常有一个迷惑点，让人看不懂题目的意图。此题迷惑点在于：走一米吃一根香蕉，一共走50米，那不是把50根香蕉吃完了吗？如果要回去搬另外50根香蕉，则往回走的时候也要吃香蕉，这样每走一米需要吃掉三根香蕉，走50米岂不是需要150根香蕉？其实不然，本题关键点在于：猴子搬箱子的过程其实分为两个阶段，第一阶段：来回搬，当香蕉数目大于50根时，猴子每搬一米需要吃掉三根香蕉。第二阶段：香蕉数《=50，直接搬回去。每走一米吃掉1根。我们分析第一阶段：假如把100根香蕉分为两箱。一箱50根。第一步，把A箱搬一米，吃一根。第二步，往回走一米，吃一根。第三步，把B箱搬一米，吃一根。这样，把所有香蕉搬走一米需要吃掉三根香蕉。这样走到第几米的时候，香蕉数刚好小于50呢？100-(n*3)&lt;50 &amp;&amp; 100-(n-1*3)&gt;50走到16米的时候，吃掉48根香蕉，剩52根香蕉。这步很有意思，它可以直接搬50往前走，也可以再来回搬一次，但结果都是一样的。到17米的时候，猴子还有49根香蕉。这时猴子就轻松啦。直接背着走就行。第二阶段：走一米吃一根。把剩下的50-17=33米走完。还剩49-33=16根香蕉。 高楼扔鸡蛋有2个鸡蛋，从100层楼上往下扔，以此来测试鸡蛋的硬度。比如鸡蛋在第9层没有摔碎，在第10层摔碎了，那么鸡蛋不会摔碎的临界点就是9层。 问：如何用最少的尝试次数，测试出鸡蛋不会摔碎的临界点？ 答案暴力法举个栗子，最笨的测试方法，是什么样的呢？把其中一个鸡蛋，从第1层开始往下扔。如果在第1层没碎，换到第2层扔；如果在第2层没碎，换到第3层扔…….如果第59层没碎，换到第60层扔；如果第60层碎了，说明不会摔碎的临界点是第59层。在最坏情况下，这个方法需要扔100次。二分法采用类似于二分查找的方法，把鸡蛋从一半楼层（50层）往下扔。如果第一枚鸡蛋，在50层碎了，第二枚鸡蛋，就从第1层开始扔，一层一层增长，一直扔到第49层。如果第一枚鸡蛋在50层没碎了，则继续使用二分法，在剩余楼层的一半（75层）往下扔……这个方法在最坏情况下，需要尝试50次。均匀法如何让第一枚鸡蛋和第二枚鸡蛋的尝试次数，尽可能均衡呢？很简单，做一个平方根运算，100的平方根是10。因此，我们尝试每10层扔一次，第一次从10层扔，第二次从20层扔，第三次从30层……一直扔到100层。这样的最好情况是在第10层碎掉，尝试次数为 1 + 9 = 10次。最坏的情况是在第100层碎掉，尝试次数为 10 + 9 = 19次。不过，这里有一个小小的优化点，我们可以从15层开始扔，接下来从25层、35层扔……一直到95层。这样最坏情况是在第95层碎掉，尝试次数为 9 + 9 = 18次。最优解法最优解法是反向思考的经典：如果最优解法在最坏情况下需要扔X次，那第一次在第几层扔最好呢？答案是：从X层扔假设最优的尝试次数的x次，为什么第一次扔就要选择第x层呢？这里的解释会有些烧脑，请小伙伴们坐稳扶好：假设第一次扔在第x+1层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x层。这样一来，我们总共尝试了x+1次，和假设尝试x次相悖。由此可见，第一次扔的楼层必须小于x+1层。假设第一次扔在第x-1层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-2层。这样一来，我们总共尝试了x-2+1 = x-1次，虽然没有超出假设次数，但似乎有些过于保守。假设第一次扔在第x层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-1层。这样一来，我们总共尝试了x-1+1 = x次，刚刚好没有超出假设次数。因此，要想尽量楼层跨度大一些，又要保证不超过假设的尝试次数x，那么第一次扔鸡蛋的最优选择就是第x层。那么算最坏情况，第二次你只剩下x-1次机会，按照上面的说法，你第二次尝试的位置必然是X+（X-1）；以此类推我们可得：x + (x-1) + (x-2) + … + 1 = 100这个方程式不难理解：左边的多项式是各次扔鸡蛋的楼层跨度之和。由于假设尝试x次，所以这个多项式共有x项。右边是总的楼层数100。下面我们来解这个方程：x + (x-1) + (x-2) + … + 1 = 100 转化为(x+1)*x/2 = 100最终x向上取整，得到 x = 14因此，最优解在最坏情况的尝试次数是14次，第一次扔鸡蛋的楼层也是14层。最后，让我们把第一个鸡蛋没碎的情况下，所尝试的楼层数完整列举出来：14，27， 39， 50， 60， 69， 77， 84， 90， 95， 99， 100举个栗子验证下：假如鸡蛋不会碎的临界点是65层，那么第一个鸡蛋扔出的楼层是14，27，50，60，69。这时候啪的一声碎了。第二个鸡蛋继续，从61层开始，61，62，63，64，65，66，啪的一声碎了。因此得到不会碎的临界点65层，总尝试次数是 6 + 6 = 12 &lt; 14 。 轮流拿石子问题：一共有N颗石子（或者其他乱七八糟的东西），每次最多取M颗最少取1颗，A，B轮流取，谁最后会获胜？（假设他们每次都取最优解）。 答案：简单的巴什博奕：https://www.cnblogs.com/StrayWolf/p/5396427.html 问题：有若干堆石子，每堆石子的数量是有限的，二个人依次从这些石子堆中拿取任意的石子，至少一个（不能不取），最后一个拿光石子的人胜利。 答案：较复杂的尼姆博弈：https://blog.csdn.net/BBHHTT/article/details/80199541 蚂蚁走树枝放N只蚂蚁在一条长度为M树枝上，蚂蚁与蚂蚁之间碰到就各自往反方向走，问总距离或者时间。 答案：这个其实就一个诀窍：蚂蚁相碰就往反方向走，可以直接看做没有发生任何事：大家都相当于独立的 A蚂蚁与B蚂蚁相碰后你可以看做没有发生这次碰撞，这样无论是求时间还是距离都很简单了。 海盗分金币5个海盗抢到了100枚金币，每一颗都一样的大小和价值。 他们决定这么分： 抽签决定自己的号码（1，2，3，4，5） 首先，由1号提出分配方案，然后大家5人进行表决，当半数以上的人同意时（ 不包括半数，这是重点），按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 如果1号死后，再由2号提出分配方案，然后大家4人进行表决，当且仅当半超过半数的人同意时，按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 依次类推…… 假设每一位海盗都足够聪明，并且利益至上，能多分一枚金币绝不少分，那么1号海盗该怎么分金币才能使自己分到最多的金币呢？ 答案从后向前推，如果1至3号强盗都喂了鲨鱼，只剩4号和5号的话，5号一定投反对票让4号喂鲨鱼，以独吞全部金币。所以，4号惟有支持3号才能保命。3号知道这一点，就会提出“100，0，0”的分配方案，对4号、5号一毛不拔而将全部金币归为已有，因为他知道4号一无所获但还是会投赞成票，再加上自己一票，他的方案即可通过。不过，2号推知3号的方案，就会提出“98，0，1，1”的方案，即放弃3号，而给予4号和5号各一枚金币。由于该方案对于4号和5号来说比在3号分配时更为有利，他们将支持他而不希望他出局而由3号来分配。这样，2号将拿走98枚金币。同样，2号的方案也会被1号所洞悉，1号并将提出（97，0，1，2，0）或（97，0，1，0，2）的方案，即放弃2号，而给3号一枚金币，同时给4号（或5号）2枚金币。由于1号的这一方案对于3号和4号（或5号）来说，相比2号分配时更优，他们将投1号的赞成票，再加上1号自己的票，1号的方案可获通过，97枚金币可轻松落入囊中。这无疑是1号能够获取最大收益的方案了！答案是：1号强盗分给3号1枚金币，分给4号或5号强盗2枚，自己独得97枚。分配方案可写成（97，0，1，2，0）或（97，0，1，0，2）。此题还有变种： 就是只需要一半人同意即可，不需要一半人以上同意方案就可以通过，在其他条件不变的情况下，1号该怎么分配才能获得最多的金币？答案：类似的推理过程4号：4号提出的方案的时候肯定是最终方案，因为不管5号同意不同意都能通过，所以4号5号不必担心自己被投入大海。那此时5号获得的金币为0，4号获得的金币为100。5号：因为4号提方案的时候 ，自己获取的金币为0 。所以只要4号之前的人分配给自己的金币大于0就同意该方案。4号：如果3号提的方案一定能获得通过（原因：3号给5号的金币大于0， 5号就同意 因此就能通过），那自己获得的金币就为0，所以只要2号让自己获得的金币大于0就会同意。3号：因为到了自己提方案的时候可以给5号一金币，自己的方案就能通过，但考虑到2号提方案的时候给4号一个金币，2号的方案就会通过，那自己获得的金币就为0。所以只要1号让自己获得的金币大于0就会同意。2号：因为到了自己提方案的时候只要给4号一金币，就能获得通过，根本就不用顾及3 号 5号同意不同意，所以不管1号怎么提都不会同意。1号：2号肯定不会同意。但只要给3号一块金币，5号一块金币（因为5号如果不同意，那么4号分配的时候，他什么都拿不到）就能获得通过。所以答案是 98，0，1，0，1。类似的问题也可用类似的推理，并不难 三个火枪手彼此痛恨的甲、乙、丙三个枪手准备决斗。甲枪法最好，十发八中；乙枪法次之，十发六中；丙枪法最差，十发四中。如果三人同时开枪，并且每人每轮只发一枪；那么枪战后，谁活下来的机会大一些？ 答案一般人认为甲的枪法好，活下来的可能性大一些。但合乎推理的结论是，枪法最糟糕的丙活下来的几率最大。那么我们先来分析一下各个枪手的策略。如同田忌赛马一般，枪手甲一定要对枪手乙先开枪。因为乙对甲的威胁要比丙对甲的威胁更大，甲应该首先干掉乙，这是甲的最佳策略。同样的道理，枪手乙的最佳策略是第一枪瞄准甲。乙一旦将甲干掉，乙和丙进行对决，乙胜算的概率自然大很多。枪手丙的最佳策略也是先对甲开枪。乙的枪法毕竟比甲差一些，丙先把甲干掉再与乙进行对决，丙的存活概率还是要高一些。我们根据分析来计算一下三个枪手在上述情况下的存活几率：第一轮：甲射乙，乙射甲，丙射甲。甲的活率为24%（40% X 60%）乙的活率为20%(100% - 80%)丙的活率为100%（无人射丙）。由于丙100％存活率，因此根据上轮甲乙存活的情况来计算三人第二轮的存活几率：情况1：甲活乙死（24% X 80% = 19.2%）甲射丙，丙射甲：甲的活率为60%，丙的活率为20%。情况2：乙活甲死（20% X 76% = 15.2%）乙射丙，丙射乙：乙的活率为60%，丙的活率为40%。情况3：甲乙同活（24% X 20% = 4.8%）重复第一轮。情况4：甲乙同死（76% X 80% = 60.8%）枪战结束。据此来计算三人活率：甲的活率为(19.2% X 60%) + (4.8% X 24%) = 12.672%乙的活率为(15.2% X 60%) + (4.8% X 20%) = 10.08%丙的活率为(19.2% X 20%) + (15.2% X 40%) + (4.8% X 100%) + (60.8% X 100%) = 75.52%通过对两轮枪战的详细概率计算，我们发现枪法最差的丙存活的几率最大，枪法较好的甲和乙的存活几率却远低于丙的存活几率。来自：https://www.zhihu.com/question/288093713/answer/482192781 囚犯拿豆子有5个囚犯被***，他们请求上诉，于是法官愿意给他们一个机会。 犯人抽签分好顺序，按序每人从100粒豆子中随意抓取，最多可以全抓，最少可以不抓，可以和别人抓的一样多。 最终，抓的最多的和最少的要被处死。 他们都是非常聪明且自私的人。 他们的原则是先求保命。如果不能保命，就拉人陪葬。 100颗不必都分完。 若有重复的情况，则也算最大或最小，一并处死（中间重复不算）。 假设每个犯人都足够聪明，但每个犯人并不知道其他犯人足够聪明。那么，谁活下来的可能性最大？ 答案不存在“谁活下来的可能性比较大”的问题。实际情况是5个人都要死。答案看起来很扯淡，但推理分析后却发现十分符合逻辑。根据题意，一号知道有五个人抓豆子，为保性命，他只要让豆子在20颗以内就可以了。但是他足够聪明的话他一定拿20颗，因为无论多拿一颗：2,3,4号的人一定会拿20颗最后死的人就会是最多的1号和最少的5号 还是少拿一颗：2,3,4号拿20个后，5号选择也拿20个拉上1234号垫背。（下面会说为什么多拿少拿也只会相差一颗）2号是知道1号抓了几颗豆子(20)的。那么，对于2号来说，只有2种选择：与1号一样多，或者不一样多。我们就从这里入手。情况一，假如2号选择与1号的豆子数不一样多，也就是说2号选择比1号多或者比1号少。我们先要证明，如果2号选择比1号多或者比1号少，那么他一定会选择比1号只多1颗或者只少1颗。要证明这个并不算太难。因为每个囚犯的第一选择是先求保命，要保命就要尽量使自己的豆子数既不是最多也不是最少。当2号决定选择比1号多的时候，他已经可以保证自己不是最少，为了尽量使自己不是最多，当然比1号多出来的数量越小越好。因为这个数量如果与一号相差大于1的话，那么3号就有机会抓到的居中数，相差越大，二号成为最多的可能性也就越大。反之，当2号决定选择比1号少的时候，也是同样的道理，他会选择只比1号少1颗。既然2号只会会选择比1号多1颗或者比1号少1颗，那么1、2号的豆子数一定是2个连续的自然数，和一定是2n+1（其中1个人是n,另1人是n+1）。轮到3号的时候，他可以从剩下的豆子数知道1、2号的数量和，也就不难计算出n的值。而3号也只有2个选择：n颗或者n+1颗。为什么呢？这与上面的证明是一样的道理，保命原则，取最接近的数量，这里不再赘述。不过，3号选择的时候会有一个特殊情况，在这一情况下，他一定会选择较小的n，而不是较大的n+1。这一特殊情况就是，当3号知道自己选择了n后(已保证自己不是最多)，剩下的豆子数由于数量有限，4、5号中一定有人比n要少，这样自己一定可以活下来。计算的话就是 [100-(3n+1)]/2&lt;=n ，不难算出，在这个特殊情况下，n&gt;=20。也就是说，当1、2号选择了20或21颗的时候，3号只要选择20颗，就可以保证自己活下来。这样一来剩下的豆子只剩39颗，4、5号至少有一人少于20颗的（这个人当然是后选的5号），这样死的将是5号和1、2号中选21颗的那个人。当然，1号、2号肯定不会有人选择21这一“倒霉”的数字（因为他们都是聪明人），这样的话，上述“特殊情况（即3号选择n）”就不会发生了。综上所述，2345这四个人不难从剩下的豆子数知道前面几个人的数量总和，也就不难进而计算出n的值，而这样一来他们也只有n或者n+1这两种选择。最后的5号也是不难算出n的。在前4个人只选择了2个数字(n和n+1)的情况下，5号已是必死无疑，这时,根据“死也要拉几个垫背”的条件，5号会选择n或n+1，选择5个人一起完蛋。情况二，如果2号选择了与1号不一样多的话，最终结果是5个人一起死，那么2号只有选择与1号一样多了。那么1、2号的和就是2n，而3号如果选择n+1或者n -1的话，就又回到第一点的情况去了(前3个人的和是3m+1或3m+2)，于是3号也只能选择n ，当然，4号还是只能选n，最后的结果仍旧是5个人一起完蛋。“最后处死抓的最多和最少的囚犯”严格执行这句话的话，除非有人舍己为人，死二留三。但这是足够聪明且自私的囚犯，所以这五个聪明人的下场是全死，这道题只不过是找了一个处死所有人的借口罢了. . . . . .变种问题：如果每个囚犯都知道其他囚犯足够聪明，事情会怎么发展？答案：这样的情况下囚犯一也会像我们一样推导出前面的结论，那么根据自私的规定，他会直接拿完100个，大家一起完蛋(反正结局已定) 学生猜生日这种题目笔试中出现的次数比较多，用排除法比较好解决 小明和小强都是张老师的学生，张老师的生日是M月N日, 2人都知道张老师的生日是下列10组中的一天，张老师把M值告诉了小明, 把N值告诉了小强，张老师问他们知道他的生日是那一天吗? 3月4日 3月5日 3月8日 6月4日 6月7日 9月1日 9月5日 12月1日 12月2日 12月8日 小明说:如果我不知道的话，小强肯定也不知道. 小强说:本来我也不知道，但是现在我知道了. 小明说:哦，那我也知道了. 请根据以上对话推断出张老师的生日是哪一天? 答案排除法：1.小明肯定小强不知道是哪天，排除所有月份里有单独日的月份：6月和12月&lt;因为如果小强的M是2或者7的话，小强就知道了，所以把6月7日与12月2日排除&gt;，所以小明拿到的是3或者92.小强本来不知道，所以小强拿到的不是2或者7，但是小强现在知道了，说明把6月与12月排除后，小强拿到的是1,4,8中的一个&lt;这里小强肯定没拿到5，否则他不会知道是哪天的&gt;3.小明现在也知道了，说明小明拿到的不是3，否则他不会知道是3月4日还是3月8日的，所以小明拿到的是9才能唯一确定生日综上，答案是9月1日 小明和小强是赵老师的学生，张老师的生日是M月N日，张老师 把M值告诉小明，N值告诉小强 给他们六个选项 3月1日 3月3日 7月3日 7月5日 9月1日 11月7日 小明说:我猜不出来 小强说:本来我也猜不出来，但是现在我知道了 问:张老师生日多少 答案：3月1日 答案排除法：1.小明说猜不出来，说明小明拿到的不是单独出现的9或者11，说明老师生日只能是3月或者7月2.小强原本不知道，说明小强拿到的不是单独出现的5或者7，说明老是生日是1日或3日3.小强现在知道了，说明小强拿到的是1，因为如果拿到的是3，那么小强就不知道是3月3日还是7月3日了综上，老师生日是3月1日 参考文章： https://www.nowcoder.com/discuss/262595","tags":["智力题","algorithm"],"categories":["algorithm"]},{"title":"常见思维题二","path":"/algorithm/algo2/","content":"轮流拿石子问题：一共有N颗石子（或者其他乱七八糟的东西），每次最多取M颗最少取1颗，A，B轮流取，谁最后会获胜？（假设他们每次都取最优解）。 答案：简单的巴什博奕：https://www.cnblogs.com/StrayWolf/p/5396427.html 问题：有若干堆石子，每堆石子的数量是有限的，二个人依次从这些石子堆中拿取任意的石子，至少一个（不能不取），最后一个拿光石子的人胜利。 答案：较复杂的尼姆博弈：https://blog.csdn.net/BBHHTT/article/details/80199541 蚂蚁走树枝放N只蚂蚁在一条长度为M树枝上，蚂蚁与蚂蚁之间碰到就各自往反方向走，问总距离或者时间。 答案：这个其实就一个诀窍：蚂蚁相碰就往反方向走，可以直接看做没有发生任何事：大家都相当于独立的 A蚂蚁与B蚂蚁相碰后你可以看做没有发生这次碰撞，这样无论是求时间还是距离都很简单了。 海盗分金币5个海盗抢到了100枚金币，每一颗都一样的大小和价值。 他们决定这么分： 抽签决定自己的号码（1，2，3，4，5） 首先，由1号提出分配方案，然后大家5人进行表决，当半数以上的人同意时（ 不包括半数，这是重点），按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 如果1号死后，再由2号提出分配方案，然后大家4人进行表决，当且仅当半超过半数的人同意时，按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 依次类推…… 假设每一位海盗都足够聪明，并且利益至上，能多分一枚金币绝不少分，那么1号海盗该怎么分金币才能使自己分到最多的金币呢？ 答案从后向前推，如果1至3号强盗都喂了鲨鱼，只剩4号和5号的话，5号一定投反对票让4号喂鲨鱼，以独吞全部金币。所以，4号惟有支持3号才能保命。3号知道这一点，就会提出“100，0，0”的分配方案，对4号、5号一毛不拔而将全部金币归为已有，因为他知道4号一无所获但还是会投赞成票，再加上自己一票，他的方案即可通过。不过，2号推知3号的方案，就会提出“98，0，1，1”的方案，即放弃3号，而给予4号和5号各一枚金币。由于该方案对于4号和5号来说比在3号分配时更为有利，他们将支持他而不希望他出局而由3号来分配。这样，2号将拿走98枚金币。同样，2号的方案也会被1号所洞悉，1号并将提出（97，0，1，2，0）或（97，0，1，0，2）的方案，即放弃2号，而给3号一枚金币，同时给4号（或5号）2枚金币。由于1号的这一方案对于3号和4号（或5号）来说，相比2号分配时更优，他们将投1号的赞成票，再加上1号自己的票，1号的方案可获通过，97枚金币可轻松落入囊中。这无疑是1号能够获取最大收益的方案了！答案是：1号强盗分给3号1枚金币，分给4号或5号强盗2枚，自己独得97枚。分配方案可写成（97，0，1，2，0）或（97，0，1，0，2）。此题还有变种： 就是只需要一半人同意即可，不需要一半人以上同意方案就可以通过，在其他条件不变的情况下，1号该怎么分配才能获得最多的金币？答案：类似的推理过程4号：4号提出的方案的时候肯定是最终方案，因为不管5号同意不同意都能通过，所以4号5号不必担心自己被投入大海。那此时5号获得的金币为0，4号获得的金币为100。5号：因为4号提方案的时候 ，自己获取的金币为0 。所以只要4号之前的人分配给自己的金币大于0就同意该方案。4号：如果3号提的方案一定能获得通过（原因：3号给5号的金币大于0， 5号就同意 因此就能通过），那自己获得的金币就为0，所以只要2号让自己获得的金币大于0就会同意。3号：因为到了自己提方案的时候可以给5号一金币，自己的方案就能通过，但考虑到2号提方案的时候给4号一个金币，2号的方案就会通过，那自己获得的金币就为0。所以只要1号让自己获得的金币大于0就会同意。2号：因为到了自己提方案的时候只要给4号一金币，就能获得通过，根本就不用顾及3 号 5号同意不同意，所以不管1号怎么提都不会同意。1号：2号肯定不会同意。但只要给3号一块金币，5号一块金币（因为5号如果不同意，那么4号分配的时候，他什么都拿不到）就能获得通过。所以答案是 98，0，1，0，1。类似的问题也可用类似的推理，并不难 三个火枪手彼此痛恨的甲、乙、丙三个枪手准备决斗。甲枪法最好，十发八中；乙枪法次之，十发六中；丙枪法最差，十发四中。如果三人同时开枪，并且每人每轮只发一枪；那么枪战后，谁活下来的机会大一些？ 答案一般人认为甲的枪法好，活下来的可能性大一些。但合乎推理的结论是，枪法最糟糕的丙活下来的几率最大。那么我们先来分析一下各个枪手的策略。如同田忌赛马一般，枪手甲一定要对枪手乙先开枪。因为乙对甲的威胁要比丙对甲的威胁更大，甲应该首先干掉乙，这是甲的最佳策略。同样的道理，枪手乙的最佳策略是第一枪瞄准甲。乙一旦将甲干掉，乙和丙进行对决，乙胜算的概率自然大很多。枪手丙的最佳策略也是先对甲开枪。乙的枪法毕竟比甲差一些，丙先把甲干掉再与乙进行对决，丙的存活概率还是要高一些。我们根据分析来计算一下三个枪手在上述情况下的存活几率：第一轮：甲射乙，乙射甲，丙射甲。甲的活率为24%（40% X 60%）乙的活率为20%(100% - 80%)丙的活率为100%（无人射丙）。由于丙100％存活率，因此根据上轮甲乙存活的情况来计算三人第二轮的存活几率：情况1：甲活乙死（24% X 80% = 19.2%）甲射丙，丙射甲：甲的活率为60%，丙的活率为20%。情况2：乙活甲死（20% X 76% = 15.2%）乙射丙，丙射乙：乙的活率为60%，丙的活率为40%。情况3：甲乙同活（24% X 20% = 4.8%）重复第一轮。情况4：甲乙同死（76% X 80% = 60.8%）枪战结束。据此来计算三人活率：甲的活率为(19.2% X 60%) + (4.8% X 24%) = 12.672%乙的活率为(15.2% X 60%) + (4.8% X 20%) = 10.08%丙的活率为(19.2% X 20%) + (15.2% X 40%) + (4.8% X 100%) + (60.8% X 100%) = 75.52%通过对两轮枪战的详细概率计算，我们发现枪法最差的丙存活的几率最大，枪法较好的甲和乙的存活几率却远低于丙的存活几率。来自：https://www.zhihu.com/question/288093713/answer/482192781 囚犯拿豆子有5个囚犯被***，他们请求上诉，于是法官愿意给他们一个机会。 犯人抽签分好顺序，按序每人从100粒豆子中随意抓取，最多可以全抓，最少可以不抓，可以和别人抓的一样多。 最终，抓的最多的和最少的要被处死。 他们都是非常聪明且自私的人。 他们的原则是先求保命。如果不能保命，就拉人陪葬。 100颗不必都分完。 若有重复的情况，则也算最大或最小，一并处死（中间重复不算）。 假设每个犯人都足够聪明，但每个犯人并不知道其他犯人足够聪明。那么，谁活下来的可能性最大？ 答案不存在“谁活下来的可能性比较大”的问题。实际情况是5个人都要死。答案看起来很扯淡，但推理分析后却发现十分符合逻辑。根据题意，一号知道有五个人抓豆子，为保性命，他只要让豆子在20颗以内就可以了。但是他足够聪明的话他一定拿20颗，因为无论多拿一颗：2,3,4号的人一定会拿20颗最后死的人就会是最多的1号和最少的5号 还是少拿一颗：2,3,4号拿20个后，5号选择也拿20个拉上1234号垫背。（下面会说为什么多拿少拿也只会相差一颗）2号是知道1号抓了几颗豆子(20)的。那么，对于2号来说，只有2种选择：与1号一样多，或者不一样多。我们就从这里入手。情况一，假如2号选择与1号的豆子数不一样多，也就是说2号选择比1号多或者比1号少。我们先要证明，如果2号选择比1号多或者比1号少，那么他一定会选择比1号只多1颗或者只少1颗。要证明这个并不算太难。因为每个囚犯的第一选择是先求保命，要保命就要尽量使自己的豆子数既不是最多也不是最少。当2号决定选择比1号多的时候，他已经可以保证自己不是最少，为了尽量使自己不是最多，当然比1号多出来的数量越小越好。因为这个数量如果与一号相差大于1的话，那么3号就有机会抓到的居中数，相差越大，二号成为最多的可能性也就越大。反之，当2号决定选择比1号少的时候，也是同样的道理，他会选择只比1号少1颗。既然2号只会会选择比1号多1颗或者比1号少1颗，那么1、2号的豆子数一定是2个连续的自然数，和一定是2n+1（其中1个人是n,另1人是n+1）。轮到3号的时候，他可以从剩下的豆子数知道1、2号的数量和，也就不难计算出n的值。而3号也只有2个选择：n颗或者n+1颗。为什么呢？这与上面的证明是一样的道理，保命原则，取最接近的数量，这里不再赘述。不过，3号选择的时候会有一个特殊情况，在这一情况下，他一定会选择较小的n，而不是较大的n+1。这一特殊情况就是，当3号知道自己选择了n后(已保证自己不是最多)，剩下的豆子数由于数量有限，4、5号中一定有人比n要少，这样自己一定可以活下来。计算的话就是 [100-(3n+1)]/2&lt;=n ，不难算出，在这个特殊情况下，n&gt;=20。也就是说，当1、2号选择了20或21颗的时候，3号只要选择20颗，就可以保证自己活下来。这样一来剩下的豆子只剩39颗，4、5号至少有一人少于20颗的（这个人当然是后选的5号），这样死的将是5号和1、2号中选21颗的那个人。当然，1号、2号肯定不会有人选择21这一“倒霉”的数字（因为他们都是聪明人），这样的话，上述“特殊情况（即3号选择n）”就不会发生了。综上所述，2345这四个人不难从剩下的豆子数知道前面几个人的数量总和，也就不难进而计算出n的值，而这样一来他们也只有n或者n+1这两种选择。最后的5号也是不难算出n的。在前4个人只选择了2个数字(n和n+1)的情况下，5号已是必死无疑，这时,根据“死也要拉几个垫背”的条件，5号会选择n或n+1，选择5个人一起完蛋。情况二，如果2号选择了与1号不一样多的话，最终结果是5个人一起死，那么2号只有选择与1号一样多了。那么1、2号的和就是2n，而3号如果选择n+1或者n -1的话，就又回到第一点的情况去了(前3个人的和是3m+1或3m+2)，于是3号也只能选择n ，当然，4号还是只能选n，最后的结果仍旧是5个人一起完蛋。“最后处死抓的最多和最少的囚犯”严格执行这句话的话，除非有人舍己为人，死二留三。但这是足够聪明且自私的囚犯，所以这五个聪明人的下场是全死，这道题只不过是找了一个处死所有人的借口罢了. . . . . .变种问题：如果每个囚犯都知道其他囚犯足够聪明，事情会怎么发展？答案：这样的情况下囚犯一也会像我们一样推导出前面的结论，那么根据自私的规定，他会直接拿完100个，大家一起完蛋(反正结局已定) 学生猜生日这种题目笔试中出现的次数比较多，用排除法比较好解决 小明和小强都是张老师的学生，张老师的生日是M月N日, 2人都知道张老师的生日是下列10组中的一天，张老师把M值告诉了小明, 把N值告诉了小强，张老师问他们知道他的生日是那一天吗? 3月4日 3月5日 3月8日 6月4日 6月7日 9月1日 9月5日 12月1日 12月2日 12月8日 小明说:如果我不知道的话，小强肯定也不知道. 小强说:本来我也不知道，但是现在我知道了. 小明说:哦，那我也知道了. 请根据以上对话推断出张老师的生日是哪一天? 答案排除法：1.小明肯定小强不知道是哪天，排除所有月份里有单独日的月份：6月和12月&lt;因为如果小强的M是2或者7的话，小强就知道了，所以把6月7日与12月2日排除&gt;，所以小明拿到的是3或者92.小强本来不知道，所以小强拿到的不是2或者7，但是小强现在知道了，说明把6月与12月排除后，小强拿到的是1,4,8中的一个&lt;这里小强肯定没拿到5，否则他不会知道是哪天的&gt;3.小明现在也知道了，说明小明拿到的不是3，否则他不会知道是3月4日还是3月8日的，所以小明拿到的是9才能唯一确定生日综上，答案是9月1日 小明和小强是赵老师的学生，张老师的生日是M月N日，张老师 把M值告诉小明，N值告诉小强 给他们六个选项 3月1日 3月3日 7月3日 7月5日 9月1日 11月7日 小明说:我猜不出来 小强说:本来我也猜不出来，但是现在我知道了 问:张老师生日多少 答案：3月1日 答案排除法：1.小明说猜不出来，说明小明拿到的不是单独出现的9或者11，说明老师生日只能是3月或者7月2.小强原本不知道，说明小强拿到的不是单独出现的5或者7，说明老是生日是1日或3日3.小强现在知道了，说明小强拿到的是1，因为如果拿到的是3，那么小强就不知道是3月3日还是7月3日了综上，老师生日是3月1日 参考文章： https://www.nowcoder.com/discuss/262595","tags":["智力题","algorithm"],"categories":["algorithm"]},{"title":"常见思维题一","path":"/algorithm/algo1/","content":"倒水问题水无限。3L和5L水桶各一个，怎样取4L的水？ 答案 老虎吃羊问题岛上有100只老虎和1只羊，老虎可以吃草但是更愿意吃羊。 假设A: 每次老虎吃完羊之后自己就变成了羊 假设B: 所有老虎都很聪明也很理性，它们都想活下去 请问这只羊会被吃吗? 答案我们先从1只老虎开始分析，如果只有一只老虎，那它一定会吃羊。因为就算吃完变成羊它也不用担心自己被吃掉。如果岛上有两只老虎的话，那羊不会被吃掉，因为如果其中一只老虎吃掉羊之后自己就会变成羊被另一只老虎吃掉。如果岛上有三只老虎，羊会被吃掉。因为一旦有一只最聪明的老虎吃掉羊之后，那只老虎自己变成羊，就变成了刚才所分析的2虎1羊的局面，剩下的2只老虎不敢吃掉变成羊的那只老虎。如果岛上有4只老虎，羊不会被吃掉，因为一旦有一只虎吃掉羊，就会变成刚刚3虎1羊的局面，那只老虎变成的羊就会被吃掉。以此类推，如果老虎的数量是偶数，羊不会被吃掉，如果老虎的数量是奇数，羊就会被吃掉。 其他No.1给一个瞎子52张扑克牌，并告诉他里面恰好有10张牌是正面朝上的。要求这个瞎子把牌分成两堆，使得每堆牌里正面朝上的牌的张数一样多。瞎子应该怎么做？ 答案把扑克牌分成两堆，一堆10张，一堆42张。然后，把小的那一堆里的所有牌全部翻过来。 No.2如何用一枚硬币等概率地产生一个1到3之间的随机整数？如果这枚硬币是不公正的呢？ 答案如果是公正的硬币，则投掷两次，“正反”为1，“反正”为2，“正正”为3，“反反”重来。如果是不公正的硬币，注意到出现“正反”和“反正”的概率一样，因此令“正反反正”、“反正正反”、“正反正反”分别为1、2、3，其余情况重来。另一种更妙的办法是，投掷三次硬币，“正反反”为1，“反正反”为2，“反反正”为3，其余情况重来。 No.330枚面值不全相同的硬币摆成一排，甲、乙两个人轮流选择这排硬币的其中一端，并取走最外边的那枚硬币。如果你先取硬币，能保证得到的钱不会比对手少吗？ 答案先取者可以让自己总是取奇数位置上的硬币或者总是取偶数位置上的硬币。数一数是奇数位置上的面值总和多还是偶数位置上的面值总和多，然后总是取这些位置上的硬币就可以了。 No.4 一个环形轨道上有n个加油站，所有加油站的油量总和正好够车跑一圈。证明，总能找到其中一个加油站，使得初始时油箱为空的汽车从这里出发，能够顺利环行一圈回到起点。 答案总存在一个加油站，仅用它的油就足够跑到下一个加油站（否则所有加油站的油量加起来将不够全程）。把下一个加油站的所有油都提前搬到这个加 油站来，并把油已被搬走的加油站无视掉。在剩下的加油站中继续寻找油量足以到达下个加油站的地方，不断合并加油站，直到只剩一个加油站为止。显然从这里出发就能顺利跑完全程。另一种证明方法：先让汽车油箱里装好足够多的油，随便从哪个加油站出发试跑一圈。车每到一个加油站时，记录此时油箱里剩下的油量，然后把那个加油站的油全部装上。试跑完一圈后，检查刚才路上到哪个加油站时剩的油量最少，那么空着油箱从那里出发显然一定能跑完全程。 No.5初始时，两个口袋里各有一个球。把后面的n-2个球依次放入口袋，放进哪个口袋其概率与各口袋已有的球数成正比。这样下来，球数较少的那个口袋平均期望有多少个球？ 答案先考虑一个看似无关的问题——怎样产生一个1到n的随机排列。首先，在纸上写下数字1；然后，把2写在1的左边或者右边；然后，把3写在最 左边，最右边，或者插进1和2之间……总之，把数字i等概率地放进由前面i-1个数产生的（包括最左端和最右端在内的）共i个空位中的一个。这样生成的显 然是一个完全随机的排列。我们换一个角度来看题目描述的过程：假想用一根绳子把两个球拴在一起，把这根绳子标号为1。接下来，把其中一个小球分裂成两个小球，这两个小球用 标号为2的绳子相连。总之，把“放进第i个球”的操作想象成把其中一个球分裂成两个用标有i-1的绳子相连的小球。联想我们前面的讨论，这些绳子的标号事 实上是一个随机的全排列，也就是说最开始绳子1的位置最后等可能地出现在每个地方。也就是说，它两边的小球个数(1,n-1)、(2,n-2)、 (3,n-3)、……、(n-1,1)这n-1种情况等可能地发生。因此，小袋子里的球数大约为n/4个。准确地说，当n为奇数时，小袋子里的球数为 (n+1)/4；当n为偶数时，小袋子里的球数为n^2/(4n-4)。 No.6考虑一个n*n的棋盘，把有公共边的两个格子叫做相邻的格子。初始时，有些格子里有病毒。每一秒钟后，只要一个格子至少有两个相邻格子染上了病毒，那么他自己也会被感染。为了让所有的格子都被感染，初始时最少需要有几个带病毒的格子？给出一种方案并证明最优性。 答案至少要n个，比如一条对角线上的n个格子。n个格子也是必需的。当一个新的格子被感染后，全体被感染的格子所组成的图形的周长将减少0个、 2个或4个单位（具体减少了多少要看它周围被感染的格子有多少个）。又因为当所有格子都被感染后，图形的周长为4n，因此初始时至少要有n个被感染的格 子。 No.7在一个m*n的棋盘上，有k个格子里放有棋子。是否总能对所有棋子进行红蓝二染色，使得每行每列的红色棋子和蓝色棋子最多差一个？ 答案可以。建一个二分图G(X,Y)，其中X有m个顶点代表了棋盘的m个行，Y有n个顶点代表了棋盘的n个列。第i行第j列有棋子就在X(i) 和Y(j)之间连一条边。先找出图G里的所有环（由于是二分图，环的长度一定是偶数），把环里的边红蓝交替染色。剩下的没染色的图一定是一些树。对每棵树 递归地进行操作：去掉一个叶子节点和对应边，把剩下的树进行合法的红蓝二染色，再把刚才去掉的顶点和边加回去，给这个边适当的颜色以满足要求。 No.8任意给一个88的01矩阵，你每次只能选一个33或者4*4的子矩阵并把里面的元素全部取反。是否总有办法把矩阵里的所有数全部变为1？ 答案不能。大矩阵中有36个33的小矩阵和25个44的小矩阵，因此总共有61种可能的操作。显然，给定一个操作序列，这些操作的先后顺序 是无关紧要的；另外，在一个操作序列中使用两种或两种以上相同的操作也是无用的。因此，实质不同的操作序列只有2^61种。但8*8的01矩阵一共有 2^64种，因此不是每种情况都有办法达到目的。 No.9五个洞排成一排，其中一个洞里藏有一只狐狸。每个夜晚，狐狸都会跳到一个相邻的洞里；每个白天，你都只允许检查其中一个洞。怎样才能保证狐狸最终会被抓住？ 答案按照2, 3, 4, 2, 3, 4的顺序检查狐狸洞可以保证抓住狐狸。为了说明这个方案是可行的，用集合F表示狐狸可能出现的位置，初始时F = {1, 2, 3, 4, 5}。如果它不在2号洞，则第二天狐狸已经跑到了F = {2, 3, 4, 5}。如果此时它不在3号洞，则第三天狐狸一定跑到了F = {1, 3, 4, 5}。如果此时它不在4号洞，则再过一晚后F = {2, 4}。如果此时它不在2号洞，则再过一天F = {3, 5}。如果此时它不在3号洞，再过一天它就一定跑到4号洞了。方案不是唯一的，下面这些方案都是可行的：2, 3, 4, 4, 3, 24, 3, 2, 2, 3, 44, 3, 2, 4, 3, 2 No.10一个经典老题是说，把一个333的立方体切成27个单位立方体，若每一刀切完后都允许重新摆放各个小块的位置，最少可以用几刀？答案仍然是6刀，因为 正中间那个单位立方体的6个面都是后来才切出来的，因此怎么也需要6刀。考虑这个问题：若把一个nnn的立方体切成一个个单位立方体，最少需要几刀？ 答案事实上，从一个更强的命题出发反而能使问题变得更简单。对于一个abc的长方体，我们需要f(a)+f(b)+f(c)刀，其中 f(x)=⌈log(x)/log(2)⌉。只需要注意到，在整个过程中的任何一步，切完当前最大的块所需要的刀数也就等于整个过程还需要的刀数，因为其 它小块需要的刀数都不会超过最大块所需刀数，它们都可以与最大块一道并行处理。这表明，我们的最优决策即是让当前的最大块尽可能的小，也就是说要把当前的 最大块尽可能相等地切成两半。利用数学归纳法，我们可以很快得到本段开头的结论。","tags":["智力题","algorithm"],"categories":["algorithm"]},{"title":"关于","path":"/about/index.html","content":"Believe in yourself.BlogWikiMessageResumePicSky Yanliang 🍂 🍀 个人简介 社畜一枚，坐标 SZ🌏，永远热爱，永远年轻相知🤞 爱好旅行/音乐/电影/阅读✨ 对一切新鲜的事物充满好奇🧐 目标是过简单的生活💪 对自己的要求是每天都要比昨天进步一点点👊 📆 建站历程 2021 年 7 月 30 日建站 🎨添加twikoo评论 📨添加首页置顶文章轮播功能 🎉 👨‍✈️ 版权声明 123456博客内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络，若您认为本博客有部分内容侵犯了您的版权，请电邮告知，我将认真处理。 赏 .single-reward { position: relative; width: 100%; margin: 30px auto; text-align: center; z-index: 999 } .single-reward .reward-open { position: relative; line-height: 24px; width: 25px; height: 25px; padding: 7px; color: #fff; text-align: center; display: inline-block; border-radius: 100%; background: #d34836; cursor: pointer; } .single-reward .reward-main { position: absolute; top: 48px; left: -153.5px; margin: 0; padding: 4px 0 0; width: 355px; background: 0 0; display: none; animation: main .4s } .reward-open:hover .reward-main { display: block } .single-reward .reward-row { margin: 0 auto; padding: 20px 15px 10px; background: #f5f5f5; display: inline-block; border-radius: 4px; } .single-reward .reward-row:before { content: \"\"; width: 0; height: 0; border-left: 13px solid transparent; border-right: 13px solid transparent; border-bottom: 13px solid #f5f5f5; position: absolute; top: -9px; left: -9px; right: 0; margin: 0 auto } .single-reward .reward-row li { list-style-type: none; padding: 0 12px; display: inline-block } .reward-row li img { width: 130px; max-width: 130px; border-radius: 3px; position: relative } .reward-row li::after { margin-top: 10px; display: block; font-size: 13px; color: #121212; } .alipay-code:after { content: \"支付宝\" } .wechat-code:after { content: \"微信\" } .md .single-reward ul li:before{ content: none }"},{"title":"Friends","path":"/friends/index.html","content":"友链更新通知由于近期对友链系统进行了重做，原链接失效的小伙伴请按照下方交换友链的步骤进行填写。在新的友链系统中，您随时可以对自己的信息进行修改而无需等待博主更新。 我可以交换友链吗？先友后链，在我们有一定了解了之后才可以交换友链，除此之外，您的网站还应满足以下条件： 合法的、非营利性、无商业广告 有实质性原创内容的 HTTPS 站点 如何自助添加友链？第一步：新建 Issue新建 GitHub Issue 按照模板格式填写并提交。为了提高图片加载速度，建议使用 Jsdelivr + Github 优化头像第二步：添加友链并等待管理员审核请添加本站到您的友链中，如果您也使用 issue 作为友链源，只需要告知您的友链源仓库即可。123title: Yanliangavatar: https://cdn.jsdelivr.net/gh/gaoyanliang/cdn@main/blog/img/head.pngurl: https://yanliang.cool待管理员审核通过，添加了 active 标签后，回来刷新即可生效。 如果您需要更新自己的友链，请直接修改 issue 内容，大约 3 分钟内生效，无需等待博客更新。如果无法修改，可以重新创建一个。"},{"path":"/recent/index.html","content":""},{"title":"设计模式","path":"/wiki/design/index.html","content":"❓ 设计模式是什么设计模式是软件设计中常见问题的典型解决方案。 每个模式就像一张蓝图， 你可以通过对其进行定制来解决代码中的特定设计问题。 设计模式与方法或库的使用方式不同， 你很难直接在自己的程序中套用某个设计模式。 模式并不是一段特定的代码， 而是解决特定问题的一般性概念。 你可以根据模式来实现符合自己程序实际所需的解决方案。 💖 设计模式优势设计模式是软件设计中对一些常见问题的解决思路。使用设计模式可以写出可扩展、可读、可维护的高质量代码。 设计模式是针对软件设计中常见问题的工具箱， 其中的工具就是各种经过实践验证的解决方案。 即使你从未遇到过这些问题， 了解模式仍然非常有用， 因为它能指导你如何使用面向对象的设计原则来解决各种问题。 为什么要学习设计模式？比较功利的一个目的是：应对面试告别被人吐槽的烂代码提高复杂代码的设计和开发能力更容易看懂源码 📃 设计模式分类不同设计模式的复杂程度、 细节层次以及在整个系统中的应用范围等方面各不相同。 我喜欢将其类比于道路的建造： 如果你希望让十字路口更加安全， 那么可以安装一些交通信号灯， 或者修建包含行人地下通道在内的多层互通式立交桥。 最基础的、 底层的模式通常被称为惯用技巧。 这类模式一般只能在一种编程语言中使用。 最通用的、 高层的模式是构架模式。 开发者可以在任何编程语言中使用这类模式。 与其他模式不同， 它们可用于整个应用程序的架构设计。 此外， 所有模式可以根据其意图或目的来分类。 本书覆盖了三种主要的模式类别： 创建型模式提供创建对象的机制， 增加已有代码的灵活性和可复用性。 结构型模式介绍如何将对象和类组装成较大的结构， 并同时保持结构的灵活和高效。 行为模式负责对象间的高效沟通和职责委派。"},{"title":"工厂模式","path":"/wiki/design/create/factory.html","content":"sdfhi"},{"title":"单例模式","path":"/wiki/design/create/single.html","content":"什么是单例模式单例设计模式( Singleton Design Pattern)理解起来非常简单。一个类只允许创建个对象(或者实例),那这个类就是一个单例类,这种设计模式就叫作单例设计模式,简称单例模式。 单例模式共分为两大类： 懒汉模式：实例在第一次使用时创建 饿汉模式：实例在类装载时创建 为什么要使用单例?站在业务概念的角度,有些数据在系统中只应该保存一份,就比较适合设计为单例类。比如,系统的配置信息类、连接池类、ID生成器类。 除此之外,我们还可以使用单例解决资源访问冲突的问题。 单例存在哪些问题?大部分情况下,我们在项目中使用单例,都是用它来表示一些全局唯一类,比如配置信息类、连接池类、ID生成器类。 单例模式书写简洁、使用方便,在代码中,我们不需要创建对象,直接通过类似 IdGenerator.getInstance() 这样的方法来调用就可以了。 但是,这种使用方法有点类似硬编码(hard code),会带来诸多问题。 1. 单例类对OOP（面向对象）特性的支持不友好 面向对象的四大特性是封装、抽象、继承、多态。单例这种设计模式对于其中的抽象、继承、多态都支持得不好。 以 IdGenerator 为例，IdGenerator 的使用方式违背了基于接口而非实现的设计原则,也就违背了广义上理解的OOP的抽象特性。 如果未来某一天,我们希望针对不同的业务采用不同的ID生成算法。比如,订单ID和用户ID采用不同的ID生成器来生成。为了应对这个需求变化,我们需要修改所有用到 GeNerator类的地方,这样代码的改动就会比较大。 除此之外,单例对继承、多态特性的支持也不友好。这里我之所以会用“不友好”这个词,而非“完全不支持”,是因为从理论上来讲,单例类也可以被继承、也可以实现多态,只是实现起来会非常奇怪,会导致代码的可读性变差。不明白设计意图的人,看到这样的设计,会觉得莫名其妙。 所以,一旦你选择将某个类设计成到单例类,也就意味着放弃了继承和多态这两个强有力的面向对象特性,也就相当于损失了可以应对未来需求变化的扩展性。 2. 单例类会隐藏类之间的依赖关系 我们知道,代码的可读性非常重要。在阅读代码的时候,我们希望一眼就能看出类与类之间的依赖关系,搞清楚这个类依赖了哪些外部类。 通过构造函数、参数传递等方式声明的类之间的依赖关系,我们通过查看函数的定义,就能很容易识别出来。 但是,单例类不需要显示创建、不需要依赖参数传递,在函数中直接调用就可以了。如果代码比较复杂,这种调用关系就会非常隐蔽。在阅读代码的时候,我们就需要仔细查看每个函数的代码实现,才能知道这个类到底依赖了哪些单例类。 3. 单例类对代码的扩展性不友好 单例类只有一个对象实例，如果未来某一天，我们需要在代码中创建两个实例或多个实例，那就要对代码有比较大的改动。 以数据库连接池为例，在系统设计初期,我们觉得系统中只应该有一个数据库连接池,这样能方便我们控制对数据库连接资源的消耗。所以,我们把数据库连接池类设计成了单例类。 但之后我们发现,系统中有些SQL语句运行得非常慢。这些SQL语句在执行的时候,长时间占用数据库连接资源,导致其他SQL请求无法响应。 为了解决这个问题,我们希望将慢SQL与其他SQL隔离开来执行。为了实现这样的目的,我们可以在系统中创建两个数据库连接池,慢SQL独享—个数据库连接池,其他SQL独享另外—个数据库连接池,这样就能避免慢SQL影响到其他SQL的执行。 如果我们将数据库连接池设计成单例类,显然就无法适应这样的需求变更,也就是说,单例类在某些情况下会影响代码的扩展性、灵活性。所以,数据库连接池、线程池这类的资源池,最好还是不要设计成单例类。实际上,一些开源的数据库连接池、线程池也确实没有设计成单例类。 4. 单例对代码的可测试性不友好 单例模式的使用会影响到代码的可测试性。如果单例类依赖比较重的外部资源,比如DB,我们在写单元测试的时候,希望能通过mock的方式将它替换掉。而单例类这种硬编码式的使用方式,导致无法实现mock替换 除此之外,如果单例类持有成员变量(比如 GeNerator中的id成员变量),那它实际上相当于一种全局变量,被所有的代码共享。如果这个全局变量是一个可变全局变量,也就是说,它的成员变量是可以被修改的,那我们在编写单元测试的时候,还需要注意不同测试用例之间,修改了单例类中的同一个成员变量的值,从而导致测试结果互相影响的问题。 5. 单例不支持有参数的构造函数 单例不支持有参数的构造函数,比如我们创建一个连接池的单例对象,我们没法通过参数来指定连接池的大小。针对这个问题,我们来看下都有哪些解决方案。 创建完实例之后，在调用init函数传递参数。 将参数放到 getInstance()方法中。 将参数放到另外一个全局变量中。 有何替代的解决方案?为了保证全局唯一,除了使用单例,我们还可以用静态方法来实现。 这也是项目开发中经常用到的一种实现思路。不过,静态方法这种实现思路,并不能解决我们之前提到的问题。 如果要完全解决这些问题,我们可能要从根上,寻找其他方式来实现全局唯一类了。比如,通过工厂模式、IOC容器(比如 Spring IOC容器)来保证,由程序员自己来保证(自己在编写代码的时候自己保证不要创建两个类对象)。 有人把单例当作反模式,主张杜绝在项目中使用。我个人觉得这有点极端。模式没有对错,关键看你怎么用。如果单例类并没有后续扩展的需求,并且不依赖外部系统,那设计成单例类就没有太大问题。对于一些全局的类,我们在其他地方new的话,还要在类之间传来传去,不如直接做成单例类,使用起来简洁方便。 单例与静态类的区别? 静态类比单例模式的效率更高，因为静态方法在编译期就完成了静态绑定。 单例对象可以被延迟初始化。而静态类总是在类被加载的时候就初始化。 在做单元测试的时候，静态类比单例类更难被 mock，因此也更难被测试。而单例类很容易被 mock 来执行单元测试。 Java 中的静态方法是不能被覆写的，这就导致某些情况不够灵活。而你随时可以继承一个非 final 的单例类来覆写其中的方法。 具体实现饿汉模式按照定义我们可以写出一个基本代码： 12345678910111213141516171819public class Singleton &#123; // 使用private将构造方法私有化，以防外界通过该构造方法创建多个实例 private Singleton() &#123; &#125; // 由于不能使用构造方法创建实例，所以需要在类的内部创建该类的唯一实例 // 使用static修饰singleton 在外界可以通过类名调用该实例 类名.成员名 final static Singleton singleton = new Singleton(); // 1 // 如果使用private封装该实例，则需要添加get方法实现对外界的开放 private static final Singleton instance = new Singleton(); // 2 // 添加static，将该方法变成类所有通过类名访问 public static Singleton getInstance()&#123; return instance; &#125; //1和2选一种即可，推荐2&#125; 对于饿汉模式来说，这种写法已经很完美了，唯一的缺点就是，由于instance的初始化是在类加载时进行的，类加载是由ClassLoader来实现的，如果初始化太早，就会造成资源浪费。 当然，如果所需的单例占用的资源很少，并且也不依赖于其他数据，那么这种实现方式也是很好的。 类装载的时机： new一个对象时 使用反射创建它的实例时 子类被加载时，如果父类还没有加载，就先加载父类 JVM启动时执行主类 会先被加载 懒汉模式懒汉模式的代码如下 123456789101112// 代码一public class Singleton &#123; private static Singleton instance = null; private Singleton()&#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 每次获取instance之前先进行判断，如果instance为空就new一个出来，否则就直接返回已存在的instance。 这种写法在单线程的时候是没问题的。但是，当有多个线程一起工作的时候，如果有两个线程同时运行到 if (instance == null)，都判断为null（第一个线程判断为空之后，并没有继续向下执行，当第二个线程判断的时候instance依然为空），最终两个线程就各自会创建一个实例出来。这样就破环了单例模式 实例的唯一性 要想保证实例的唯一性就需要使用 synchronized 加上一个同步锁 12345678910111213// 代码二public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; synchronized(Singleton.class)&#123; if (instance == null) instance = new Singleton(); &#125; return instance; &#125;&#125; 加上synchronized关键字之后，getInstance方法就会锁上了。如果有两个线程（T1、T2）同时执行到这个方法时，会有其中一个线程T1获得同步锁，得以继续执行，而另一个线程T2则需要等待，当第T1执行完毕getInstance之后（完成了null判断、对象创建、获得返回值之后），T2线程才会执行执行。 所以这段代码也就避免了代码一中，可能出现因为多线程导致多个实例的情况。但是，这种写法也有一个问题：给getInstance方法加锁，虽然避免了可能会出现的多个实例问题，但是会强制除T1之外的所有线程等待，实际上会对程序的执行效率造成负面影响。 双重检查（Double-Check）代码二相对于代码一的效率问题，其实是为了解决1%几率的问题，而使用了一个100%出现的防护盾。那有一个优化的思路，就是把100%出现的防护盾，也改为1%的几率出现，使之只出现在可能会导致多个实例出现的地方。 代码如下： 123456789101112131415// 代码三public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null)&#123; synchronized(Singleton.class)&#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这段代码看起来有点复杂，注意其中有两次if(instance==null)的判断，这个叫做 双重检查 Double-Check。 第一个 if(instance==null)，其实是为了解决代码二中的效率问题，只有instance为null的时候，才进入synchronized的代码段大大减少了几率。 第二个if(instance==null)，则是跟代码二一样，是为了防止可能出现多个实例的情况。 这段代码看起来已经完美无瑕了。当然，只是『看起来』，还是有小概率出现问题的。想要充分理解需要先弄清楚以下几个概念：原子操作、指令重排。 原子操作 简单来说，原子操作（atomic）就是不可分割的操作，在计算机中，就是指不会因为线程调度被打断的操作。比如，简单的赋值是一个原子操作： 1m = 6; // 这是个原子操作 假如m原先的值为0，那么对于这个操作，要么执行成功m变成了6，要么是没执行 m还是0，而不会出现诸如m=3这种中间态——即使是在并发的线程中。 但是，声明并赋值就不是一个原子操作： 1int n=6;//这不是一个原子操作 对于这个语句，至少有两个操作：①声明一个变量n ②给n赋值为6——这样就会有一个中间状态：变量n已经被声明了但是还没有被赋值的状态。这样，在多线程中，由于线程执行顺序的不确定性，如果两个线程都使用m，就可能会导致不稳定的结果出现。 指令重排 简单来说，就是计算机为了提高执行效率，会做的一些优化，在不影响最终结果的情况下，可能会对一些语句的执行顺序进行调整。比如，这一段代码： 1234int a ; // 语句1 a = 8 ; // 语句2int b = 9 ; // 语句3int c = a + b ; // 语句4 正常来说，对于顺序结构，执行的顺序是自上到下，也即1234。但是，由于指令重排的原因，因为不影响最终的结果，所以，实际执行的顺序可能会变成3124或者1324。 由于语句3和4没有原子性的问题，语句3和语句4也可能会拆分成原子操作，再重排。——也就是说，对于非原子性的操作，在不影响最终结果的情况下，其拆分成的原子操作可能会被重新排列执行顺序。 OK，了解了原子操作和指令重排的概念之后，我们再继续看代码三的问题。 主要在于singleton = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 singleton 分配内存 调用 Singleton 的构造函数来初始化成员变量，形成实例 将singleton对象指向分配的内存空间（执行完这步 singleton才是非 null了） 在JVM的即时编译器中存在指令重排序的优化。 也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 再稍微解释一下，就是说，由于有一个『instance已经不为null但是仍没有完成初始化』的中间状态，而这个时候，如果有其他线程刚好运行到第一层if (instance ==null)这里，这里读取到的instance已经不为null了，所以就直接把这个中间状态的instance拿去用了，就会产生问题。这里的关键在于线程T1对instance的写操作没有完成，线程T2就执行了读操作。 对于代码三出现的问题，解决方案为：给instance的声明加上volatile关键字代码如下： 1234567891011121314public class Singleton &#123; private static volatile Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null)&#123; synchronized(Singleton.class)&#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; volatile关键字的一个作用是禁止指令重排，把instance声明为volatile之后，对它的写操作就会有一个内存屏障，这样，在它的赋值完成之前，就不用会调用读操作。 注意：volatile阻止的不是singleton = new Singleton()这句话内部[1-2-3]的指令重排，而是保证了在一个写操作（[1-2-3]）完成之前，不会调用读操作（if (instance == null)）。 静态内部类123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种写法的巧妙之处在于：对于内部类SingletonHolder，它是一个饿汉式的单例实现，在SingletonHolder初始化的时候会由ClassLoader来保证同步，使INSTANCE是一个真单例。 同时，由于SingletonHolder是一个内部类，只在外部类的Singleton的getInstance()中被使用，所以它被加载的时机也就是在getInstance()方法第一次被调用的时候。 它利用了ClassLoader来保证了同步，同时又能让开发者控制类加载的时机。从内部看是一个饿汉式的单例，但是从外部看来，又的确是懒汉式的实现 枚举1234567891011121314151617181920212223public class Singleton &#123; // 枚举类型是线程安全的，并且只会装载一次 private enum SingletonEnum &#123; INSTANCE; // 声明单例对象 private final Singleton instance; // 实例化 SingletonEnum() &#123; instance = new Singleton(); &#125; private Singleton getInstance() &#123; return instance; &#125; &#125; // 获取实例（单例对象） public static Singleton getInstance() &#123; return SingletonEnum.INSTANCE.getInstance(); &#125; private Singleton() &#123; &#125;&#125; 是不是很简单？而且因为自动序列化机制，保证了线程的绝对安全。三个词概括该方式：简单、高效、安全 这种写法在功能上与共有域方法相近，但是它更简洁，无偿地提供了序列化机制，绝对防止对此实例化，即使是在面对复杂的序列化或者反射攻击的时候。虽然这中方法还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。"},{"title":"并发设计模式：Immutability 模式","path":"/wiki/design/other/immutability.html","content":"在并发模式下, 多个线程同时读写同一共享变量存在并发问题。 其中导致出现并发问题的必要条件之一就是 读写 ，如果没有写，只存在读，是不会存在并发问题的。 如果让一个共享变量只有读操作，没有写操作，如此则可以解决并发问题。该理论的具体实现就是 不变性（Immutability）模式 。所谓不变性，简单来讲，就是对象一旦被创建之后，状态就不再发生变化。换句话说，就是变量一旦被赋值，就不允许修改了（没有写操作）；没有修改操作，也就是保持了不变性。 实现具备不可变性的类将一个类所有的属性都设置成 final ，并且只允许存在读方法，那么这个类基本上就具备不可变性了。更严格的做法是这个类本身也是 final 的，也就是不允许继承。因为子类可以覆盖父类的方法，有可能改变不可变性。 Java SDK 里很多类都具备不可变性，只是由于它们的使用太简单，最后反而被忽略了。例如经常用到的 String 和 Long、Integer、Double 等基础类型的包装类都具备不可变性，这些对象的线程安全性都是靠不可变性来保证的。如果你仔细翻看这些类的声明、属性和方法，你会发现它们都严格遵守不可变类的三点要求：类和属性都是 final 的，所有方法均是只读的。 看到这里你可能会疑惑，Java 的 String 方法也有类似字符替换操作，怎么能说所有方法都是只读的呢？下面通过 String 的源代码来看一哈。 下面的示例代码源自 Java 1.8 SDK。String 这个类以及它的属性 value[] 都是 final 的；而 replace() 方法的实现，没有修改 value[]，而是将替换后的字符串作为返回值返回了。 1234567891011121314151617181920212223242526272829303132333435363738394041public final class String &#123; private final char value[]; // 字符替换 String replace(char oldChar, char newChar) &#123; // 无需替换，直接返回 this if (oldChar == newChar)&#123; return this; &#125; int len = value.length; int i = -1; /* avoid getfield opcode */ char[] val = value; // 定位到需要替换的字符位置 while (++i &lt; len) &#123; if (val[i] == oldChar) &#123; break; &#125; &#125; // 未找到 oldChar，无需替换 if (i &gt;= len) &#123; return this; &#125; // 创建一个 buf[]，这是关键 // 用来保存替换后的字符串 char buf[] = new char[len]; for (int j = 0; j &lt; i; j++) &#123; buf[j] = val[j]; &#125; while (i &lt; len) &#123; char c = val[i]; buf[i] = (c == oldChar) ? newChar : c; i++; &#125; // 创建一个新的字符串返回 // 原字符串不会发生任何变化 return new String(buf, true); &#125;&#125; 由上面的代码可以发现，String 是通过创建一个新的不可变对象 来实现 修改 的功能。如果 所有的修改操作都创建一个新的不可变对象，你可能会有这种担心：是不是创建的对象太多了，有点太浪费内存呢？是的，这样做的确有些浪费，那如何解决呢？ 利用享元模式避免创建重复对象利用享元模式可以减少创建对象的数量，从而减少内存占用。Java 语言里面 Long、Integer、Short、Byte 等这些基本数据类型的包装类都用到了享元模式。 下面以 Long 这个类作为例子，看看它是如何利用享元模式来优化对象的创建的。 享元模式本质上其实就是一个 对象池，利用享元模式创建对象的逻辑也很简单：创建之前，首先去对象池里看看是不是存在；如果已经存在，就利用对象池里的对象；如果不存在，就会新创建一个对象，并且把这个新创建出来的对象放进对象池里。 Long 这个类并没有照搬享元模式，Long 内部维护了一个静态的对象池，仅缓存了 [-128,127] 之间的数字，这个对象池在 JVM 启动的时候就创建好了，而且这个对象池一直都不会变化，也就是说它是静态的。之所以采用这样的设计，是因为 Long 这个对象的状态共有 2 的 64 次方 种，实在太多，并不适合全部缓存，而 [-128,127] 之间的数字利用率最高。下面的示例代码出自 Java 1.8，valueOf() 方法就用到了 LongCache 这个缓存。 1234567891011121314151617181920Long valueOf(long l) &#123; final int offset = 128; // [-128,127] 直接的数字做了缓存 if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; return LongCache .cache[(int)l + offset]; &#125; return new Long(l);&#125;// 缓存，等价于对象池// 仅缓存 [-128,127] 直接的数字static class LongCache &#123; static final Long cache[] = new Long[-(-128) + 127 + 1]; static &#123; for(int i=0; i&lt;cache.length; i++) cache[i] = new Long(i-128); &#125;&#125; 注意： “Integer 和 String 类型的对象不适合做锁”，其实基本上所有的基础类型的包装类都不适合做锁，因为它们内部用到了享元模式，这会导致看上去私有的锁，其实是共有的。例如在下面代码中，本意是 A 用锁 al，B 用锁 bl，各自管理各自的，互不影响。但实际上 al 和 bl 是一个对象，结果 A 和 B 共用的是一把锁。 12345678910111213141516class A &#123; Long al=Long.valueOf(1); public void setAX()&#123; synchronized (al) &#123; // 省略代码无数 &#125; &#125;&#125;class B &#123; Long bl=Long.valueOf(1); public void setBY()&#123; synchronized (bl) &#123; // 省略代码无数 &#125; &#125;&#125; 使用 Immutability 模式的注意事项在使用 Immutability 模式的时候，需要注意以下两点： 对象的所有属性都是 final 的，并不能保证不可变性； 不可变对象也需要正确发布。 在 Java 语言中，final 修饰的属性一旦被赋值，就不可以再修改，但是如果属性的类型是普通对象，那么这个普通对象的属性是可以被修改的。例如下面的代码中，Bar 的属性 foo 虽然是 final 的，依然可以通过 setAge() 方法来设置 foo 的属性 age。所以，在使用 Immutability 模式的时候一定要确认保持不变性的边界在哪里，是否要求属性对象也具备不可变性。 123456789class Foo&#123; int age=0;&#125;final class Bar &#123; final Foo foo; void setAge(int a)&#123; foo.age=a; &#125;&#125; 下面我们再看看如何正确地发布不可变对象。不可变对象虽然是线程安全的，但是并不意味着引用这些不可变对象的对象就是线程安全的。例如在下面的代码中，Foo 具备不可变性，线程安全，但是类 Bar 并不是线程安全的，类 Bar 中持有对 Foo 的引用 foo，对 foo 这个引用的修改在多线程中并不能保证可见性和原子性。 1234567891011//Foo 线程安全final class Foo&#123; final int age=0;&#125;//Bar 线程不安全class Bar &#123; Foo foo; void setFoo(Foo f)&#123; this.foo=f; &#125;&#125; 如果你的程序仅仅需要 foo 保持可见性，无需保证原子性，那么可以将 foo 声明为 volatile 变量，这样就能保证可见性。如果你的程序需要保证原子性，那么可以通过原子类来实现。下面的示例代码是合理库存的原子化实现，你应该很熟悉了，其中就是用原子类解决了不可变对象引用的原子性问题。 12345678910111213141516171819202122232425262728public class SafeWM &#123; class WMRange&#123; final int upper; final int lower; WMRange(int upper,int lower)&#123; // 省略构造函数实现 &#125; &#125; final AtomicReference&lt;WMRange&gt; rf = new AtomicReference&lt;&gt;( new WMRange(0,0) ); // 设置库存上限 void setUpper(int v)&#123; while(true)&#123; WMRange or = rf.get(); // 检查参数合法性 if(v &lt; or.lower)&#123; throw new IllegalArgumentException(); &#125; WMRange nr = new WMRange(v, or.lower); if(rf.compareAndSet(or, nr))&#123; return; &#125; &#125; &#125;&#125; 总结具备不变性的对象，只有一种状态，这个状态由对象内部所有的不变属性共同决定。其实还有一种更简单的不变性对象，那就是 无状态。无状态对象内部没有属性，只有方法。除了无状态的对象，你可能还听说过无状态的服务、无状态的协议等等。无状态有很多好处，最核心的一点就是性能。在多线程领域，无状态对象没有线程安全问题，无需同步处理，自然性能很好；在分布式领域，无状态意味着可以无限地水平扩展，所以分布式领域里面性能的瓶颈一定不是出在无状态的服务节点上。"},{"title":"dsfasdfasdf","path":"/wiki/design/structural/structural-pattern.html","content":"sdfhi"}]