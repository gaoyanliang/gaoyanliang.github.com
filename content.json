{"meta":{"title":"yanliang‘s blog","subtitle":null,"description":null,"author":"yanliang","url":"https://gyl-coder.github.io","root":"/"},"pages":[{"title":"404 Not Found","date":"2019-10-01T01:18:53.711Z","updated":"2019-10-01T01:18:53.711Z","comments":true,"path":"404.html","permalink":"https://gyl-coder.github.io/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2019-10-01T01:32:00.322Z","updated":"2019-10-01T01:32:00.322Z","comments":true,"path":"projects/index.html","permalink":"https://gyl-coder.github.io/projects/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-10-01T01:15:50.699Z","updated":"2019-10-01T01:15:50.699Z","comments":true,"path":"categories/index.html","permalink":"https://gyl-coder.github.io/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2019-10-04T11:42:10.000Z","updated":"2019-10-04T11:42:10.000Z","comments":true,"path":"comment/index.html","permalink":"https://gyl-coder.github.io/comment/index.html","excerpt":"","text":"欢迎前来灌水。。。"},{"title":"关于","date":"2019-10-04T11:40:51.045Z","updated":"2019-10-04T11:40:51.045Z","comments":true,"path":"about/index.html","permalink":"https://gyl-coder.github.io/about/index.html","excerpt":"","text":"我是 yanliang喜欢自己胡乱捣鼓东西"},{"title":"我的朋友们","date":"2019-10-07T05:05:29.173Z","updated":"2019-10-07T05:05:29.173Z","comments":true,"path":"friends/index.html","permalink":"https://gyl-coder.github.io/friends/index.html","excerpt":"","text":"欢迎和我交换友链~各位大佬想交换友链的话可以在下方留言，必须要提供名称、头像和链接哦~请先将本站添加到你滴友链中喔，谢谢~ 友链提交模板： 名称：【请填入名称，9字以内】 头像：【请输入地址，支持png、jpg、gif等常见格式】 地址：【请填入地址，不支持url.cn等短链形式，必须以https://或http://或其他协议标准开头】 描述：【请填入描述，14字以内】"},{"title":"","date":"2019-10-01T01:16:39.406Z","updated":"2019-10-01T01:16:39.406Z","comments":true,"path":"mylist/index.html","permalink":"https://gyl-coder.github.io/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-10-01T01:16:11.969Z","updated":"2019-10-01T01:16:11.969Z","comments":true,"path":"tags/index.html","permalink":"https://gyl-coder.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Kafka中的HW、LEO、LSO等分别代表什么？","slug":"Kafka中的HW、LEO、LSO等分别代表什么？","date":"2019-10-04T15:49:03.584Z","updated":"2019-10-04T15:51:55.574Z","comments":true,"path":"2019/10/04/Kafka中的HW、LEO、LSO等分别代表什么？/","link":"","permalink":"https://gyl-coder.github.io/2019/10/04/Kafka中的HW、LEO、LSO等分别代表什么？/","excerpt":"HW 、 LEO 等概念和上一篇文章所说的 ISR有着紧密的关系，如果不了解 ISR 可以先看下ISR相关的介绍。 HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。","text":"HW 、 LEO 等概念和上一篇文章所说的 ISR有着紧密的关系，如果不了解 ISR 可以先看下ISR相关的介绍。 HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。 LEO （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1.分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。 下面具体分析一下 ISR 集合和 HW、LEO的关系。 假设某分区的 ISR 集合中有 3 个副本，即一个 leader 副本和 2 个 follower 副本，此时分区的 LEO 和 HW 都分别为 3 。消息3和消息4从生产者出发之后先被存入leader副本。 在消息被写入leader副本之后，follower副本会发送拉取请求来拉取消息3和消息4进行消息同步。 在同步过程中不同的副本同步的效率不尽相同，在某一时刻follower1完全跟上了leader副本而follower2只同步了消息3，如此leader副本的LEO为5，follower1的LEO为5，follower2的LEO 为4，那么当前分区的HW取最小值4，此时消费者可以消费到offset0至3之间的消息。 当所有副本都成功写入消息3和消息4之后，整个分区的HW和LEO都变为5，因此消费者可以消费到offset为4的消息了。 由此可见kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认已成功提交，这种复制方式极大的影响了性能。而在异步复制的方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就会被认为已经成功提交。在这种情况下，如果follower副本都还没有复制完而落后于leader副本，然后leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效的权衡了数据可靠性和性能之间的关系。","categories":[{"name":"kafka","slug":"kafka","permalink":"https://gyl-coder.github.io/categories/kafka/"}],"tags":[],"author":{"name":"yanliang","avatar":"https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.0/img/touxiang.jpg","url":"https://gyl-coder.github.io"}},{"title":"Kafka中的HW、LEO、LSO等分别代表什么？","slug":"kafka中的ISR、AR代表什么？ISR的伸缩性又指什么？","date":"2019-10-04T15:47:20.937Z","updated":"2019-10-04T15:52:13.566Z","comments":true,"path":"2019/10/04/kafka中的ISR、AR代表什么？ISR的伸缩性又指什么？/","link":"","permalink":"https://gyl-coder.github.io/2019/10/04/kafka中的ISR、AR代表什么？ISR的伸缩性又指什么？/","excerpt":"相信大家已经对 kafka 的基本概念已经有一定的了解了，下面直接来分析一下 ISR 和 AR 的概念。","text":"相信大家已经对 kafka 的基本概念已经有一定的了解了，下面直接来分析一下 ISR 和 AR 的概念。 ISR and AR简单来说，分区中的所有副本统称为 AR (Assigned Replicas)。所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成 ISR (In Sync Replicas)。 ISR 集合是 AR 集合的一个子集。消息会先发送到leader副本，然后follower副本才能从leader中拉取消息进行同步。同步期间，follow副本相对于leader副本而言会有一定程度的滞后。前面所说的 ”一定程度同步“ 是指可忍受的滞后范围，这个范围可以通过参数进行配置。于leader副本同步滞后过多的副本（不包括leader副本）将组成 OSR （Out-of-Sync Replied）由此可见，AR = ISR + OSR。正常情况下，所有的follower副本都应该与leader 副本保持 一定程度的同步，即AR=ISR，OSR集合为空。 ISR 的伸缩性leader副本负责维护和跟踪 ISR 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。如果 OSR 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变）。","categories":[{"name":"kafka","slug":"kafka","permalink":"https://gyl-coder.github.io/categories/kafka/"}],"tags":[],"author":{"name":"yanliang","avatar":"https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.0/img/touxiang.jpg","url":"https://gyl-coder.github.io"}},{"title":"kafka 主题管理","slug":"kafka 主题管理","date":"2019-10-03T06:47:01.321Z","updated":"2019-10-04T16:09:43.549Z","comments":true,"path":"2019/10/03/kafka 主题管理/","link":"","permalink":"https://gyl-coder.github.io/2019/10/03/kafka 主题管理/","excerpt":"对于 kafka 主题（topic）的管理（增删改查），使用最多的便是kafka自带的脚本。","text":"对于 kafka 主题（topic）的管理（增删改查），使用最多的便是kafka自带的脚本。 创建主题kafka提供了自带的 kafka-topics 脚本，用来帮助用户创建主题（topic）。 1bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name --partitions 1 --replication-factor 1 create 表明我们要创建主题，而 partitions 和 replication factor 分别设置了主题的分区数以及每个分区下的副本数。 这里为什么用的 --bootstrap-server 参数，而不是 --zookeeper ?--zookeeper 参数是之前版本的用法，从kafka 2.2 版本开始，社区推荐使用 --bootstrap-server 参数替换 --zoookeeper ，并且显式地将后者标记为 “已过期”，因此，如果你已经在使用 2.2 版本了，那么创建主题请指定 --bootstrap-server 参数。 推荐使用 --bootstrap-server 而非 --zookeeper 的原因主要有两个。 使用 –zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 –zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束。这显然是 Kafka 集群的运维人员不希望看到的。 使用 –bootstrap-server 与集群进行交互，越来越成为使用 Kafka 的标准姿势。换句话说，以后会有越来越少的命令和 API 需要与 ZooKeeper 进行连接。这样，我们只需要一套连接信息，就能与 Kafka 进行全方位的交互，不用像以前一样，必须同时维护 ZooKeeper 和 Broker 的连接信息。 查询主题创建好主题之后，Kafka 允许我们使用相同的脚本查询主题。你可以使用下面的命令，查询所有主题的列表。 1bin/kafka-topics.sh --bootstrap-server broker_host:port --list 如果要查询单个主题的详细数据，你可以使用下面的命令。 1bin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt; 如果 describe 命令不指定具体的主题名称，那么 Kafka 默认会返回所有 “可见” 主题的详细数据给你。 这里的 “可见”，是指发起这个命令的用户能够看到的 Kafka 主题。这和前面说到主题创建时，使用 –zookeeper 和 –bootstrap-server 的区别是一样的。如果指定了 –bootstrap-server，那么这条命令就会受到安全认证体系的约束，即对命令发起者进行权限验证，然后返回它能看到的主题。否则，如果指定 –zookeeper 参数，那么默认会返回集群中所有的主题详细数据。基于这些原因，我建议你最好统一使用 –bootstrap-server 连接参数。 修改主题修改主题分区其实就是增加分区，目前 Kafka 不允许减少某个主题的分区数。你可以使用 kafka-topics 脚本，结合 –alter 参数来增加某个主题的分区数，命令如下： 1bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt; 新分区数 &gt; 这里要注意的是，你指定的分区数一定要比原有分区数大，否则 Kafka 会抛出 InvalidPartitionsException 异常。 修改主题级别参数在主题创建之后，我们可以使用 kafka-configs 脚本修改对应的参数。 假设我们要设置主题级别参数 max.message.bytes，那么命令如下： 1bin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes=10485760 也许你会觉得奇怪，为什么这个脚本就要指定 –zookeeper，而不是 –bootstrap-server 呢？其实，这个脚本也能指定 –bootstrap-server 参数，只是它是用来设置动态参数的。在专栏后面，我会详细介绍什么是动态参数，以及动态参数都有哪些。现在，你只需要了解设置常规的主题级别参数，还是使用 –zookeeper。 变更副本数使用自带的 kafka-reassign-partitions 脚本，帮助我们增加主题的副本数。 假设kafka的内部主题 __consumer_offsets 只有 1 个副本，现在我们想要增加至 3 个副本。下面是操作： 创建一个 json 文件，显式提供 50 个分区对应的副本数。注意，replicas 中的 3 台 Broker 排列顺序不同，目的是将 Leader 副本均匀地分散在 Broker 上。该文件具体格式如下 12345678&#123;\"version\":1, \"partitions\":[ &#123;\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]&#125;, &#123;\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]&#125;, &#123;\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]&#125;, &#123;\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[1,2,0]&#125;, ... &#123;\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]&#125;]&#125; 执行 kafka-reassign-patitions 脚本，命令如下： 1bin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute 除了修改内部主题，我们可能还想查看这些内部主题的消息内容。特别是对于 __consumer_offsets 而言，由于它保存了消费者组的位移数据，有时候直接查看该主题消息是很方便的事情。下面的命令可以帮助我们直接查看消费者组提交的位移数据。 1bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --from-beginning 除了查看位移提交数据，我们还可以直接读取该主题消息，查看消费者组的状态信息。 1bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter&quot; --from-beginning 对于内部主题 __transaction_state 而言，方法是相同的。你只需要指定 kafka.coordinator.transaction.TransactionLog$TransactionLogMessageFormatter 即可。 修改主题限速这里主要是指设置 Leader 副本和 Follower 副本使用的带宽。有时候，我们想要让某个主题的副本在执行副本同步机制时，不要消耗过多的带宽。Kafka 提供了这样的功能。我来举个例子。假设我有个主题，名为 test，我想让该主题各个分区的 Leader 副本和 Follower 副本在处理副本同步时，不得占用超过 100MBps 的带宽。注意是大写 B，即每秒不超过 100MB。那么，我们应该怎么设置呢？ 要达到这个目的，我们必须先设置 Broker 端参数 leader.replication.throttled.rate 和 follower.replication.throttled.rate，命令如下： 1bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &apos;leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600&apos; --entity-type brokers --entity-name 0 这条命令结尾处的 –entity-name 就是 Broker ID。倘若该主题的副本分别在 0、1、2、3 多个 Broker 上，那么你还要依次为 Broker 1、2、3 执行这条命令。 设置好这个参数之后，我们还需要为该主题设置要限速的副本。在这个例子中，我们想要为所有副本都设置限速，因此统一使用通配符 * 来表示，命令如下： 1bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &apos;leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*&apos; --entity-type topics --entity-name test 主题分区迁移同样是使用 kafka-reassign-partitions 脚本，对主题各个分区的副本进行 “手术” 般的调整，比如把某些分区批量迁移到其他 Broker 上。 删除主题1bin/kafka-topics.sh --bootstrap-server broker_host:port --delete --topic &lt;topic_name&gt; 删除主题的命令并不复杂，关键是删除操作是异步的，执行完这条命令不代表主题立即就被删除了。它仅仅是被标记成 “已删除” 状态而已。Kafka 会在后台默默地开启主题删除操作。因此，通常情况下，你都需要耐心地等待一段时间。 主题删除失败当运行完上面的删除命令后，很多人发现已删除主题的分区数据依然 “躺在” 硬盘上，没有被清除。这时该怎么办呢？ 实际上，造成主题删除失败的原因有很多，最常见的原因有两个： 副本所在的 Broker 宕机了 待删除主题的部分分区依然在执行迁移过程。 如果是因为前者，通常你重启对应的 Broker 之后，删除操作就能自动恢复；如果是因为后者，那就麻烦了，很可能两个操作会相互干扰。 不管什么原因，一旦你碰到主题无法删除的问题，可以采用这样的方法： 手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。 手动删除该主题在磁盘上的分区目录。 在 ZooKeeper 中执行 rmr /controller，触发 Controller 重选举，刷新 Controller 缓存。 在执行最后一步时，你一定要谨慎，因为它可能造成大面积的分区 Leader 重选举。事实上，仅仅执行前两步也是可以的，只是 Controller 缓存中没有清空待删除主题罢了，也不影响使用。 常见问题__consumer_offsets 占用太多的磁盘一旦你发现这个主题消耗了过多的磁盘空间，那么，你一定要显式地用 jstack 命令查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。倘若真是这个原因导致的，那我们就只能重启相应的 Broker 了。另外，请你注意保留出错日志，因为这通常都是 Bug 导致的，最好提交到社区看一下。 Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"kafka","slug":"kafka","permalink":"https://gyl-coder.github.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://gyl-coder.github.io/tags/kafka/"},{"name":"topic","slug":"topic","permalink":"https://gyl-coder.github.io/tags/topic/"}],"author":{"name":"yanliang","avatar":"https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.0/img/touxiang.jpg","url":"https://gyl-coder.github.io"}},{"title":"Hello World","slug":"hello-world","date":"2019-09-30T16:06:08.620Z","updated":"2019-10-03T07:19:55.274Z","comments":true,"path":"2019/10/01/hello-world/","link":"","permalink":"https://gyl-coder.github.io/2019/10/01/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}